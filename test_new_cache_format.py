#!/usr/bin/env python3
"""Test cache_daily_data.py fix by creating new cache entries."""

import sys
from pathlib import Path

ROOT_DIR = Path(__file__).resolve().parent
if str(ROOT_DIR) not in sys.path:
    sys.path.insert(0, str(ROOT_DIR))

import pandas as pd
from common.cache_manager import CacheManager
from common.indicators_common import add_indicators
from config.settings import get_settings


def test_new_cache_format():
    """Test creating new cache with PascalCase columns."""
    print("ğŸ” æ–°ã—ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥å½¢å¼ã‚’ãƒ†ã‚¹ãƒˆ")

    settings = get_settings(create_dirs=True)
    cm = CacheManager(settings)

    # Simulate EODHD API data format (as returned by get_eodhd_data)
    test_data = {
        "Date": pd.date_range("2024-01-01", periods=100),
        "Open": [100.0 + i * 0.5 for i in range(100)],
        "High": [101.0 + i * 0.5 for i in range(100)],
        "Low": [99.0 + i * 0.5 for i in range(100)],
        "Close": [100.5 + i * 0.5 for i in range(100)],
        "AdjClose": [100.5 + i * 0.5 for i in range(100)],
        "Volume": [1000000 + i * 1000 for i in range(100)],
    }

    df = pd.DataFrame(test_data).set_index("Date")

    print(f"ğŸ“Š å…ƒãƒ‡ãƒ¼ã‚¿å½¢å¼: {list(df.columns)}")

    # Apply indicators as cache_daily_data.py would do
    full_df = add_indicators(df.copy())

    print(f"ğŸ§® æŒ‡æ¨™è¿½åŠ å¾Œ: {len(full_df.columns)} åˆ—")
    print(f"ğŸ“ æŒ‡æ¨™è¿½åŠ å¾Œåˆ—å: {list(full_df.columns)[:15]}...")

    # Apply the fixed processing (no .rename(columns=str.lower))
    df_reset = full_df.reset_index()

    print(f"ğŸ’¾ ä¿å­˜å½¢å¼: {len(df_reset.columns)} åˆ—")
    print(f"ğŸ“ ä¿å­˜å½¢å¼åˆ—å: {list(df_reset.columns)[:15]}...")

    # Save to test location
    test_path = cm.full_dir / "TEST_NEW_FORMAT.csv"
    df_reset.to_csv(test_path, index=False)
    print(f"âœ… ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {test_path}")

    # Load it back and check
    loaded = pd.read_csv(test_path)
    print(f"ğŸ“‚ ãƒ­ãƒ¼ãƒ‰å¾Œ: {len(loaded.columns)} åˆ—")
    print(f"ğŸ“ ãƒ­ãƒ¼ãƒ‰å¾Œåˆ—å: {list(loaded.columns)[:15]}...")

    # Check for duplicates
    all_cols = loaded.columns.tolist()
    seen = set()
    duplicates = []
    for col in all_cols:
        if col.lower() in seen:
            duplicates.append(col)
        else:
            seen.add(col.lower())

    if duplicates:
        print(f"ğŸ”´ é‡è¤‡åˆ—ç™ºè¦‹: {duplicates}")
    else:
        print("âœ… é‡è¤‡åˆ—ãªã—!")

    # Test with build_rolling_with_indicators
    from scripts.build_rolling_with_indicators import _prepare_rolling_frame

    result = _prepare_rolling_frame(loaded, target_days=50)
    if result is not None:
        print(f"ğŸ”§ rollingå‡¦ç†å¾Œ: {len(result.columns)} åˆ—")

        # Check for duplicates after rolling processing
        all_cols = result.columns.tolist()
        seen = set()
        duplicates = []
        for col in all_cols:
            if col.lower() in seen:
                duplicates.append(col)
            else:
                seen.add(col.lower())

        if duplicates:
            print(f"ğŸ”´ rollingå‡¦ç†å¾Œã«é‡è¤‡åˆ—: {duplicates}")
        else:
            print("âœ… rollingå‡¦ç†å¾Œã‚‚é‡è¤‡åˆ—ãªã—!")
    else:
        print("âŒ rollingå‡¦ç†ãŒå¤±æ•—")


if __name__ == "__main__":
    test_new_cache_format()
