#!/usr/bin/env python3
"""Bulk APIãƒ‡ãƒ¼ã‚¿ã®ç²¾åº¦ã‚’æ¤œè¨¼ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å€‹åˆ¥APIã¾ãŸã¯æ—¢å­˜ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ã®å·®ç•°ã‚’ç¢ºèªã—ã€
Bulk APIã®ä¿¡é ¼æ€§ã‚’æ•°å€¤åŒ–ã—ã¾ã™ã€‚
"""

from __future__ import annotations

from datetime import datetime, timedelta
import os
from pathlib import Path
import sys
from typing import Any

from dotenv import load_dotenv
import pandas as pd
import requests

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’PYTHONPATHã«è¿½åŠ 
ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from common.cache_manager import CacheManager  # noqa: E402
from config.environment import get_env_config  # noqa: E402
from config.settings import get_settings  # noqa: E402
from scripts.update_from_bulk_last_day import fetch_bulk_last_day  # noqa: E402

load_dotenv()
API_KEY = os.getenv("EODHD_API_KEY")


class BulkDataVerifier:
    """Bulk APIãƒ‡ãƒ¼ã‚¿ã®å“è³ªã‚’æ¤œè¨¼ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.settings = get_settings()
        self.cm = CacheManager(self.settings)
        self.discrepancies: list[dict[str, Any]] = []

        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿
        env_config = get_env_config()

        # Volumeå·®ç•°ã®è¨±å®¹ç¯„å›²ï¼ˆç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡å¯èƒ½ï¼‰
        self.volume_tolerance = env_config.bulk_api_volume_tolerance / 100.0
        # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®è¨±å®¹ç¯„å›²ï¼ˆå¾“æ¥é€šã‚Šï¼‰
        self.price_tolerance = env_config.bulk_api_price_tolerance / 100.0
        # ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ã®æœ€ä½åŸºæº–
        self.min_reliability = env_config.bulk_api_min_reliability / 100.0

    def fetch_individual_eod(self, symbol: str, date: str | None = None) -> dict[str, Any]:
        """å€‹åˆ¥APIã§æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆæ¤œè¨¼ç”¨ï¼‰"""
        if not API_KEY:
            return {}

        url = f"https://eodhistoricaldata.com/api/eod/{symbol.lower()}.US"
        params = {
            "api_token": API_KEY,
            "fmt": "json",
            "from": (date if date else (datetime.now() - timedelta(days=5)).strftime("%Y-%m-%d")),
            "to": date if date else datetime.now().strftime("%Y-%m-%d"),
        }

        try:
            response = requests.get(url, params=params, timeout=10)
            if response.status_code == 200:
                data = response.json()
                return data[-1] if data else {}
        except Exception as e:
            print(f"  âš ï¸ å€‹åˆ¥APIå–å¾—ã‚¨ãƒ©ãƒ¼ {symbol}: {e}")
        return {}

    def compare_prices(
        self,
        bulk_row: pd.Series,
        reference: dict[str, Any] | pd.Series,
        symbol: str,
        tolerance: float = 0.01,
    ) -> dict[str, Any]:
        """ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’æ¯”è¼ƒï¼ˆè¨±å®¹èª¤å·®: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ1%ï¼‰"""
        issues = []

        # ä¾¡æ ¼ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        price_fields = {
            "open": ["open", "Open"],
            "high": ["high", "High"],
            "low": ["low", "Low"],
            "close": ["close", "Close"],
            "adjusted_close": ["adjusted_close", "adjclose", "AdjClose"],
            "volume": ["volume", "Volume"],
        }

        for field, aliases in price_fields.items():
            bulk_val = None
            ref_val = None

            # Bulkãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å€¤ã‚’å–å¾—
            for alias in aliases:
                if alias in bulk_row.index and pd.notna(bulk_row[alias]):
                    try:
                        bulk_val = float(bulk_row[alias])
                        break
                    except (ValueError, TypeError):
                        continue

            # å‚ç…§ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å€¤ã‚’å–å¾—
            if isinstance(reference, dict):
                for alias in aliases:
                    if alias in reference and reference[alias] is not None:
                        try:
                            ref_val = float(reference[alias])
                            break
                        except (ValueError, TypeError):
                            continue
            else:
                for alias in aliases:
                    if alias in reference.index and pd.notna(reference[alias]):
                        try:
                            ref_val = float(reference[alias])
                            break
                        except (ValueError, TypeError):
                            continue

            # æ¯”è¼ƒï¼ˆVolumeã¯å°‚ç”¨è¨±å®¹ç¯„å›²ã‚’ä½¿ç”¨ï¼‰
            if bulk_val is not None and ref_val is not None and ref_val > 0:
                diff_pct = abs(bulk_val - ref_val) / ref_val
                # Volumeã¯ç·©å’Œã—ãŸè¨±å®¹ç¯„å›²ã€ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã¯å³æ ¼ãªè¨±å®¹ç¯„å›²
                field_tolerance = self.volume_tolerance if field == "volume" else tolerance

                if diff_pct > field_tolerance:
                    issues.append(
                        {
                            "field": field,
                            "bulk": bulk_val,
                            "reference": ref_val,
                            "diff_pct": diff_pct,
                        }
                    )

        return {"symbol": symbol, "has_issues": len(issues) > 0, "issues": issues}

    def verify_sample_symbols(
        self, sample_symbols: list[str] | None = None, use_individual_api: bool = False
    ) -> dict[str, Any]:
        """ã‚µãƒ³ãƒ—ãƒ«éŠ˜æŸ„ã§Bulkãƒ‡ãƒ¼ã‚¿ã®ç²¾åº¦ã‚’æ¤œè¨¼"""

        if sample_symbols is None:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚µãƒ³ãƒ—ãƒ«éŠ˜æŸ„ï¼ˆä¸»è¦æŒ‡æ•°ãƒ»å¤§å‹æ ªãƒ»å°å‹æ ªã®æ··åˆï¼‰
            sample_symbols = [
                "SPY",
                "QQQ",
                "IWM",
                "AAPL",
                "MSFT",
                "GOOGL",
                "AMZN",
                "TSLA",
                "NVDA",
                "META",
            ]

        print("=" * 60)
        print("ğŸ” Bulk APIãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼")
        print("=" * 60)
        print("ğŸ“Š Bulk APIãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...", flush=True)

        bulk_df = fetch_bulk_last_day()

        if bulk_df is None or bulk_df.empty:
            print("âŒ Bulk ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return {"success": False, "message": "Bulk data fetch failed"}

        # æ—¥ä»˜ã‚’ç¢ºèª
        bulk_date = None
        if "date" in bulk_df.columns:
            try:
                bulk_date = pd.to_datetime(bulk_df["date"].iloc[0]).strftime("%Y-%m-%d")
                print(f"ğŸ“… Bulk ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜: {bulk_date}")
            except Exception:
                print("âš ï¸ æ—¥ä»˜ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ")

        print(f"ğŸ“¦ Bulk ãƒ‡ãƒ¼ã‚¿: {len(bulk_df)}è¡Œå–å¾—")
        print()

        results = {
            "date": bulk_date,
            "total_symbols": len(sample_symbols),
            "verified": 0,
            "issues": [],
            "missing": [],
            "perfect_match": [],
        }

        for idx, symbol in enumerate(sample_symbols, 1):
            print(f"[{idx}/{len(sample_symbols)}] ğŸ” æ¤œè¨¼ä¸­: {symbol}")

            # Bulkãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è©²å½“éŠ˜æŸ„ã‚’æŠ½å‡º
            bulk_sym = bulk_df[bulk_df["code"].str.upper() == symbol] if "code" in bulk_df.columns else pd.DataFrame()

            if bulk_sym.empty:
                print("  âš ï¸ Bulkãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ã¾ã›ã‚“")
                results["missing"].append(symbol)
                continue

            bulk_row = bulk_sym.iloc[0]
            comparison_done = False

            # æ–¹æ³•1: æ—¢å­˜ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨æ¯”è¼ƒï¼ˆAPIã‚³ãƒ¼ãƒ«ä¸è¦ï¼‰
            try:
                cached = self.cm.read(symbol, "full")
                if cached is not None and not cached.empty:
                    # æœ€æ–°è¡Œã¨æ¯”è¼ƒ
                    latest_cached = cached.iloc[-1]

                    # æ—¥ä»˜ã‚’ç¢ºèª
                    cached_date = None
                    if "Date" in cached.columns:
                        cached_date = pd.to_datetime(cached["Date"].iloc[-1]).strftime("%Y-%m-%d")
                    elif "date" in cached.columns:
                        cached_date = pd.to_datetime(cached["date"].iloc[-1]).strftime("%Y-%m-%d")

                    if cached_date:
                        print(f"  ğŸ“ ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€æ–°æ—¥: {cached_date}")

                    comparison = self.compare_prices(bulk_row, latest_cached, symbol)
                    comparison_done = True

                    if comparison["has_issues"]:
                        print("  âš ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ã®å·®ç•°ã‚’æ¤œå‡º:")
                        for issue in comparison["issues"]:
                            print(
                                f"    - {issue['field']}: Bulk={issue['bulk']:.2f}, "
                                f"Cache={issue['reference']:.2f} "
                                f"({issue['diff_pct']:.2%}å·®)"
                            )
                        results["issues"].append(comparison)
                    else:
                        print("  âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ä¸€è‡´")
                        results["perfect_match"].append(symbol)
            except Exception as e:
                print(f"  âš ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”è¼ƒã‚¨ãƒ©ãƒ¼: {e}")

            # æ–¹æ³•2: å€‹åˆ¥APIã§å†å–å¾—ã—ã¦æ¯”è¼ƒï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€APIã‚³ãƒ¼ãƒ«æ¶ˆè²»æ³¨æ„ï¼‰
            if use_individual_api and not comparison_done:
                print("  ğŸŒ å€‹åˆ¥APIã§æ¤œè¨¼ä¸­...")
                individual = self.fetch_individual_eod(symbol, bulk_date)
                if individual:
                    comparison = self.compare_prices(bulk_row, individual, symbol)
                    if comparison["has_issues"]:
                        print("  âš ï¸ å€‹åˆ¥APIã¨ã®å·®ç•°ã‚’æ¤œå‡º:")
                        for issue in comparison["issues"]:
                            print(
                                f"    - {issue['field']}: Bulk={issue['bulk']:.2f}, "
                                f"API={issue['reference']:.2f} "
                                f"({issue['diff_pct']:.2%}å·®)"
                            )
                        results["issues"].append(comparison)
                    else:
                        print("  âœ… å€‹åˆ¥APIã¨ä¸€è‡´")
                        results["perfect_match"].append(symbol)
                else:
                    print("  âš ï¸ å€‹åˆ¥APIã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")

            results["verified"] += 1

        # ã‚µãƒãƒªãƒ¼å‡ºåŠ›
        print("\n" + "=" * 60)
        print("ğŸ“‹ æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼")
        print("=" * 60)
        print(f"  æ¤œè¨¼éŠ˜æŸ„æ•°: {results['verified']}/{results['total_symbols']}")
        print(f"  å®Œå…¨ä¸€è‡´: {len(results['perfect_match'])}ä»¶")
        print(f"  å•é¡Œæ¤œå‡º: {len(results['issues'])}ä»¶")
        print(f"  ãƒ‡ãƒ¼ã‚¿æ¬ æ: {len(results['missing'])}ä»¶")

        if results["perfect_match"]:
            print(f"\nâœ… å®Œå…¨ä¸€è‡´ã—ãŸéŠ˜æŸ„: {', '.join(results['perfect_match'])}")

        if results["issues"]:
            print("\nâš ï¸ å•é¡Œã®ã‚ã‚‹éŠ˜æŸ„:")
            for item in results["issues"]:
                print(f"  - {item['symbol']}: {len(item['issues'])}é …ç›®ã§å·®ç•°")

        if results["missing"]:
            print(f"\nâš ï¸ Bulkãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ãªã„éŠ˜æŸ„: {', '.join(results['missing'])}")

        # ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ã®ç®—å‡º
        verified_count = results["verified"]
        issue_count = len(results["issues"])

        if verified_count > 0:
            total_symbols = results["total_symbols"]
            reliability_score = (verified_count - issue_count) / total_symbols
        else:
            reliability_score = 0.0

        results["reliability_score"] = reliability_score

        print("\n" + "=" * 60)
        # ç’°å¢ƒå¤‰æ•°ã§è¨­å®šã•ã‚ŒãŸæœ€ä½åŸºæº–ã¨æ¯”è¼ƒ
        if reliability_score >= 0.95:
            print(f"âœ… ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢: {reliability_score:.1%}")
            print("ğŸ‘ Bulk APIã¯é«˜å“è³ªã§ã™ã€‚å®‰å¿ƒã—ã¦ä½¿ç”¨ã§ãã¾ã™ã€‚")
        elif reliability_score >= self.min_reliability:
            print(f"âš ï¸ ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢: {reliability_score:.1%}")
            print("ğŸ’¡ ä¸€éƒ¨éŠ˜æŸ„ã§å·®ç•°ãŒã‚ã‚Šã¾ã™ã€‚é‡è¦éŠ˜æŸ„ã¯å€‹åˆ¥ç¢ºèªã‚’æ¨å¥¨ã€‚")
            print(f"   ï¼ˆåŸºæº–: {self.min_reliability:.0%}ä»¥ä¸Šã§ä½¿ç”¨å¯èƒ½ï¼‰")
        else:
            print(f"âŒ ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢: {reliability_score:.1%}")
            print("ğŸš¨ Bulk APIã®å“è³ªãŒä½ã„ã§ã™ã€‚å€‹åˆ¥APIä½¿ç”¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
            print(f"   ï¼ˆåŸºæº–: {self.min_reliability:.0%}æœªæº€ï¼‰")
        print("=" * 60)

        return results

    def verify_timing_impact(self):
        """å–å¾—ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã«ã‚ˆã‚‹å½±éŸ¿ã‚’èª¿æŸ»"""
        print("\n" + "=" * 60)
        print("ğŸ• å–å¾—ã‚¿ã‚¤ãƒŸãƒ³ã‚°å½±éŸ¿èª¿æŸ»")
        print("=" * 60)

        # ç¾åœ¨æ™‚åˆ»ã‚’ç¢ºèª
        now = datetime.now()

        # ç±³å›½å¸‚å ´ã®ã‚¯ãƒ­ãƒ¼ã‚ºæ™‚åˆ»ï¼ˆET 4PMï¼‰
        # æ—¥æœ¬æ™‚é–“ã§è€ƒãˆã‚‹ã¨ã€å¤æ™‚é–“: ç¿Œæœ5æ™‚ã€å†¬æ™‚é–“: ç¿Œæœ6æ™‚
        print(f"ç¾åœ¨æ™‚åˆ»: {now.strftime('%Y-%m-%d %H:%M:%S')}")

        # ç°¡æ˜“çš„ãªåˆ¤å®šï¼ˆå®Ÿéš›ã®é‹ç”¨ã§ã¯å¸‚å ´ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼APIã‚’ä½¿ç”¨ã™ã¹ãï¼‰
        hour = now.hour

        if 6 <= hour < 10:
            print("âœ… æ¨å¥¨å®Ÿè¡Œæ™‚é–“å¸¯ã§ã™ï¼ˆç±³å›½å¸‚å ´ã‚¯ãƒ­ãƒ¼ã‚ºå¾Œã€ãƒ‡ãƒ¼ã‚¿å®‰å®šï¼‰")
            print("ğŸ’¡ ã“ã®æ™‚é–“å¸¯ã®Bulk APIå–å¾—ã¯ä¿¡é ¼æ€§ãŒé«˜ã„ã§ã™ã€‚")
        elif 0 <= hour < 6:
            print("âš ï¸ å¸‚å ´ã‚¯ãƒ­ãƒ¼ã‚ºç›´å¾Œã®æ™‚é–“å¸¯ã§ã™")
            print("ğŸ’¡ ãƒ‡ãƒ¼ã‚¿ãŒä¸å®Œå…¨ãªå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚6æ™‚ä»¥é™ã®å®Ÿè¡Œã‚’æ¨å¥¨ã€‚")
        else:
            print("â„¹ï¸ é€šå¸¸ã®å®Ÿè¡Œæ™‚é–“å¸¯ã§ã™")
            print("ğŸ’¡ å‰å–¶æ¥­æ—¥ã®ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã•ã‚Œã¾ã™ã€‚")

        print("=" * 60)

    def analyze_bulk_coverage(self):
        """Bulkãƒ‡ãƒ¼ã‚¿ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’åˆ†æ"""
        print("\n" + "=" * 60)
        print("ğŸ“Š Bulkãƒ‡ãƒ¼ã‚¿ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ")
        print("=" * 60)

        bulk_df = fetch_bulk_last_day()
        if bulk_df is None or bulk_df.empty:
            print("âŒ Bulk ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return

        # ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã¨æ¯”è¼ƒ
        try:
            from common.symbol_universe import build_symbol_universe_from_settings

            universe = build_symbol_universe_from_settings(self.settings)
            universe_set = set(s.upper() for s in universe)

            if "code" in bulk_df.columns:
                bulk_symbols = set(bulk_df["code"].str.upper())

                coverage = len(bulk_symbols & universe_set) / len(universe_set) if universe_set else 0
                missing = universe_set - bulk_symbols

                print(f"ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹éŠ˜æŸ„æ•°: {len(universe_set)}")
                print(f"Bulkå–å¾—éŠ˜æŸ„æ•°: {len(bulk_symbols)}")
                print(f"ã‚«ãƒãƒ¬ãƒƒã‚¸: {coverage:.1%}")

                if missing:
                    print(f"\nâš ï¸ Bulkã«å­˜åœ¨ã—ãªã„éŠ˜æŸ„: {len(missing)}ä»¶")
                    if len(missing) <= 20:
                        print(f"  {', '.join(sorted(missing))}")
                    else:
                        sample = sorted(missing)[:20]
                        print(f"  (æœ€åˆã®20ä»¶) {', '.join(sample)}")
                        print(f"  ... ä»– {len(missing) - 20}ä»¶")
        except Exception as e:
            print(f"âš ï¸ ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

        print("=" * 60)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    import argparse

    parser = argparse.ArgumentParser(
        description="Bulk APIãƒ‡ãƒ¼ã‚¿ã®ç²¾åº¦æ¤œè¨¼",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚µãƒ³ãƒ—ãƒ«éŠ˜æŸ„ã§æ¤œè¨¼
  python scripts/verify_bulk_accuracy.py

  # ç‰¹å®šéŠ˜æŸ„ã‚’æŒ‡å®šã—ã¦æ¤œè¨¼
  python scripts/verify_bulk_accuracy.py --symbols AAPL,MSFT,SPY

  # å€‹åˆ¥APIã§ã‚‚æ¤œè¨¼ï¼ˆAPIã‚³ãƒ¼ãƒ«æ¶ˆè²»æ³¨æ„ï¼‰
  python scripts/verify_bulk_accuracy.py --use-api

  # ã‚¿ã‚¤ãƒŸãƒ³ã‚°å½±éŸ¿ã‚’èª¿æŸ»
  python scripts/verify_bulk_accuracy.py --timing

  # ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ
  python scripts/verify_bulk_accuracy.py --coverage

  # å…¨æ©Ÿèƒ½å®Ÿè¡Œ
  python scripts/verify_bulk_accuracy.py --full
        """,
    )

    parser.add_argument("--symbols", type=str, help="æ¤œè¨¼ã™ã‚‹éŠ˜æŸ„ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰ä¾‹: AAPL,MSFT,SPY")
    parser.add_argument(
        "--use-api",
        action="store_true",
        help="å€‹åˆ¥APIã§ã‚‚æ¤œè¨¼ï¼ˆAPIã‚³ãƒ¼ãƒ«æ¶ˆè²»ã«æ³¨æ„ï¼‰",
    )
    parser.add_argument("--timing", action="store_true", help="å–å¾—ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®å½±éŸ¿ã‚’èª¿æŸ»")
    parser.add_argument("--coverage", action="store_true", help="Bulkãƒ‡ãƒ¼ã‚¿ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’åˆ†æ")
    parser.add_argument(
        "--full",
        action="store_true",
        help="å…¨æ©Ÿèƒ½ã‚’å®Ÿè¡Œï¼ˆã‚¿ã‚¤ãƒŸãƒ³ã‚°ãƒ»ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ»ç²¾åº¦æ¤œè¨¼ï¼‰",
    )
    parser.add_argument(
        "--tolerance",
        type=float,
        default=0.01,
        help="ä¾¡æ ¼å·®ç•°ã®è¨±å®¹èª¤å·®ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.01 = 1%%ï¼‰",
    )

    args = parser.parse_args()

    verifier = BulkDataVerifier()

    # ã‚¿ã‚¤ãƒŸãƒ³ã‚°å½±éŸ¿èª¿æŸ»
    if args.timing or args.full:
        verifier.verify_timing_impact()

    # ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ
    if args.coverage or args.full:
        verifier.analyze_bulk_coverage()

    # ç²¾åº¦æ¤œè¨¼
    if args.symbols:
        symbols = [s.strip().upper() for s in args.symbols.split(",")]
        results = verifier.verify_sample_symbols(symbols, use_individual_api=args.use_api)
    else:
        results = verifier.verify_sample_symbols(use_individual_api=args.use_api)

    # çµ‚äº†ã‚³ãƒ¼ãƒ‰
    reliability_score = results.get("reliability_score", 0)
    if reliability_score >= 0.80:
        return 0  # æˆåŠŸ
    else:
        return 1  # å¤±æ•—ï¼ˆå“è³ªãŒä½ã„ï¼‰


if __name__ == "__main__":
    sys.exit(main())
