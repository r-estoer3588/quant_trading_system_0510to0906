#!/usr/bin/env python3
"""Analyze rolling cache missing CSV and produce a markdown summary.

Usage:
    python scripts/analyze_missing_rolling.py --input \
        "C:/path/to/rolling_cache_missing_20250921_155609.csv"

Writes summary to `data_cache/rolling/_missing_reports/summary_<timestamp>.md` by default.
"""

from __future__ import annotations

import argparse
import datetime
from pathlib import Path
import sys

import pandas as pd


def fmt_md_table(df, cols=None, limit=100):
    if cols is None:
        cols = list(df.columns)
    lines = []
    lines.append("| " + " | ".join(cols) + " |")
    lines.append("|" + "---|" * len(cols))
    for _, r in df.head(limit).iterrows():
        lines.append("| " + " | ".join(str(r.get(c, "")) for c in cols) + " |")
    return "\n".join(lines)


def analyze(path: Path, top_n: int = 20, out_dir: Path | None = None):
    df = pd.read_csv(path)

    now = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    if out_dir is None:
        out_dir = Path("data_cache") / "rolling" / "_missing_reports"
    out_dir.mkdir(parents=True, exist_ok=True)
    out_path = out_dir / f"summary_{now}.md"

    rows = len(df)
    symbol_col = None
    for c in ["Symbol", "symbol", "Ticker"]:
        if c in df.columns:
            symbol_col = c
            break

    unique_symbols = df[symbol_col].nunique() if symbol_col else 0

    top_symbols = None
    if symbol_col:
        top_symbols = df[symbol_col].value_counts().head(top_n).reset_index()
        top_symbols.columns = [symbol_col, "count"]

    date_cols = [c for c in ["Date", "StartDate", "EndDate"] if c in df.columns]
    date_ranges = {}
    for c in date_cols:
        try:
            s = pd.to_datetime(df[c], errors="coerce")
            date_ranges[c] = {"min": s.min(), "max": s.max(), "na": int(s.isna().sum())}
        except Exception:
            date_ranges[c] = {"min": None, "max": None, "na": int(df[c].isna().sum())}

    # date distribution if Date exists
    date_dist = None
    if "Date" in df.columns:
        try:
            s = pd.to_datetime(df["Date"], errors="coerce")
            date_dist = s.dt.date.value_counts().sort_index()
        except Exception:
            date_dist = None

    # assemble markdown
    lines = []
    lines.append(f"# Rolling Cache Missing Report â€” {now}")
    lines.append("")
    lines.append("## Summary")
    lines.append("")
    lines.append(f"- input file: `{path}`")
    lines.append(f"- rows: **{rows}**")
    lines.append(f"- unique symbols: **{unique_symbols}**")
    lines.append("")

    if top_symbols is not None:
        lines.append("## Top missing symbols")
        lines.append("")
        lines.append("| Symbol | Missing Count |")
        lines.append("|---|---:|")
        for _, r in top_symbols.iterrows():
            sym = r.iloc[0]
            cnt = int(r.iloc[1])
            lines.append(f"| {sym} | {cnt} |")
        lines.append("")

    if date_ranges:
        lines.append("## Date columns range & NaNs")
        lines.append("")
        lines.append("| Column | Min | Max | NaN Count |")
        lines.append("|---|---|---|---:|")
        for c, v in date_ranges.items():
            minv = v["min"] if v["min"] is not pd.NaT and v["min"] is not None else ""
            maxv = v["max"] if v["max"] is not pd.NaT and v["max"] is not None else ""
            lines.append(f"| {c} | {minv} | {maxv} | {v['na']} |")
        lines.append("")

    if date_dist is not None:
        lines.append("## Missing count by Date")
        lines.append("")
        lines.append("| Date | Missing Count |")
        lines.append("|---|---:|")
        for d, c in date_dist.items():
            lines.append(f"| {d} | {int(c)} |")
        lines.append("")

    # sample rows for top symbols
    if symbol_col and top_symbols is not None:
        lines.append("## Sample rows for top symbols")
        lines.append("")
        sample_syms = top_symbols[symbol_col].head(10).tolist()
        sample_df = df[df[symbol_col].isin(sample_syms)].copy()
        cols = [symbol_col] + [c for c in ["Date", "StartDate", "EndDate", "Reason"] if c in df.columns]
        if not cols:
            cols = df.columns.tolist()[:10]
        lines.append(fmt_md_table(sample_df, cols=cols, limit=200))
        lines.append("")

    lines.append("---")
    lines.append(f"Generated by `scripts/analyze_missing_rolling.py` on {now}")

    with open(out_path, "w", encoding="utf-8") as f:
        f.write("\n".join(str(x) for x in lines))

    print(f"Analysis written to: {out_path}")


def main_cli():
    p = argparse.ArgumentParser(description="Analyze rolling cache missing CSV")
    p.add_argument("--input", "-i", required=True, help="CSV file path")
    p.add_argument("--top", "-n", type=int, default=20, help="Top N symbols")
    p.add_argument("--outdir", help="Output directory for markdown report")
    args = p.parse_args()

    path = Path(args.input)
    if not path.exists():
        print(f"ERROR: input file not found: {path}", file=sys.stderr)
        sys.exit(2)

    outdir = Path(args.outdir) if args.outdir else None
    analyze(path, top_n=args.top, out_dir=outdir)


if __name__ == "__main__":
    main_cli()
