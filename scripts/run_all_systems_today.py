from __future__ import annotations

import argparse
from collections.abc import Callable
from concurrent.futures import Future, ThreadPoolExecutor, as_completed
import logging
from pathlib import Path
from datetime import datetime
from zoneinfo import ZoneInfo
from typing import no_type_check
import os

import pandas as pd

from common import broker_alpaca as ba
from common.alpaca_order import submit_orders_df
from common.cache_manager import CacheManager, load_base_cache
from common.notifier import create_notifier
from common.position_age import load_entry_dates, save_entry_dates
from common.signal_merge import Signal, merge_signals
from common.utils_spy import get_latest_nyse_trading_day, get_spy_with_indicators
from config.settings import get_settings

# strategies
from strategies.system1_strategy import System1Strategy
from strategies.system2_strategy import System2Strategy
from strategies.system3_strategy import System3Strategy
from strategies.system4_strategy import System4Strategy
from strategies.system5_strategy import System5Strategy
from strategies.system6_strategy import System6Strategy
from strategies.system7_strategy import System7Strategy

# ãƒ¯ãƒ¼ã‚«ãƒ¼å´ã§è¦³æ¸¬ã—ãŸ cand_cnt(=TRDlist) ã‚’ä¿å­˜ã—ã€ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å‚ç…§ã™ã‚‹ãŸã‚ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
_CAND_COUNT_SNAPSHOT: dict[str, int] = {}

_LOG_CALLBACK = None
_LOG_START_TS = None  # CLI ç”¨ã®çµŒéæ™‚é–“æ¸¬å®šé–‹å§‹æ™‚åˆ»

# ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å›ºå®šãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã€‚å¿…è¦ã«å¿œã˜ã¦æ—¥ä»˜ä»˜ãã¸åˆ‡æ›¿ã€‚
_LOG_FILE_PATH: Path | None = None
_LOG_FILE_MODE: str = "single"  # single | dated


def _configure_today_logger(*, mode: str = "single", run_id: str | None = None) -> None:
    """today_signals ç”¨ã®ãƒ­ã‚¬ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ§‹æˆã™ã‚‹ã€‚

    mode:
      - "single": å›ºå®šãƒ•ã‚¡ã‚¤ãƒ« `today_signals.log`
      - "dated":  æ—¥ä»˜ä»˜ã `today_signals_YYYYMMDD_HHMM.log`ï¼ˆJSTï¼‰
    run_id: äºˆç´„ï¼ˆç¾çŠ¶æœªä½¿ç”¨ï¼‰ã€‚å°†æ¥ã€ãƒ•ã‚¡ã‚¤ãƒ«åã«å«ã‚ãŸã„å ´åˆã«åˆ©ç”¨ã€‚
    """
    global _LOG_FILE_PATH, _LOG_FILE_MODE
    _LOG_FILE_MODE = mode or "single"
    try:
        settings = get_settings(create_dirs=True)
        log_dir = Path(settings.LOGS_DIR)
    except Exception:
        log_dir = Path("logs")
    try:
        log_dir.mkdir(parents=True, exist_ok=True)
    except Exception:
        pass

    if _LOG_FILE_MODE == "dated":
        try:
            jst_now = datetime.now(ZoneInfo("Asia/Tokyo"))
        except Exception:
            jst_now = datetime.now()
        stamp = jst_now.strftime("%Y%m%d_%H%M")
        filename = f"today_signals_{stamp}.log"
    else:
        filename = "today_signals.log"

    _LOG_FILE_PATH = log_dir / filename
    # ãƒãƒ³ãƒ‰ãƒ©ã‚’æœ€æ–°ãƒ‘ã‚¹ã«åˆã‚ã›ã¦å¼µã‚Šæ›¿ãˆã‚‹
    try:
        logger = logging.getLogger("today_signals")
        for h in list(logger.handlers):
            try:
                if isinstance(h, logging.FileHandler) and getattr(h, "baseFilename", None):
                    if Path(h.baseFilename) != _LOG_FILE_PATH:
                        logger.removeHandler(h)
                        try:
                            h.close()
                        except Exception:
                            pass
            except Exception:
                # ãƒãƒ³ãƒ‰ãƒ©æƒ…å ±å–å¾—ã«å¤±æ•—ã—ãŸå ´åˆã¯ç„¡è¦–
                pass
        # ä»¥é™ã€_get_today_logger() ãŒé©åˆ‡ãªãƒãƒ³ãƒ‰ãƒ©ã‚’è¿½åŠ ã™ã‚‹
    except Exception:
        pass


def _get_today_logger() -> logging.Logger:
    """today_signals ç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ã‚¬ãƒ¼ã‚’å–å¾—ã€‚

    ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ `logs/today_signals.log`ã€‚
    `_configure_today_logger(mode="dated")` é©ç”¨æ™‚ã¯æ—¥ä»˜ä»˜ããƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ã€‚
    UI æœ‰ç„¡ã«é–¢ä¿‚ãªãã€å®Œå…¨ãªå®Ÿè¡Œãƒ­ã‚°ã‚’å¸¸ã«ãƒ•ã‚¡ã‚¤ãƒ«ã¸æ®‹ã™ã€‚
    """
    logger = logging.getLogger("today_signals")
    logger.setLevel(logging.INFO)
    # ãƒ«ãƒ¼ãƒˆãƒ­ã‚¬ãƒ¼ã¸ã®ä¼æ’­ã‚’æ­¢ã‚ã¦é‡è¤‡å‡ºåŠ›ã‚’é˜²æ­¢
    try:
        logger.propagate = False
    except Exception:
        pass
    # ãƒ«ãƒ¼ãƒˆãƒ­ã‚¬ãƒ¼ã¸ã®ä¼æ’­ã‚’æ­¢ã‚ã€ã‚³ãƒ³ã‚½ãƒ¼ãƒ«äºŒé‡å‡ºåŠ›ã‚’é˜²æ­¢
    try:
        logger.propagate = False
    except Exception:
        pass
    # ç›®æ¨™ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ±ºå®š
    try:
        # ç’°å¢ƒå¤‰æ•°ã§ã‚‚æ—¥ä»˜åˆ¥ãƒ­ã‚°æŒ‡å®šã‚’è¨±å¯ï¼ˆUI å®Ÿè¡Œãªã© main() ã‚’çµŒãªã„å ´åˆï¼‰
        if globals().get("_LOG_FILE_PATH") is None:
            try:
                import os as _os

                _mode_env = (_os.environ.get("TODAY_SIGNALS_LOG_MODE") or "").strip().lower()
                if _mode_env == "dated":
                    try:
                        _jst_now = datetime.now(ZoneInfo("Asia/Tokyo"))
                    except Exception:
                        _jst_now = datetime.now()
                    _stamp = _jst_now.strftime("%Y%m%d_%H%M")
                    try:
                        settings = get_settings(create_dirs=True)
                        _log_dir = Path(settings.LOGS_DIR)
                    except Exception:
                        _log_dir = Path("logs")
                    try:
                        _log_dir.mkdir(parents=True, exist_ok=True)
                    except Exception:
                        pass
                    globals()["_LOG_FILE_PATH"] = _log_dir / f"today_signals_{_stamp}.log"
            except Exception:
                pass

        if globals().get("_LOG_FILE_PATH") is not None:
            log_path = globals().get("_LOG_FILE_PATH")  # type: ignore[assignment]
        else:
            try:
                settings = get_settings(create_dirs=True)
                log_dir = Path(settings.LOGS_DIR)
            except Exception:
                log_dir = Path("logs")
            try:
                log_dir.mkdir(parents=True, exist_ok=True)
            except Exception:
                pass
            log_path = log_dir / "today_signals.log"
    except Exception:
        log_path = Path("logs") / "today_signals.log"

    # æ—¢å­˜ã®åŒä¸€ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãŒã‚ã‚‹ã‹ç¢ºèª
    has_handler = False
    for h in list(logger.handlers):
        try:
            if isinstance(h, logging.FileHandler):
                base = getattr(h, "baseFilename", None)
                if base:
                    if Path(base).resolve() == Path(str(log_path)).resolve():
                        has_handler = True
                        break
        except Exception:
            continue
    if not has_handler:
        try:
            fh = logging.FileHandler(str(log_path), encoding="utf-8")
            fmt = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s", "%Y-%m-%d %H:%M:%S")
            fh.setFormatter(fmt)
            logger.addHandler(fh)
        except Exception:
            pass
    return logger


def _emit_ui_log(message: str) -> None:
    """UI å´ã®ãƒ­ã‚°ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒç™»éŒ²ã•ã‚Œã¦ã„ã‚Œã°ã€ãã®ã¾ã¾æ–‡å­—åˆ—ã‚’é€ä¿¡ã™ã‚‹ã€‚"""
    try:
        cb = globals().get("_LOG_CALLBACK")
        if cb and callable(cb):
            cb(str(message))
    except Exception:
        # UI ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯æœªè¨­å®šã‚„ä¾‹å¤–ã¯é»™ã£ã¦ç„¡è¦–ï¼ˆCLI å®Ÿè¡Œæ™‚ã‚’è€ƒæ…®ï¼‰
        pass


def _log(msg: str, ui: bool = True):
    """CLI å‡ºåŠ›ã«ã¯ [HH:MM:SS | måˆ†sç§’] ã‚’ä»˜ä¸ã€‚å¿…è¦ã«å¿œã˜ã¦ UI ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’æŠ‘åˆ¶ã€‚"""
    import time as _t

    # åˆå›å‘¼ã³å‡ºã—ã§é–‹å§‹æ™‚åˆ»ã‚’è¨­å®š
    try:
        global _LOG_START_TS
        if _LOG_START_TS is None:
            _LOG_START_TS = _t.time()
    except Exception:
        _LOG_START_TS = None

    # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’ä½œæˆï¼ˆç¾åœ¨æ™‚åˆ» + åˆ†ç§’çµŒéï¼‰
    try:
        now = _t.strftime("%H:%M:%S")
        elapsed = 0 if _LOG_START_TS is None else max(0, _t.time() - _LOG_START_TS)
        m, s = divmod(int(elapsed), 60)
        prefix = f"[{now} | {m}åˆ†{s}ç§’] "
    except Exception:
        prefix = ""

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ã‚ˆã‚‹é™¤å¤–åˆ¤å®šï¼ˆå…¨ä½“ï¼‰
    try:
        if any(k in str(msg) for k in _GLOBAL_SKIP_KEYWORDS):
            return
        ui_allowed = ui and not any(k in str(msg) for k in _UI_ONLY_SKIP_KEYWORDS)
    except Exception:
        ui_allowed = ui

    # CLI ã¸ã¯æ•´å½¢ã—ã¦å‡ºåŠ›
    try:
        print(f"{prefix}{msg}", flush=True)
    except Exception:
        pass

    # UI å´ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«ã¯ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ã§é€šçŸ¥ï¼ˆUI ã§ã®é‡è¤‡ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹å›é¿ï¼‰
    if ui_allowed:
        _emit_ui_log(str(msg))

    # å¸¸ã«ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã‚‚INFOã§å‡ºåŠ›ï¼ˆUI/CLI ã®åˆ¥ãªãå®Œå…¨ãªãƒ­ã‚°ã‚’ä¿å­˜ï¼‰
    try:
        _get_today_logger().info(str(msg))
    except Exception:
        pass


def _asc_by_score_key(score_key: str | None) -> bool:
    return bool(score_key and score_key.upper() in {"RSI4"})


# ãƒ­ã‚°å‡ºåŠ›ã‹ã‚‰é™¤å¤–ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
_GLOBAL_SKIP_KEYWORDS = (
    "ãƒãƒƒãƒæ™‚é–“",
    "batch time",
)
# UI è¡¨ç¤ºã‹ã‚‰ã®ã¿é™¤å¤–ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
_UI_ONLY_SKIP_KEYWORDS = (
    "é€²æ—",
    "ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼è¨ˆç®—",
    "å€™è£œæŠ½å‡º",
    "å€™è£œæ—¥æ•°",
    "éŠ˜æŸ„:",
)


def _filter_logs(lines: list[str], ui: bool = False) -> list[str]:
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ãƒ­ã‚°è¡Œã‚’é™¤å¤–ã™ã‚‹ã€‚

    Args:
        lines: å¯¾è±¡ãƒ­ã‚°è¡Œã®ãƒªã‚¹ãƒˆã€‚
        ui: True ã®å ´åˆã¯ UI é™å®šã®é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚‚é©ç”¨ã€‚
    """

    skip_keywords = _GLOBAL_SKIP_KEYWORDS + (_UI_ONLY_SKIP_KEYWORDS if ui else ())
    return [ln for ln in lines if not any(k in ln for k in skip_keywords)]


def _amount_pick(
    per_system: dict[str, pd.DataFrame],
    strategies: dict[str, object],
    total_budget: float,
    weights: dict[str, float],
    side: str,
) -> pd.DataFrame:
    """è³‡é‡‘é…åˆ†ã«åŸºã¥ã„ã¦å€™è£œã‚’æ¡ç”¨ã€‚
    shares ã¨ position_value ã‚’ä»˜ä¸ã—ã¦è¿”ã™ã€‚
    """
    chosen = []
    chosen_symbols = set()

    # ã‚·ã‚¹ãƒ†ãƒ ã”ã¨ã®å‰²å½“äºˆç®—
    budgets = {
        name: float(total_budget) * float(weights.get(name, 0.0)) for name in weights
    }  # noqa: E501
    remaining = budgets.copy()

    # ã‚·ã‚¹ãƒ†ãƒ åã®é †åºã‚’å›ºå®šï¼ˆsystem1..system7ï¼‰
    sys_order = [f"system{i}" for i in range(1, 8)]
    ordered_names = [n for n in sys_order if n in weights]
    # å„ã‚·ã‚¹ãƒ†ãƒ ã®æœ€å¤§ãƒã‚¸ã‚·ãƒ§ãƒ³ä¸Šé™ï¼ˆè¨­å®š max_positionsã€æ—¢å®š10ï¼‰ã¨æ¡ç”¨ã‚«ã‚¦ãƒ³ã‚¿
    max_pos_by_system: dict[str, int] = {}
    for _n in ordered_names:
        try:
            _stg = strategies.get(_n)
            _lim = int(getattr(_stg, "config", {}).get("max_positions", 10))
        except Exception:
            _lim = 10
        max_pos_by_system[_n] = max(0, _lim)
    count_by_system: dict[str, int] = {k: 0 for k in ordered_names}
    # ã‚·ã‚¹ãƒ†ãƒ ã”ã¨ã«ã‚¹ã‚³ã‚¢é †ã§æ¡ç”¨ã€‚è¤‡æ•°å‘¨å›ã—ã¦1ä»¶ãšã¤æ‹¾ã†ï¼ˆåã‚Šã‚’è»½æ¸›ï¼‰
    still = True
    while still:
        still = False
        for name in ordered_names:
            df = per_system.get(name, pd.DataFrame())
            if (
                df is None
                or df.empty
                or remaining.get(name, 0.0) <= 0.0
                or count_by_system.get(name, 0) >= max_pos_by_system.get(name, 0)
            ):
                continue
            stg = strategies[name]
            # é †ã«æ¢ç´¢
            for _, row in df.iterrows():
                sym = row["symbol"]
                if sym in chosen_symbols:
                    continue
                entry = (
                    float(row["entry_price"])
                    if not pd.isna(row.get("entry_price"))
                    else None  # noqa: E501
                )
                stop = (
                    float(row["stop_price"])
                    if not pd.isna(row.get("stop_price"))
                    else None  # noqa: E501
                )
                if not entry or not stop or entry <= 0:
                    continue

                # æœ›ã¾ã—ã„æšæ•°ï¼ˆå…¨ã‚·ã‚¹ãƒ†ãƒ å‰²å½“åŸºæº–ï¼‰
                try:
                    # stg may be typed as object; call via cast to avoid
                    # static type errors. Call calculate_position_size if available.
                    calc_fn = getattr(stg, "calculate_position_size", None)
                    if callable(calc_fn):
                        try:
                            ds = calc_fn(
                                budgets[name],
                                entry,
                                stop,
                                risk_pct=float(
                                    getattr(stg, "config", {}).get("risk_pct", 0.02)
                                ),  # noqa: E501
                                max_pct=float(
                                    getattr(stg, "config", {}).get("max_pct", 0.10)
                                ),  # noqa: E501
                            )
                            if ds is None:
                                desired_shares = 0
                            else:
                                try:
                                    if isinstance(ds, (int | float | str)):
                                        try:
                                            desired_shares = int(float(ds))
                                        except Exception:
                                            desired_shares = 0
                                    else:
                                        desired_shares = 0
                                except Exception:
                                    desired_shares = 0
                        except Exception:
                            desired_shares = 0
                    else:
                        desired_shares = 0
                except Exception:
                    desired_shares = 0
                if desired_shares <= 0:
                    continue

                # äºˆç®—å†…ã«åã¾ã‚‹ã‚ˆã†èª¿æ•´
                max_by_cash = int(remaining[name] // abs(entry))
                shares = min(desired_shares, max_by_cash)
                if shares <= 0:
                    continue
                position_value = shares * abs(entry)
                if position_value <= 0:
                    continue

                # æ¡ç”¨
                rec = row.to_dict()
                rec["shares"] = int(shares)
                rec["position_value"] = float(round(position_value, 2))
                # æ¡ç”¨ç›´å‰ã®æ®‹ä½™ã‚’ system_budget ã«è¡¨ç¤ºï¼ˆè¦‹ãŸç›®ãŒæ¸›ã£ã¦ã„ãï¼‰
                rec["system_budget"] = float(round(remaining[name], 2))
                rec["remaining_after"] = float(round(remaining[name] - position_value, 2))
                chosen.append(rec)
                chosen_symbols.add(sym)
                remaining[name] -= position_value
                count_by_system[name] = count_by_system.get(name, 0) + 1
                still = True
                break  # 1ä»¶ãšã¤æ‹¾ã£ã¦æ¬¡ã®ã‚·ã‚¹ãƒ†ãƒ ã¸

    if not chosen:
        return pd.DataFrame()
    out = pd.DataFrame(chosen)
    out["side"] = side
    return out


def _submit_orders(
    final_df: pd.DataFrame,
    *,
    paper: bool = True,
    order_type: str = "market",
    tif: str = "GTC",
    retries: int = 2,
    delay: float = 0.5,
) -> pd.DataFrame:
    """final_df ã‚’ã‚‚ã¨ã« Alpaca ã¸æ³¨æ–‡é€ä¿¡ï¼ˆshares å¿…é ˆï¼‰ã€‚
    è¿”ã‚Šå€¤: å®Ÿè¡Œçµæœã® DataFrameï¼ˆorder_id/status/error ã‚’å«ã‚€ï¼‰
    """
    if final_df is None or final_df.empty:
        _log("(submit) final_df is empty; skip")
        return pd.DataFrame()
    if "shares" not in final_df.columns:
        _log("(submit) shares åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚" "è³‡é‡‘é…åˆ†ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return pd.DataFrame()
    try:
        client = ba.get_client(paper=paper)
    except Exception as e:
        _log(f"(submit) Alpacaæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return pd.DataFrame()

    results = []
    for _, r in final_df.iterrows():
        sym = str(r.get("symbol"))
        qty = int(r.get("shares") or 0)
        side = "buy" if str(r.get("side")).lower() == "long" else "sell"
        system = str(r.get("system"))
        entry_date = r.get("entry_date")
        if not sym or qty <= 0:
            continue
        # safely parse limit price
        limit_price = None
        if order_type == "limit":
            try:
                val = r.get("entry_price")
                if val is not None and val != "":
                    limit_price = float(val)
            except Exception:
                limit_price = None
        # estimate price for notification purposes
        price_val = None
        try:
            val = r.get("entry_price")
            if val is not None and val != "":
                price_val = float(val)
        except Exception:
            price_val = None
        if limit_price is not None:
            price_val = limit_price
        try:
            order = ba.submit_order_with_retry(
                client,
                sym,
                qty,
                side=side,
                order_type=order_type,
                limit_price=limit_price,
                time_in_force=tif,
                retries=max(0, int(retries)),
                backoff_seconds=max(0.0, float(delay)),
                rate_limit_seconds=max(0.0, float(delay)),
                log_callback=_log,
            )
            results.append(
                {
                    "symbol": sym,
                    "side": side,
                    "qty": qty,
                    "price": price_val,
                    "system": system,
                    "entry_date": entry_date,
                    # Streamlit/Arrow äº’æ›ã®ãŸã‚ UUID ã‚’æ–‡å­—åˆ—åŒ–
                    "order_id": (
                        str(getattr(order, "id", ""))
                        if getattr(order, "id", None) is not None
                        else ""
                    ),
                    "status": getattr(order, "status", None),
                }
            )
        except Exception as e:
            results.append(
                {
                    "symbol": sym,
                    "side": side,
                    "qty": qty,
                    "price": price_val,
                    "system": system,
                    "entry_date": entry_date,
                    "error": str(e),
                }
            )
    if results:
        out = pd.DataFrame(results)
        # å¿µã®ãŸã‚ order_id åˆ—ãŒå­˜åœ¨ã™ã‚Œã°æ–‡å­—åˆ—åŒ–ï¼ˆä»–çµŒè·¯ã§ UUID å‹ãŒæ··ã˜ã‚‹ã®ã‚’é˜²ãï¼‰
        try:
            if "order_id" in out.columns:
                out["order_id"] = out["order_id"].apply(
                    lambda x: str(x) if x not in (None, "") else ""
                )
        except Exception:
            pass
        _log("\n=== Alpaca submission results ===")
        _log(out.to_string(index=False))
        # record entry dates for future day-based rules
        entry_map = load_entry_dates()
        for _, row in out.iterrows():
            sym = str(row.get("symbol"))
            side_val = str(row.get("side", "")).lower()
            if side_val == "buy" and row.get("entry_date"):
                entry_map[sym] = str(row["entry_date"])
            elif side_val == "sell":
                entry_map.pop(sym, None)
        save_entry_dates(entry_map)
        notifier = create_notifier(platform="auto", fallback=True)
        notifier.send_trade_report("integrated", results)
        return out
    return pd.DataFrame()


def _apply_filters(
    df: pd.DataFrame,
    *,
    only_long: bool = False,
    only_short: bool = False,
    top_per_system: int = 0,
) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    out = df.copy()
    if "side" in out.columns:
        if only_long and not only_short:
            out = out[out["side"].str.lower() == "long"]
        if only_short and not only_long:
            out = out[out["side"].str.lower() == "short"]
    if top_per_system and top_per_system > 0 and "system" in out.columns:
        by = ["system"] + (["side"] if "side" in out.columns else [])
        out = out.groupby(by, as_index=False, group_keys=False).head(
            int(top_per_system)
        )  # noqa: E501
    return out


@no_type_check
def compute_today_signals(
    symbols: list[str] | None,
    *,
    slots_long: int | None = None,
    slots_short: int | None = None,
    capital_long: float | None = None,
    capital_short: float | None = None,
    save_csv: bool = False,
    csv_name_mode: str | None = None,
    notify: bool = True,
    log_callback: Callable[[str], None] | None = None,
    progress_callback: Callable[[int, int, str], None] | None = None,
    # è¿½åŠ : ä¸¦åˆ—å®Ÿè¡Œæ™‚ãªã©ã« system ã”ã¨ã®é–‹å§‹/å®Œäº†ã‚’é€šçŸ¥ã™ã‚‹è»½é‡ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    # phase ã¯ "start" | "done" ã‚’æƒ³å®š
    per_system_progress: Callable[[str, str], None] | None = None,
    symbol_data: dict[str, pd.DataFrame] | None = None,
    parallel: bool = False,
) -> tuple[pd.DataFrame, dict[str, pd.DataFrame]]:
    """å½“æ—¥ã‚·ã‚°ãƒŠãƒ«æŠ½å‡ºï¼‹é…åˆ†ã®æœ¬ä½“ã€‚

    Args:
        symbols: å¯¾è±¡ã‚·ãƒ³ãƒœãƒ«ãƒªã‚¹ãƒˆã€‚
        parallel: True ã®å ´åˆã¯ã‚·ã‚¹ãƒ†ãƒ ã”ã¨ã®ã‚·ã‚°ãƒŠãƒ«æŠ½å‡ºã‚’ä¸¦è¡Œå®Ÿè¡Œã™ã‚‹ã€‚

    æˆ»ã‚Šå€¤: (final_df, per_system_df_dict)
    """
    # CLI çµŒç”±ã§æœªè¨­å®šã®å ´åˆï¼ˆUI ç­‰ï¼‰ã€æ—¢å®šã§æ—¥ä»˜åˆ¥ãƒ­ã‚°ã«åˆ‡æ›¿
    try:
        if globals().get("_LOG_FILE_PATH") is None:
            import os as _os

            _mode_env = (_os.environ.get("TODAY_SIGNALS_LOG_MODE") or "").strip().lower()
            _configure_today_logger(mode=("single" if _mode_env == "single" else "dated"))
    except Exception:
        pass
    # === CLI ãƒãƒŠãƒ¼ï¼ˆé–‹å§‹ã®æ˜ç¢ºåŒ–ï¼‰: RUN-ID ã®ã¿äº‹å‰ç”Ÿæˆ ===
    try:
        import uuid as _uuid

        _run_id = str(_uuid.uuid4())[:8]
    except Exception:
        _run_id = "--------"

    settings = get_settings(create_dirs=True)
    cm = CacheManager(settings)
    # install log callback for helpers
    globals()["_LOG_CALLBACK"] = log_callback
    cache_dir = cm.rolling_dir
    signals_dir = Path(settings.outputs.signals_dir)
    signals_dir.mkdir(parents=True, exist_ok=True)

    # å‰å›çµæœã®ä¿å­˜/èª­è¾¼ãƒ˜ãƒ«ãƒ‘
    def _prev_counts_path() -> Path:
        try:
            return signals_dir / "previous_per_system_counts.json"
        except Exception:
            return Path("signals/previous_per_system_counts.json")

    def _load_prev_counts() -> dict[str, int]:
        fp = _prev_counts_path()
        if not fp.exists():
            return {}
        try:
            import json as _json

            data = _json.loads(fp.read_text(encoding="utf-8"))
            counts = data.get("counts", {}) if isinstance(data, dict) else {}
            out: dict[str, int] = {}
            for i in range(1, 8):
                k = f"system{i}"
                try:
                    out[k] = int(counts.get(k, 0))
                except Exception:
                    out[k] = 0
            return out
        except Exception:
            return {}

    def _save_prev_counts(per_system_map: dict[str, pd.DataFrame]) -> None:
        try:
            from datetime import datetime as _dt
            import json as _json

            counts = {
                k: (0 if (v is None or v.empty) else int(len(v))) for k, v in per_system_map.items()
            }
            data = {"timestamp": _dt.utcnow().isoformat() + "Z", "counts": counts}
            fp = _prev_counts_path()
            try:
                fp.parent.mkdir(parents=True, exist_ok=True)
            except Exception:
                pass
            fp.write_text(_json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
        except Exception:
            pass

    # CLIå®Ÿè¡Œæ™‚ã®Streamlitè­¦å‘Šã‚’æŠ‘åˆ¶ï¼ˆUIã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒç„¡ã„å ´åˆã®ã¿ï¼‰
    try:
        import logging as _lg
        import os as _os

        if not _os.environ.get("STREAMLIT_SERVER_ENABLED"):

            class _SilenceBareModeWarnings(_lg.Filter):
                def filter(self, record: _lg.LogRecord) -> bool:  # type: ignore[override]
                    msg = str(record.getMessage())
                    if "missing ScriptRunContext" in msg:
                        return False
                    if "Session state does not function" in msg:
                        return False
                    return True

            _names = [
                "streamlit",
                "streamlit.runtime",
                "streamlit.runtime.scriptrunner_utils.script_run_context",
                "streamlit.runtime.state.session_state_proxy",
            ]
            for _name in _names:
                _logger = _lg.getLogger(_name)
                _logger.addFilter(_SilenceBareModeWarnings())
                try:
                    _logger.setLevel(_lg.ERROR)
                except Exception:
                    pass
    except Exception:
        pass

    # æœ€æ–°å–¶æ¥­æ—¥ï¼ˆNYSEï¼‰
    today = get_latest_nyse_trading_day().normalize()
    _log(f"ğŸ“… æœ€æ–°å–¶æ¥­æ—¥ï¼ˆNYSEï¼‰: {today.date()}")
    _log("â„¹ï¸ æ³¨: EODHDã¯å½“æ—¥çµ‚å€¤ãŒæœªåæ˜ ã®ãŸã‚ã€ç›´è¿‘å–¶æ¥­æ—¥ãƒ™ãƒ¼ã‚¹ã§è¨ˆç®—ã—ã¾ã™ã€‚")
    # é–‹å§‹ç›´å¾Œã«å‰å›çµæœã‚’ã¾ã¨ã‚ã¦è¡¨ç¤º
    try:
        prev = _load_prev_counts()
        if prev:
            for i in range(1, 8):
                key = f"system{i}"
                v = int(prev.get(key, 0))
                icon = "âœ…" if v > 0 else "âŒ"
                _log(f"ğŸ§¾ {icon} (å‰å›çµæœ) {key}: {v} ä»¶{' ğŸš«' if v == 0 else ''}")
    except Exception:
        pass
    if progress_callback:
        try:
            progress_callback(0, 8, "init")
        except Exception:
            pass

    # ã‚·ãƒ³ãƒœãƒ«æ±ºå®š
    if symbols and len(symbols) > 0:
        symbols = [s.upper() for s in symbols]
    else:
        from common.universe import build_universe_from_cache, load_universe_file

        universe = load_universe_file()
        if not universe:
            universe = build_universe_from_cache(limit=None)
        symbols = [s.upper() for s in universe]
        if not symbols:
            try:
                files = list(cache_dir.glob("*.*"))
                primaries = [p.stem for p in files if p.stem.upper() == "SPY"]
                others = sorted({p.stem for p in files if len(p.stem) <= 5})[:200]
                symbols = list(dict.fromkeys(primaries + others))
            except Exception:
                symbols = []
    if "SPY" not in symbols:
        symbols.append("SPY")

    # ãƒãƒŠãƒ¼ï¼ˆé–‹å§‹ï¼‰: ç½«ç·šã¯ print ã§å‡ºåŠ›ã—ã¦ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä»˜ã‘ãªã„
    try:
        print("#" * 68, flush=True)
    except Exception:
        pass
    # CLI å°‚ç”¨ã®é–‹å§‹ãƒãƒŠãƒ¼ï¼ˆUI ã«ã¯å‡ºã•ãªã„ï¼‰
    _log("# ğŸš€ğŸš€ğŸš€  æœ¬æ—¥ã®ã‚·ã‚°ãƒŠãƒ« å®Ÿè¡Œé–‹å§‹ (Engine)  ğŸš€ğŸš€ğŸš€", ui=False)
    try:
        import time as _time

        _now = _time.strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        _now = ""
    try:
        universe_total = sum(1 for s in symbols if str(s).upper() != "SPY")
    except Exception:
        universe_total = len(symbols)
    _log(
        f"# â±ï¸ {_now} | éŠ˜æŸ„æ•°ï¼š{universe_total}ã€€| RUN-ID: {_run_id}",
        ui=False,
    )
    try:
        print("#" * 68 + "\n", flush=True)
    except Exception:
        pass

    _log(
        f"ğŸ¯ å¯¾è±¡ã‚·ãƒ³ãƒœãƒ«æ•°: {len(symbols)}"
        f"ï¼ˆä¾‹: {', '.join(symbols[:10])}"
        f"{'...' if len(symbols) > 10 else ''}ï¼‰"
    )
    if log_callback:
        try:
            log_callback("ğŸ§­ ã‚·ãƒ³ãƒœãƒ«æ±ºå®šå®Œäº†ã€‚åŸºç¤ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ã¸â€¦")
        except Exception:
            pass
    if progress_callback:
        try:
            # ç›´å¾Œã«åŸºç¤ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã™ã‚‹ãŸã‚ã€ãƒ•ã‚§ãƒ¼ã‚ºåã‚’æ˜ç¢ºåŒ–
            progress_callback(1, 8, "å¯¾è±¡èª­ã¿è¾¼ã¿:start")
        except Exception:
            pass

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    # --- ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã§éŠ˜æŸ„ã‚’çµã‚Šè¾¼ã¿ã€
    #     é€šééŠ˜æŸ„ã®ã¿ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ ---
    # 1. ã¾ãšãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿
    #    ï¼ˆæ ªä¾¡ãƒ»å£²è²·ä»£é‡‘ãƒ»ATRç­‰ï¼‰ã‚’å…¨éŠ˜æŸ„åˆ†ãƒ­ãƒ¼ãƒ‰
    # --- ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰é–¢æ•°ã‚’
    #     ãƒ­ãƒ¼ã‚«ãƒ«é–¢æ•°ã¨ã—ã¦å®šç¾© ---

    def load_basic_data(symbols):
        import time as _t

        data = {}
        total_syms = len(symbols)
        start_ts = _t.time()
        CHUNK = 500
        for idx, sym in enumerate(symbols, start=1):
            try:
                # ã¾ãšã¯å‘¼ã³å‡ºã—å…ƒã‹ã‚‰æ¸¡ã•ã‚ŒãŸ minimal ãƒ‡ãƒ¼ã‚¿ã‚’å„ªå…ˆ
                df = None
                try:
                    if symbol_data and sym in symbol_data:
                        df = symbol_data.get(sym)
                        if df is not None and not df.empty:
                            x = df.copy()
                            if x.index.name is not None:
                                x = x.reset_index()
                            # æ—¥ä»˜åˆ—ã®æ­£è¦åŒ–
                            if "date" in x.columns:
                                x["date"] = pd.to_datetime(x["date"], errors="coerce")
                            elif "Date" in x.columns:
                                x["date"] = pd.to_datetime(x["Date"], errors="coerce")
                            # åˆ—åã®æ­£è¦åŒ–ï¼ˆå­˜åœ¨ã™ã‚‹ã‚‚ã®ã®ã¿ï¼‰
                            col_map = {
                                "Open": "open",
                                "High": "high",
                                "Low": "low",
                                "Close": "close",
                                "Adj Close": "adjusted_close",
                                "AdjClose": "adjusted_close",
                                "Volume": "volume",
                            }
                            for k, v in list(col_map.items()):
                                if k in x.columns:
                                    x = x.rename(columns={k: v})
                            # æœ€ä½é™ã®å¿…é ˆåˆ—ãŒæƒã£ã¦ã„ã‚‹ã‹ç¢ºèª
                            required = {"date", "close"}
                            if required.issubset(set(x.columns)):
                                x = x.dropna(subset=["date"]).sort_values("date")
                                df = x
                            else:
                                df = None
                        else:
                            df = None
                except Exception:
                    df = None
                # å—ã‘å–ã‚ŠãŒç„¡ã„/ä¸è¶³ â†’ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
                if df is None or df.empty:
                    df = cm.read(sym, "rolling")
                # æ—¢å­˜ rolling ãŒã‚ã£ã¦ã‚‚è¡Œæ•°ä¸è¶³ãªã‚‰å†æ§‹ç¯‰ã™ã‚‹
                target_len = int(
                    settings.cache.rolling.base_lookback_days + settings.cache.rolling.buffer_days
                )
                if df is None or df.empty or (hasattr(df, "__len__") and len(df) < target_len):
                    # rolling ä¸åœ¨ â†’ base ã‹ã‚‰å¿…è¦åˆ†ã‚’ç”Ÿæˆã—ã¦ä¿å­˜
                    base_df = load_base_cache(sym, rebuild_if_missing=True)
                    if base_df is None or base_df.empty:
                        continue
                    x = base_df.copy()
                    if x.index.name is not None:
                        x = x.reset_index()
                    if "Date" in x.columns:
                        x["date"] = pd.to_datetime(x["Date"], errors="coerce")
                    elif "date" in x.columns:
                        x["date"] = pd.to_datetime(x["date"], errors="coerce")
                    else:
                        continue
                    x = x.dropna(subset=["date"]).sort_values("date")
                    # åˆ—åã‚’ rolling æƒ³å®šã¸ï¼ˆå­˜åœ¨ã™ã‚‹ã‚‚ã®ã®ã¿ï¼‰
                    col_map = {
                        "Open": "open",
                        "High": "high",
                        "Low": "low",
                        "Close": "close",
                        "AdjClose": "adjusted_close",
                        "Volume": "volume",
                    }
                    for k, v in list(col_map.items()):
                        if k in x.columns:
                            x = x.rename(columns={k: v})
                    # å¿…è¦æœŸé–“: è¨­è¨ˆä¸Š base_lookback_days + buffer_daysï¼ˆä¸è¶³æ™‚ã¯å…¨é‡ï¼‰
                    n = int(
                        settings.cache.rolling.base_lookback_days
                        + settings.cache.rolling.buffer_days
                    )
                    sliced = x.tail(n).reset_index(drop=True)
                    cm.write_atomic(sliced, sym, "rolling")
                    df = sliced
                if df is not None and not df.empty:
                    try:
                        if "Date" not in df.columns:
                            if "date" in df.columns:
                                df = df.copy()
                                df["Date"] = pd.to_datetime(df["date"], errors="coerce")
                            else:
                                # æœ€ä½é™ index ã‚’ Date åˆ—ã«æ˜‡æ ¼
                                df = df.copy()
                                df["Date"] = pd.to_datetime(df.index, errors="coerce")
                        # æ­£è¦åŒ–ï¼ˆè¡¨ç¤º/äº’æ›æ€§å‘ä¸Šï¼‰
                        df["Date"] = pd.to_datetime(df["Date"], errors="coerce").dt.normalize()
                    except Exception:
                        pass
                    df = _normalize_ohlcv(df)
                    data[sym] = df
            except Exception:
                continue
            if idx % CHUNK == 0:
                try:
                    elapsed = max(0.001, _t.time() - start_ts)
                    rate = idx / elapsed
                    remain = max(0, total_syms - idx)
                    eta_sec = int(remain / rate) if rate > 0 else 0
                    m, s = divmod(eta_sec, 60)
                    msg = f"ğŸ“¦ åŸºç¤ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰é€²æ—: {idx}/{total_syms} | ETA {m}åˆ†{s}ç§’"
                    _log(msg, ui=False)
                    _emit_ui_log(msg)
                except Exception:
                    _log(f"ğŸ“¦ åŸºç¤ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰é€²æ—: {idx}/{total_syms}", ui=False)
                    _emit_ui_log(f"ğŸ“¦ åŸºç¤ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰é€²æ—: {idx}/{total_syms}")
        try:
            total_elapsed = int(max(0, _t.time() - start_ts))
            m, s = divmod(total_elapsed, 60)
            done_msg = f"ğŸ“¦ åŸºç¤ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(data)}/{total_syms} | æ‰€è¦ {m}åˆ†{s}ç§’"
            _log(done_msg)
            _emit_ui_log(done_msg)
        except Exception:
            _log(f"ğŸ“¦ åŸºç¤ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(data)}/{total_syms}")
            _emit_ui_log(f"ğŸ“¦ åŸºç¤ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(data)}/{total_syms}")
        return data

    # åˆ—åã®å¤§å°ãƒ»é‡è¤‡ï¼ˆDataFrameï¼‰ã«ã‚‚è€ãˆã‚‹å®‰å…¨ãªæŠ½å‡ºãƒ˜ãƒ«ãƒ‘ãƒ¼
    def _pick_series(df, names):
        try:
            for nm in names:
                if nm in df.columns:
                    s = df[nm]
                    # é‡è¤‡åˆ—ã§ DataFrame ã«ãªã‚‹å ´åˆã¯å…ˆé ­åˆ—ã‚’æ¡ç”¨
                    if isinstance(s, pd.DataFrame):
                        try:
                            s = s.iloc[:, 0]
                        except Exception:
                            continue
                    # æ•°å€¤åŒ–ï¼ˆå¤±æ•—ã¯ NaNï¼‰
                    try:
                        s = pd.to_numeric(s, errors="coerce")
                    except Exception:
                        pass
                    return s
        except Exception:
            pass
        return None

    def _last_scalar(series):
        try:
            if series is None:
                return None
            s2 = series.dropna()
            if s2.empty:
                return None
            return float(s2.iloc[-1])
        except Exception:
            return None

    def _normalize_ohlcv(df: pd.DataFrame) -> pd.DataFrame:
        """åˆ—åã‚’å¤§æ–‡å­—OHLCVã«çµ±ä¸€"""
        col_map = {
            "open": "Open",
            "high": "High",
            "low": "Low",
            "close": "Close",
            "volume": "Volume",
            "adj_close": "AdjClose",
            "adjusted_close": "AdjClose",
        }
        try:
            return df.rename(columns={k: v for k, v in col_map.items() if k in df.columns})
        except Exception:
            return df

    def filter_system1(symbols, data):
        result = []
        for sym in symbols:
            df = data.get(sym)
            if df is None or df.empty:
                continue
            # æ ªä¾¡5ãƒ‰ãƒ«ä»¥ä¸Šï¼ˆç›´è¿‘çµ‚å€¤ï¼‰
            close_s = _pick_series(df, ["close", "Close", "Adj Close", "adj_close"])
            last_close = _last_scalar(close_s)
            if last_close is None or last_close < 5:
                continue
            # éå»20æ—¥å¹³å‡å£²è²·ä»£é‡‘ï¼ˆå³å¯†: mean(close*volume)ï¼‰ãŒ5000ä¸‡ãƒ‰ãƒ«ä»¥ä¸Š
            vol_s = _pick_series(df, ["volume", "Volume", "Vol", "vol"])
            if vol_s is None or close_s is None:
                continue
            try:
                dollar_vol = (close_s * vol_s).dropna()
            except Exception:
                continue
            if dollar_vol.tail(20).mean() < 5e7:
                continue
            result.append(sym)
        return result

    def filter_system2(symbols, data):
        result = []
        for sym in symbols:
            df = data.get(sym)
            if df is None or df.empty:
                continue
            close_s = _pick_series(df, ["close", "Close", "Adj Close", "adj_close"])
            last_close = _last_scalar(close_s)
            if last_close is None or last_close < 5:
                continue
            vol_s = _pick_series(df, ["volume", "Volume", "Vol", "vol"])
            if vol_s is None or close_s is None:
                continue
            try:
                dollar_vol = (close_s * vol_s).dropna()
            except Exception:
                continue
            if dollar_vol.tail(20).mean() < 2.5e7:
                continue
            # ATRè¨ˆç®—ï¼ˆéå»10æ—¥ï¼‰
            high_s = _pick_series(df, ["high", "High"]) if df is not None else None
            low_s = _pick_series(df, ["low", "Low"]) if df is not None else None
            if high_s is not None and low_s is not None and close_s is not None:
                try:
                    tr = (high_s - low_s).dropna().tail(10)
                    atr = tr.mean()
                except Exception:
                    atr = None
                if atr is not None and atr < (last_close * 0.03):
                    continue
            result.append(sym)
        return result

    def filter_system3(symbols, data):
        result = []
        for sym in symbols:
            df = data.get(sym)
            if df is None or df.empty:
                continue
            low = df.get("Low", df.get("low"))
            if low is None or float(low.iloc[-1]) < 1:
                continue
            av50 = df.get("AvgVolume50")
            if av50 is None or pd.isna(av50.iloc[-1]) or float(av50.iloc[-1]) < 1_000_000:
                continue
            atr_ratio = df.get("ATR_Ratio")
            if atr_ratio is None or pd.isna(atr_ratio.iloc[-1]) or float(atr_ratio.iloc[-1]) < 0.05:
                continue
            result.append(sym)
        return result

    def filter_system4(symbols, data):
        result = []
        for sym in symbols:
            df = data.get(sym)
            if df is None or df.empty:
                continue
            dv50 = df.get("DollarVolume50")
            hv50 = df.get("HV50")
            try:
                if dv50 is None or pd.isna(dv50.iloc[-1]) or float(dv50.iloc[-1]) <= 100_000_000:
                    continue
                if hv50 is None or pd.isna(hv50.iloc[-1]):
                    continue
                hv = float(hv50.iloc[-1])
                if hv < 10 or hv > 40:
                    continue
            except Exception:
                continue
            result.append(sym)
        return result

    def filter_system5(symbols, data):
        result = []
        for sym in symbols:
            df = data.get(sym)
            if df is None or df.empty:
                continue
            av50 = df.get("AvgVolume50")
            dv50 = df.get("DollarVolume50")
            atr_pct = df.get("ATR_Pct")
            try:
                if av50 is None or pd.isna(av50.iloc[-1]) or float(av50.iloc[-1]) <= 500_000:
                    continue
                if dv50 is None or pd.isna(dv50.iloc[-1]) or float(dv50.iloc[-1]) <= 2_500_000:
                    continue
                if atr_pct is None or pd.isna(atr_pct.iloc[-1]) or float(atr_pct.iloc[-1]) <= 0.04:
                    continue
            except Exception:
                continue
            result.append(sym)
        return result

    def filter_system6(symbols, data):
        result = []
        for sym in symbols:
            df = data.get(sym)
            if df is None or df.empty:
                continue
            low = df.get("Low", df.get("low"))
            if low is None or float(low.iloc[-1]) < 5:
                continue
            dv50 = df.get("DollarVolume50")
            if dv50 is None or pd.isna(dv50.iloc[-1]) or float(dv50.iloc[-1]) <= 10_000_000:
                continue
            result.append(sym)
        return result

    def load_indicator_data(symbols):
        import time as _t

        data = {}
        total_syms = len(symbols)
        start_ts = _t.time()
        CHUNK = 500
        for idx, sym in enumerate(symbols, start=1):
            try:
                # æä¾›ã•ã‚ŒãŸ minimal ãƒ‡ãƒ¼ã‚¿ã‚’å„ªå…ˆ
                df = None
                try:
                    if symbol_data and sym in symbol_data:
                        df = symbol_data.get(sym)
                        if df is not None and not df.empty:
                            x = df.copy()
                            if x.index.name is not None:
                                x = x.reset_index()
                            if "date" in x.columns:
                                x["date"] = pd.to_datetime(x["date"], errors="coerce")
                            elif "Date" in x.columns:
                                x["date"] = pd.to_datetime(x["Date"], errors="coerce")
                            col_map = {
                                "Open": "open",
                                "High": "high",
                                "Low": "low",
                                "Close": "close",
                                "Adj Close": "adjusted_close",
                                "AdjClose": "adjusted_close",
                                "Volume": "volume",
                            }
                            for k, v in list(col_map.items()):
                                if k in x.columns:
                                    x = x.rename(columns={k: v})
                            required = {"date", "close"}
                            if required.issubset(set(x.columns)):
                                x = x.dropna(subset=["date"]).sort_values("date")
                                df = x
                            else:
                                df = None
                        else:
                            df = None
                except Exception:
                    df = None
                if df is None or df.empty:
                    df = cm.read(sym, "rolling")
                target_len = int(
                    settings.cache.rolling.base_lookback_days + settings.cache.rolling.buffer_days
                )
                if df is None or df.empty or (hasattr(df, "__len__") and len(df) < target_len):
                    base_df = load_base_cache(sym, rebuild_if_missing=True)
                    if base_df is None or base_df.empty:
                        continue
                    x = base_df.copy()
                    if x.index.name is not None:
                        x = x.reset_index()
                    if "Date" in x.columns:
                        x["date"] = pd.to_datetime(x["Date"], errors="coerce")
                    elif "date" in x.columns:
                        x["date"] = pd.to_datetime(x["date"], errors="coerce")
                    else:
                        continue
                    x = x.dropna(subset=["date"]).sort_values("date")
                    col_map = {
                        "Open": "open",
                        "High": "high",
                        "Low": "low",
                        "Close": "close",
                        "AdjClose": "adjusted_close",
                        "Volume": "volume",
                    }
                    for k, v in list(col_map.items()):
                        if k in x.columns:
                            x = x.rename(columns={k: v})
                    n = int(
                        settings.cache.rolling.base_lookback_days
                        + settings.cache.rolling.buffer_days
                    )
                    sliced = x.tail(n).reset_index(drop=True)
                    cm.write_atomic(sliced, sym, "rolling")
                    df = sliced
                if df is not None and not df.empty:
                    try:
                        if "Date" not in df.columns:
                            if "date" in df.columns:
                                df = df.copy()
                                df["Date"] = pd.to_datetime(df["date"], errors="coerce")
                            else:
                                df = df.copy()
                                df["Date"] = pd.to_datetime(df.index, errors="coerce")
                        df["Date"] = pd.to_datetime(df["Date"], errors="coerce").dt.normalize()
                    except Exception:
                        pass
                    df = _normalize_ohlcv(df)
                    data[sym] = df
            except Exception:
                continue
            if total_syms > 0 and idx % CHUNK == 0:
                try:
                    elapsed = max(0.001, _t.time() - start_ts)
                    rate = idx / elapsed
                    remain = max(0, total_syms - idx)
                    eta_sec = int(remain / rate) if rate > 0 else 0
                    m, s = divmod(eta_sec, 60)
                    msg = f"ğŸ§® æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰é€²æ—: {idx}/{total_syms} | ETA {m}åˆ†{s}ç§’"
                    _log(msg, ui=False)
                    _emit_ui_log(msg)
                except Exception:
                    _log(f"ğŸ§® æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰é€²æ—: {idx}/{total_syms}", ui=False)
                    _emit_ui_log(f"ğŸ§® æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰é€²æ—: {idx}/{total_syms}")
        try:
            total_elapsed = int(max(0, _t.time() - start_ts))
            m, s = divmod(total_elapsed, 60)
            done_msg = f"ğŸ§® æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(data)}/{total_syms} | æ‰€è¦ {m}åˆ†{s}ç§’"
            _log(done_msg)
            _emit_ui_log(done_msg)
        except Exception:
            _log(f"ğŸ§® æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(data)}/{total_syms}")
            _emit_ui_log(f"ğŸ§® æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(data)}/{total_syms}")
        return data

    # å®Ÿè¡Œã‚¹ã‚³ãƒ¼ãƒ—ã§å¤‰æ•°å®šç¾©
    # --- ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å¤‰æ•°ã‚’
    #     forãƒ«ãƒ¼ãƒ—ã‚ˆã‚Šå‰ã«å®šç¾© ---
    basic_data = load_basic_data(symbols)
    if progress_callback:
        try:
            progress_callback(2, 8, "load_basic")
        except Exception:
            pass
    # ãƒ‡ãƒ¼ã‚¿ã‚«ãƒãƒ¬ãƒƒã‚¸å†…è¨³ï¼ˆrollingã«å­˜åœ¨ã™ã‚‹éŠ˜æŸ„æ•°ï¼‰
    try:
        cov_have = len(basic_data)
        cov_total = len(symbols)
        cov_missing = max(0, cov_total - cov_have)
        _log(
            "ğŸ§® ãƒ‡ãƒ¼ã‚¿ã‚«ãƒãƒ¬ãƒƒã‚¸: "
            + f"rollingå–å¾—æ¸ˆã¿ {cov_have}/{cov_total} | missing={cov_missing}"
        )
        if cov_missing > 0:
            missing_syms = [s for s in symbols if s not in basic_data]
            _log(f"ğŸ›  æ¬ æãƒ‡ãƒ¼ã‚¿è£œå®Œä¸­: {len(missing_syms)}éŠ˜æŸ„", ui=False)
            fixed = 0
            for sym in missing_syms:
                try:
                    base_df = load_base_cache(sym, rebuild_if_missing=True)
                    if base_df is None or base_df.empty:
                        continue
                    x = base_df.copy()
                    if x.index.name is not None:
                        x = x.reset_index()
                    if "Date" in x.columns:
                        x["date"] = pd.to_datetime(x["Date"], errors="coerce")
                    elif "date" in x.columns:
                        x["date"] = pd.to_datetime(x["date"], errors="coerce")
                    else:
                        continue
                    x = x.dropna(subset=["date"]).sort_values("date")
                    col_map = {
                        "Open": "open",
                        "High": "high",
                        "Low": "low",
                        "Close": "close",
                        "AdjClose": "adjusted_close",
                        "Volume": "volume",
                    }
                    for k, v in list(col_map.items()):
                        if k in x.columns:
                            x = x.rename(columns={k: v})
                    n = int(
                        settings.cache.rolling.base_lookback_days
                        + settings.cache.rolling.buffer_days
                    )
                    sliced = x.tail(n).reset_index(drop=True)
                    cm.write_atomic(sliced, sym, "rolling")
                    df = _normalize_ohlcv(sliced)
                    basic_data[sym] = df
                    fixed += 1
                except Exception:
                    continue
            try:
                if fixed > 0:
                    _log(f"ğŸ§© è£œå®Œæ›¸ãæˆ»ã—: rollingç”Ÿæˆ {fixed}ä»¶")
            except Exception:
                pass
            cov_have = len(basic_data)
            cov_missing = max(0, cov_total - cov_have)
            _log(
                "ğŸ§® ãƒ‡ãƒ¼ã‚¿ã‚«ãƒãƒ¬ãƒƒã‚¸(è£œå®Œå¾Œ): "
                + f"rollingå–å¾—æ¸ˆã¿ {cov_have}/{cov_total} | missing={cov_missing}"
            )
            # è£œå®Œå¾Œã®å¯¾è±¡ä»¶æ•°ã‚’ UI ã® Tgt ã«å³æ™‚åæ˜ ï¼ˆå…¨systemå…±é€šï¼‰
            try:
                cb2 = globals().get("_PER_SYSTEM_STAGE")
            except Exception:
                cb2 = None
            if cb2 and callable(cb2):
                try:
                    # Tgt ã¯ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ç·æ•°ï¼ˆSPYé™¤å¤–ï¼‰ã‚’æ¡ç”¨
                    try:
                        tgt_total = int(cov_total)
                        if any(str(s).upper() == "SPY" for s in (symbols or [])):
                            tgt_total = max(0, tgt_total - 1)
                    except Exception:
                        tgt_total = int(cov_total)
                    for i in range(1, 8):
                        cb2(f"system{i}", 0, tgt_total, None, None, None)
                except Exception:
                    pass
    except Exception:
        pass
    # å…±æœ‰æŒ‡æ¨™ã®å‰è¨ˆç®—ï¼ˆATR/SMA/ADXãªã©ï¼‰
    try:
        import os as _os

        from common.indicators_precompute import (
            PRECOMPUTED_INDICATORS,
            precompute_shared_indicators,
        )

        # å®Ÿè¡Œã—ãã„å€¤ï¼ˆå°è¦æ¨¡ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã§ã¯å‰è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰å‰Šæ¸›ï¼‰
        try:
            _thr_syms = int(_os.environ.get("PRECOMPUTE_SYMBOLS_THRESHOLD", "300"))
        except Exception:
            _thr_syms = 300
        if len(basic_data) < max(0, _thr_syms):
            _log(
                f"ğŸ§® å…±æœ‰æŒ‡æ¨™ã®å‰è¨ˆç®—: ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå¯¾è±¡éŠ˜æŸ„ {len(basic_data)} ä»¶ < é–¾å€¤ {_thr_syms}ï¼‰"
            )
        else:
            try:
                _log(
                    "ğŸ§® å…±æœ‰æŒ‡æ¨™ã®å‰è¨ˆç®—ã‚’é–‹å§‹: "
                    + ", ".join(list(PRECOMPUTED_INDICATORS)[:8])
                    + (" â€¦" if len(PRECOMPUTED_INDICATORS) > 8 else "")
                )
            except Exception:
                _log("ğŸ§® å…±æœ‰æŒ‡æ¨™ã®å‰è¨ˆç®—ã‚’é–‹å§‹ (ATR/SMA/ADX ã»ã‹)")
            # å¤§è¦æ¨¡ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹æ™‚ã¯ä¸¦åˆ—åŒ–ï¼ˆç’°å¢ƒå¤‰æ•°ã§å¼·åˆ¶ON/OFFå¯èƒ½ï¼‰
            force_parallel = _os.environ.get("PRECOMPUTE_PARALLEL", "").lower()
            try:
                _thr_parallel = int(_os.environ.get("PRECOMPUTE_PARALLEL_THRESHOLD", "1000"))
            except Exception:
                _thr_parallel = 1000
            if force_parallel in ("1", "true", "yes"):
                use_parallel = True
            elif force_parallel in ("0", "false", "no"):
                use_parallel = False
            else:
                use_parallel = len(basic_data) >= max(0, _thr_parallel)

            # å‰è¨ˆç®—ã®ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã¯è¨­å®šå€¤ã«é€£å‹•ï¼ˆç’°å¢ƒå¤‰æ•°ã®ç›´æ¥æŒ‡å®šãŒã‚ã‚‹å ´åˆã¯åˆ¥é€”é–¢çŸ¥ï¼‰
            try:
                _st = get_settings(create_dirs=False)
                _pre_workers = int(getattr(_st, "THREADS_DEFAULT", 12))
            except Exception:
                _pre_workers = 12
            if use_parallel:
                try:
                    _log(f"ğŸ§µ å‰è¨ˆç®— ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼: {_pre_workers}")
                except Exception:
                    pass
            basic_data = precompute_shared_indicators(
                basic_data,
                log=_log,
                parallel=use_parallel,
                max_workers=_pre_workers if use_parallel else None,
            )
            _log("ğŸ§® å…±æœ‰æŒ‡æ¨™ã®å‰è¨ˆç®—ãŒå®Œäº†")
    except Exception as e:
        _log(f"âš ï¸ å…±æœ‰æŒ‡æ¨™ã®å‰è¨ˆç®—ã«å¤±æ•—: {e}")
    _log("ğŸ§ª äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å®Ÿè¡Œä¸­ (system1ã€œsystem6)â€¦")
    system1_syms = filter_system1(symbols, basic_data)
    system2_syms = filter_system2(symbols, basic_data)
    system3_syms = filter_system3(symbols, basic_data)
    system4_syms = filter_system4(symbols, basic_data)
    system5_syms = filter_system5(symbols, basic_data)
    system6_syms = filter_system6(symbols, basic_data)
    # å„ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é€šéä»¶æ•°ã‚’UIã¸é€šçŸ¥
    try:
        cb2 = globals().get("_PER_SYSTEM_STAGE")
    except Exception:
        cb2 = None
    if cb2 and callable(cb2):
        try:
            cb2("system1", 25, len(system1_syms), None, None, None)
            cb2("system2", 25, len(system2_syms), None, None, None)
            cb2("system3", 25, len(system3_syms), None, None, None)
            cb2("system4", 25, len(system4_syms), None, None, None)
            cb2("system5", 25, len(system5_syms), None, None, None)
            cb2("system6", 25, len(system6_syms), None, None, None)
            cb2(
                "system7",
                25,
                1 if "SPY" in (basic_data or {}) else 0,
                None,
                None,
                None,
            )
        except Exception:
            pass
    # System2 ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å†…è¨³ã®å¯è¦–åŒ–ï¼ˆä¾¡æ ¼ãƒ»å£²è²·ä»£é‡‘ãƒ»ATR ã®æ®µéšé€šéæ•°ï¼‰
    try:
        s2_total = len(symbols)
        c_price = 0
        c_dv = 0
        c_atr = 0
        for _sym in symbols:
            _df = basic_data.get(_sym)
            if _df is None or _df.empty:
                continue
            try:
                # ä¾¡æ ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                last_close = float(_df["close"].iloc[-1])
                if last_close >= 5:
                    c_price += 1
                else:
                    continue
                # å£²è²·ä»£é‡‘ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆ20æ—¥å¹³å‡ãƒ»å³å¯†ï¼‰
                dv = float((_df["close"] * _df["volume"]).tail(20).mean())
                if dv >= 2.5e7:
                    c_dv += 1
                else:
                    continue
                # ATR æ¯”ç‡ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆ10æ—¥ï¼‰
                if "high" in _df.columns and "low" in _df.columns:
                    _tr = (_df["high"] - _df["low"]).tail(10)
                    _atr = float(_tr.mean())
                    if _atr >= last_close * 0.03:
                        c_atr += 1
            except Exception:
                continue
        _log(
            "ğŸ§ª system2å†…è¨³: "
            + f"å…ƒ={s2_total}, ä¾¡æ ¼>=5: {c_price}, DV20>=25M: {c_dv}, ATR>=3%: {c_atr}"
        )
    except Exception:
        pass
    # System1 ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å†…è¨³ï¼ˆä¾¡æ ¼ãƒ»å£²è²·ä»£é‡‘ï¼‰
    try:
        s1_total = len(symbols)
        s1_price = 0
        s1_dv = 0
        for _sym in symbols:
            _df = basic_data.get(_sym)
            if _df is None or _df.empty:
                continue
            try:
                last_close = float(_df.get("close", _df.get("Close")).iloc[-1])  # type: ignore[index]
                if last_close >= 5:
                    s1_price += 1
                else:
                    continue
                # å®‰å…¨ã«ã‚«ãƒ©ãƒ ã‚’å–å¾—ã—ã¦ DV20 ã‚’è¨ˆç®—
                _c = _df["close"] if "close" in _df.columns else _df["Close"]
                _v = _df["volume"] if "volume" in _df.columns else _df["Volume"]
                dv20 = float((_c * _v).tail(20).mean())
                if dv20 >= 5e7:
                    s1_dv += 1
            except Exception:
                continue
        _log("ğŸ§ª system1å†…è¨³: " + f"å…ƒ={s1_total}, ä¾¡æ ¼>=5: {s1_price}, DV20>=50M: {s1_dv}")
    except Exception:
        pass
    # System3 ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å†…è¨³ï¼ˆLow>=1 â†’ AvgVol50>=1M â†’ ATR_Ratio>=5%ï¼‰
    try:
        s3_total = len(symbols)
        s3_low = 0
        s3_av = 0
        s3_atr = 0
        for _sym in symbols:
            _df = basic_data.get(_sym)
            if _df is None or _df.empty:
                continue
            try:
                _low_ser = _df.get("Low", _df.get("low"))
                if _low_ser is None:
                    continue
                if float(_low_ser.iloc[-1]) >= 1:
                    s3_low += 1
                else:
                    continue
                _av50 = _df.get("AvgVolume50")
                if (
                    _av50 is not None
                    and not pd.isna(_av50.iloc[-1])
                    and float(_av50.iloc[-1]) >= 1_000_000
                ):
                    s3_av += 1
                else:
                    continue
                _atr_ratio = _df.get("ATR_Ratio")
                if (
                    _atr_ratio is not None
                    and not pd.isna(_atr_ratio.iloc[-1])
                    and float(_atr_ratio.iloc[-1]) >= 0.05
                ):
                    s3_atr += 1
            except Exception:
                continue
        _log(
            "ğŸ§ª system3å†…è¨³: "
            + f"å…ƒ={s3_total}, Low>=1: {s3_low}, AvgVol50>=1M: {s3_av}, ATR_Ratio>=5%: {s3_atr}"
        )
    except Exception:
        pass
    # System4 ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å†…è¨³ï¼ˆDV50>=100M â†’ HV50 10ã€œ40ï¼‰
    try:
        s4_total = len(symbols)
        s4_dv = 0
        s4_hv = 0
        for _sym in symbols:
            _df = basic_data.get(_sym)
            if _df is None or _df.empty:
                continue
            try:
                _dv50 = _df.get("DollarVolume50")
                _hv50 = _df.get("HV50")
                if (
                    _dv50 is not None
                    and not pd.isna(_dv50.iloc[-1])
                    and float(_dv50.iloc[-1]) > 100_000_000
                ):
                    s4_dv += 1
                else:
                    continue
                if _hv50 is not None and not pd.isna(_hv50.iloc[-1]):
                    hv = float(_hv50.iloc[-1])
                    if 10 <= hv <= 40:
                        s4_hv += 1
            except Exception:
                continue
        _log("ğŸ§ª system4å†…è¨³: " + f"å…ƒ={s4_total}, DV50>=100M: {s4_dv}, HV50 10ã€œ40: {s4_hv}")
    except Exception:
        pass
    # System5 ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å†…è¨³ï¼ˆAvgVol50>500k â†’ DV50>2.5M â†’ ATR_Pct>4%ï¼‰
    try:
        s5_total = len(symbols)
        s5_av = 0
        s5_dv = 0
        s5_atr = 0
        for _sym in symbols:
            _df = basic_data.get(_sym)
            if _df is None or _df.empty:
                continue
            try:
                _av50 = _df.get("AvgVolume50")
                if (
                    _av50 is not None
                    and not pd.isna(_av50.iloc[-1])
                    and float(_av50.iloc[-1]) > 500_000
                ):
                    s5_av += 1
                else:
                    continue
                _dv50 = _df.get("DollarVolume50")
                if (
                    _dv50 is not None
                    and not pd.isna(_dv50.iloc[-1])
                    and float(_dv50.iloc[-1]) > 2_500_000
                ):
                    s5_dv += 1
                else:
                    continue
                _atrp = _df.get("ATR_Pct")
                if (
                    _atrp is not None
                    and not pd.isna(_atrp.iloc[-1])
                    and float(_atrp.iloc[-1]) > 0.04
                ):
                    s5_atr += 1
            except Exception:
                continue
        _log(
            "ğŸ§ª system5å†…è¨³: "
            + f"å…ƒ={s5_total}, AvgVol50>500k: {s5_av}, DV50>2.5M: {s5_dv}, ATR_Pct>4%: {s5_atr}"
        )
    except Exception:
        pass
    # System6 ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å†…è¨³ï¼ˆLow>=5 â†’ DV50>10Mï¼‰
    try:
        s6_total = len(symbols)
        s6_low = 0
        s6_dv = 0
        for _sym in symbols:
            _df = basic_data.get(_sym)
            if _df is None or _df.empty:
                continue
            try:
                _low_ser = _df.get("Low", _df.get("low"))
                if _low_ser is None:
                    continue
                if float(_low_ser.iloc[-1]) >= 5:
                    s6_low += 1
                else:
                    continue
                _dv50 = _df.get("DollarVolume50")
                if (
                    _dv50 is not None
                    and not pd.isna(_dv50.iloc[-1])
                    and float(_dv50.iloc[-1]) > 10_000_000
                ):
                    s6_dv += 1
            except Exception:
                continue
        _log("ğŸ§ª system6å†…è¨³: " + f"å…ƒ={s6_total}, Low>=5: {s6_low}, DV50>10M: {s6_dv}")
    except Exception:
        pass
    # System7 ã¯ SPY å›ºå®šï¼ˆå‚è€ƒæƒ…å ±ã®ã¿ï¼‰
    try:
        spyp = (
            1 if ("SPY" in basic_data and not getattr(basic_data.get("SPY"), "empty", True)) else 0
        )
        _log("ğŸ§ª system7å†…è¨³: SPYå›ºå®š | SPYå­˜åœ¨=" + str(spyp))
    except Exception:
        pass
    _log(
        "ğŸ§ª ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµæœ: "
        + f"system1={len(system1_syms)}ä»¶, "
        + f"system2={len(system2_syms)}ä»¶, "
        + f"system3={len(system3_syms)}ä»¶, "
        + f"system4={len(system4_syms)}ä»¶, "
        + f"system5={len(system5_syms)}ä»¶, "
        + f"system6={len(system6_syms)}ä»¶"
    )
    if progress_callback:
        try:
            progress_callback(3, 8, "filter")
        except Exception:
            pass

    # å„ã‚·ã‚¹ãƒ†ãƒ ç”¨ã®ç”Ÿãƒ‡ãƒ¼ã‚¿è¾æ›¸ã‚’äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®éŠ˜æŸ„ã§æ§‹ç¯‰
    def _subset_data(keys: list[str]) -> dict[str, pd.DataFrame]:
        out = {}
        for s in keys or []:
            v = basic_data.get(s)
            if v is not None and not getattr(v, "empty", True):
                out[s] = v
        return out

    _log("ğŸ§® æŒ‡æ¨™è¨ˆç®—ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ä¸­ (system1)â€¦")
    raw_data_system1 = _subset_data(system1_syms)
    _log(f"ğŸ§® æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿: system1={len(raw_data_system1)}éŠ˜æŸ„")
    # System1 ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³ï¼ˆæœ€æ–°æ—¥ã® setup åˆ¤å®šæ•°ï¼‰ã‚’ CLI ã«å‡ºåŠ›
    try:
        # ãƒ•ã‚£ãƒ«ã‚¿é€šéã¯äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµæœï¼ˆsystem1_symsï¼‰ç”±æ¥ã§ç¢ºå®š
        s1_filter = int(len(system1_syms))
        # ç›´è¿‘æ—¥ã® SMA25>SMA50 ã‚’é›†è¨ˆï¼ˆäº‹å‰è¨ˆç®—æ¸ˆã¿åˆ—ã‚’å‚ç…§ï¼‰
        s1_setup = 0
        # å¸‚å ´æ¡ä»¶ï¼ˆSPYã®Close>SMA100ï¼‰ã‚’å…ˆã«åˆ¤å®š
        _spy_ok = None
        try:
            if "SPY" in (basic_data or {}):
                _spy_df = get_spy_with_indicators(basic_data["SPY"])
                if _spy_df is not None and not getattr(_spy_df, "empty", True):
                    _last = _spy_df.iloc[-1]
                    _spy_ok = int(float(_last.get("Close", 0)) > float(_last.get("SMA100", 0)))
        except Exception:
            _spy_ok = None
        for _sym, _df in (raw_data_system1 or {}).items():
            if _df is None or getattr(_df, "empty", True):
                continue
            try:
                last = _df.iloc[-1]
            except Exception:
                continue
            try:
                sma_pass = float(last.get("SMA25", float("nan"))) > float(
                    last.get("SMA50", float("nan"))
                )
            except Exception:
                sma_pass = False
            if sma_pass:
                s1_setup += 1
        # å‡ºåŠ›é †: ãƒ•ã‚£ãƒ«ã‚¿é€šé â†’ SPY>SMA100 â†’ SMA25>SMA50
        if _spy_ok is None:
            _log(
                f"ğŸ§© system1ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: ãƒ•ã‚£ãƒ«ã‚¿é€šé={s1_filter}, SPY>SMA100: -, "
                f"SMA25>SMA50: {s1_setup}"
            )
        else:
            _log(
                f"ğŸ§© system1ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: ãƒ•ã‚£ãƒ«ã‚¿é€šé={s1_filter}, SPY>SMA100: {_spy_ok}, "
                f"SMA25>SMA50: {s1_setup}"
            )
        # UI ã® STUpass ã¸åæ˜ ï¼ˆ50%æ™‚ç‚¹ï¼‰
        try:
            cb2 = globals().get("_PER_SYSTEM_STAGE")
            if cb2 and callable(cb2):
                # SPY ã‚²ãƒ¼ãƒˆï¼ˆClose>SMA100ï¼‰ãŒå½ãªã‚‰ STUpass ã¯ 0 æ‰±ã„
                s1_setup_eff = int(s1_setup)
                try:
                    if isinstance(_spy_ok, int) and _spy_ok == 0:
                        s1_setup_eff = 0
                except Exception:
                    pass
                cb2("system1", 50, int(s1_filter), int(s1_setup_eff), None, None)
        except Exception:
            pass
        # å‚è€ƒ: System1 ã® SPY gate çŠ¶æ…‹ã‚’ UI ã«è£œè¶³è¡¨ç¤º
        try:
            cb_note = globals().get("_PER_SYSTEM_NOTE")
            if cb_note and callable(cb_note):
                try:
                    if _spy_ok is None:
                        cb_note("system1", "SPY>SMA100: -")
                    else:
                        cb_note(
                            "system1",
                            "SPY>SMA100: OK" if int(_spy_ok) == 1 else "SPY>SMA100: NG",
                        )
                except Exception:
                    pass
        except Exception:
            pass
    except Exception:
        pass
    _log("ğŸ§® æŒ‡æ¨™è¨ˆç®—ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ä¸­ (system2)â€¦")
    raw_data_system2 = _subset_data(system2_syms)
    _log(f"ğŸ§® æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿: system2={len(raw_data_system2)}éŠ˜æŸ„")
    # System2 ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: ãƒ•ã‚£ãƒ«ã‚¿é€šé, RSI3>90, TwoDayUp
    try:
        s2_filter = int(len(system2_syms))
        s2_rsi = 0
        s2_up2 = 0
        for _sym in system2_syms or []:
            _df = raw_data_system2.get(_sym)
            if _df is None or getattr(_df, "empty", True):
                continue
            try:
                last = _df.iloc[-1]
            except Exception:
                continue
            try:
                if float(last.get("RSI3", 0)) > 90:
                    s2_rsi += 1
            except Exception:
                pass
            try:
                if bool(last.get("TwoDayUp", False)):
                    s2_up2 += 1
            except Exception:
                pass
        _log(
            "ğŸ§© system2ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: "
            + f"ãƒ•ã‚£ãƒ«ã‚¿é€šé={s2_filter}, RSI3>90: {s2_rsi}, "
            + f"TwoDayUp: {s2_up2}"
        )
        try:
            cb2 = globals().get("_PER_SYSTEM_STAGE")
            if cb2 and callable(cb2):
                cb2("system2", 50, int(s2_filter), int(max(s2_rsi, s2_up2)), None, None)
        except Exception:
            pass
    except Exception:
        pass
    _log("ğŸ§® æŒ‡æ¨™è¨ˆç®—ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ä¸­ (system3)â€¦")
    raw_data_system3 = _subset_data(system3_syms)
    _log(f"ğŸ§® æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿: system3={len(raw_data_system3)}éŠ˜æŸ„")
    # System3 ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: ãƒ•ã‚£ãƒ«ã‚¿é€šé, Close>SMA150, 3æ—¥ä¸‹è½ç‡>=12.5%
    try:
        s3_filter = int(len(system3_syms))
        s3_close = 0
        s3_drop = 0
        for _sym in system3_syms or []:
            _df = raw_data_system3.get(_sym)
            if _df is None or getattr(_df, "empty", True):
                continue
            try:
                last = _df.iloc[-1]
            except Exception:
                continue
            try:
                if float(last.get("Close", 0)) > float(last.get("SMA150", float("inf"))):
                    s3_close += 1
            except Exception:
                pass
            try:
                if float(last.get("Drop3D", 0)) >= 0.125:
                    s3_drop += 1
            except Exception:
                pass
        _log(
            "ğŸ§© system3ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: "
            + f"ãƒ•ã‚£ãƒ«ã‚¿é€šé={s3_filter}, Close>SMA150: {s3_close}, "
            + f"3æ—¥ä¸‹è½ç‡>=12.5%: {s3_drop}"
        )
        try:
            cb2 = globals().get("_PER_SYSTEM_STAGE")
            if cb2 and callable(cb2):
                cb2("system3", 50, int(s3_filter), int(max(s3_close, s3_drop)), None, None)
        except Exception:
            pass
    except Exception:
        pass
    _log("ğŸ§® æŒ‡æ¨™è¨ˆç®—ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ä¸­ (system4)â€¦")
    raw_data_system4 = _subset_data(system4_syms)
    _log(f"ğŸ§® æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿: system4={len(raw_data_system4)}éŠ˜æŸ„")
    # System4 ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: ãƒ•ã‚£ãƒ«ã‚¿é€šé, Close>SMA200
    try:
        s4_filter = int(len(system4_syms))
        s4_close = 0
        for _sym in system4_syms or []:
            _df = raw_data_system4.get(_sym)
            if _df is None or getattr(_df, "empty", True):
                continue
            try:
                last = _df.iloc[-1]
            except Exception:
                continue
            try:
                if float(last.get("Close", 0)) > float(last.get("SMA200", float("inf"))):
                    s4_close += 1
            except Exception:
                pass
        _log(f"ğŸ§© system4ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: ãƒ•ã‚£ãƒ«ã‚¿é€šé={s4_filter}, Close>SMA200: {s4_close}")
        try:
            cb2 = globals().get("_PER_SYSTEM_STAGE")
            if cb2 and callable(cb2):
                cb2("system4", 50, int(s4_filter), int(s4_close), None, None)
        except Exception:
            pass
    except Exception:
        pass
    _log("ğŸ§® æŒ‡æ¨™è¨ˆç®—ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ä¸­ (system5)â€¦")
    raw_data_system5 = _subset_data(system5_syms)
    _log(f"ğŸ§® æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿: system5={len(raw_data_system5)}éŠ˜æŸ„")
    # System5 ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: ãƒ•ã‚£ãƒ«ã‚¿é€šé, Close>SMA100+ATR10, ADX7>55, RSI3<50
    try:
        s5_filter = int(len(system5_syms))
        s5_close = 0
        s5_adx = 0
        s5_rsi = 0
        for _sym in system5_syms or []:
            _df = raw_data_system5.get(_sym)
            if _df is None or getattr(_df, "empty", True):
                continue
            try:
                last = _df.iloc[-1]
            except Exception:
                continue
            try:
                if float(last.get("Close", 0)) > float(last.get("SMA100", 0)) + float(
                    last.get("ATR10", 0)
                ):
                    s5_close += 1
            except Exception:
                pass
            try:
                if float(last.get("ADX7", 0)) > 55:
                    s5_adx += 1
            except Exception:
                pass
            try:
                if float(last.get("RSI3", 100)) < 50:
                    s5_rsi += 1
            except Exception:
                pass
        _log(
            "ğŸ§© system5ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: "
            + f"ãƒ•ã‚£ãƒ«ã‚¿é€šé={s5_filter}, Close>SMA100+ATR10: {s5_close}, "
            + f"ADX7>55: {s5_adx}, RSI3<50: {s5_rsi}"
        )
        try:
            cb2 = globals().get("_PER_SYSTEM_STAGE")
            if cb2 and callable(cb2):
                cb2("system5", 50, int(s5_filter), int(s5_close), None, None)
        except Exception:
            pass
    except Exception:
        pass
    _log("ğŸ§® æŒ‡æ¨™è¨ˆç®—ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ä¸­ (system6)â€¦")
    raw_data_system6 = _subset_data(system6_syms)
    _log(f"ğŸ§® æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿: system6={len(raw_data_system6)}éŠ˜æŸ„")
    # System6 ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: ãƒ•ã‚£ãƒ«ã‚¿é€šé, Return6D>20%, UpTwoDays
    try:
        s6_filter = int(len(system6_syms))
        s6_ret = 0
        s6_up2 = 0
        for _sym in system6_syms or []:
            _df = raw_data_system6.get(_sym)
            if _df is None or getattr(_df, "empty", True):
                continue
            try:
                last = _df.iloc[-1]
            except Exception:
                continue
            try:
                if float(last.get("Return6D", 0)) > 0.20:
                    s6_ret += 1
            except Exception:
                pass
            try:
                if bool(last.get("UpTwoDays", False)):
                    s6_up2 += 1
            except Exception:
                pass
        _log(
            "ğŸ§© system6ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: "
            + f"ãƒ•ã‚£ãƒ«ã‚¿é€šé={s6_filter}, Return6D>20%: {s6_ret}, "
            + f"UpTwoDays: {s6_up2}"
        )
        try:
            cb2 = globals().get("_PER_SYSTEM_STAGE")
            if cb2 and callable(cb2):
                cb2("system6", 50, int(s6_filter), int(max(s6_ret, s6_up2)), None, None)
        except Exception:
            pass
    except Exception:
        pass
    if progress_callback:
        try:
            progress_callback(4, 8, "load_indicators")
        except Exception:
            pass
    # ...raw_data_system...
    if "SPY" in basic_data:
        spy_df = get_spy_with_indicators(basic_data["SPY"])
    else:
        spy_df = None
        _log(
            "âš ï¸ SPY ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (base/full_backup/rolling ã‚’ç¢ºèª)ã€‚"
            "SPY.csv ã‚’ data_cache/base ã‚‚ã—ãã¯ data_cache/full_backup ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚"
        )

    # ã‚¹ãƒˆãƒ©ãƒ†ã‚¸åˆæœŸåŒ–
    strategy_objs = [
        System1Strategy(),
        System2Strategy(),
        System3Strategy(),
        System4Strategy(),
        System5Strategy(),
        System6Strategy(),
        System7Strategy(),
    ]
    strategies = {getattr(s, "SYSTEM_NAME", "").lower(): s for s in strategy_objs}
    # ã‚¨ãƒ³ã‚¸ãƒ³å±¤ã¯UIä¾å­˜ã‚’æ’é™¤ï¼ˆUIè¡¨ç¤ºã¯log/progressã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å´ã«ä»»ã›ã‚‹ï¼‰

    def _run_strategy(name: str, stg) -> tuple[str, pd.DataFrame, str, list[str]]:
        logs: list[str] = []

        def _local_log(message: str) -> None:
            logs.append(str(message))
            # UI ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒã‚ã‚Œã°ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ã§é€ä¿¡ã€ç„¡ã‘ã‚Œã° CLI ã«å‡ºåŠ›
            try:
                cb = globals().get("_LOG_CALLBACK")
            except Exception:
                cb = None
            if cb and callable(cb):
                _emit_ui_log(f"[{name}] {message}")
            else:
                try:
                    print(f"[{name}] {message}", flush=True)
                except Exception:
                    pass

        if name == "system1":
            base = raw_data_system1
        elif name == "system2":
            base = raw_data_system2
        elif name == "system3":
            base = raw_data_system3
        elif name == "system4":
            base = raw_data_system4
        elif name == "system5":
            base = raw_data_system5
        elif name == "system6":
            base = raw_data_system6
        elif name == "system7":
            base = {"SPY": basic_data.get("SPY")} if "basic_data" in locals() else {}
        else:
            base = basic_data if "basic_data" in locals() else {}
        if name == "system4" and spy_df is None:
            _local_log(
                "âš ï¸ System4 ã¯ SPY æŒ‡æ¨™ãŒå¿…è¦ã§ã™ãŒ "
                + "SPY ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
                + "ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚"
            )
            return name, pd.DataFrame(), f"âŒ {name}: 0 ä»¶ ğŸš«", logs
        _local_log(f"ğŸ” {name}: ã‚·ã‚°ãƒŠãƒ«æŠ½å‡ºã‚’é–‹å§‹")
        try:
            # æ®µéšé€²æ—: 0/25/50/75/100 ã‚’ UI å´ã«æ©‹æ¸¡ã—
            def _stage(
                v: int,
                f: int | None = None,
                s: int | None = None,
                c: int | None = None,
                fin: int | None = None,
            ) -> None:
                try:
                    cb2 = globals().get("_PER_SYSTEM_STAGE")
                except Exception:
                    cb2 = None
                if cb2 and callable(cb2):
                    try:
                        cb2(name, max(0, min(100, int(v))), f, s, c, fin)
                    except Exception:
                        pass
                # TRDlistä»¶æ•°ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’æ›´æ–°ï¼ˆå¾Œæ®µã®ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰é€šçŸ¥ã§ä½¿ç”¨ï¼‰
                try:
                    if c is not None:
                        _CAND_COUNT_SNAPSHOT[name] = int(c)
                except Exception:
                    pass

            import os as _os

            # ãƒ—ãƒ­ã‚»ã‚¹ãƒ—ãƒ¼ãƒ«åˆ©ç”¨å¯å¦ï¼ˆç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãå¯ï¼‰
            env_pp = _os.environ.get("USE_PROCESS_POOL", "").lower()
            if env_pp in ("0", "false", "no"):
                use_process_pool = False
            elif env_pp in ("1", "true", "yes"):
                use_process_pool = True
            else:
                # æ—¢å®šã¯ãƒ—ãƒ­ã‚»ã‚¹ãƒ—ãƒ¼ãƒ«ç„¡åŠ¹ï¼ˆUIãƒ­ã‚°/ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å„ªå…ˆï¼‰
                use_process_pool = False
            # ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã¯ç’°å¢ƒå¤‰æ•°ãŒã‚ã‚Œã°å„ªå…ˆã€ç„¡ã‘ã‚Œã°è¨­å®š(THREADS_DEFAULT)ã«é€£å‹•
            try:
                _env_workers = _os.environ.get("PROCESS_POOL_WORKERS", "").strip()
                if _env_workers:
                    max_workers = int(_env_workers) or None
                else:
                    try:
                        _st = get_settings(create_dirs=False)
                        max_workers = int(getattr(_st, "THREADS_DEFAULT", 8)) or None
                    except Exception:
                        max_workers = None
            except Exception:
                max_workers = None
            # ãƒ«ãƒƒã‚¯ãƒãƒƒã‚¯ã¯ã€å¿…è¦æŒ‡æ¨™ã®æœ€å¤§çª“ï¼‹Î±ã€ã‚’å‹•çš„æ¨å®š
            try:
                settings2 = get_settings(create_dirs=True)
                lb_default = int(
                    settings2.cache.rolling.base_lookback_days + settings2.cache.rolling.buffer_days
                )
            except Exception:
                settings2 = None
                lb_default = 240
            # YAMLã®strategiesã‚»ã‚¯ã‚·ãƒ§ãƒ³ç­‰ã‹ã‚‰ãƒ’ãƒ³ãƒˆã‚’å–å¾—ï¼ˆãªã‘ã‚Œã°ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ï¼‰
            # ãƒ«ãƒƒã‚¯ãƒãƒƒã‚¯ã®ãƒãƒ¼ã‚¸ãƒ³/æœ€å°æ—¥æ•°ã¯ç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãå¯èƒ½
            try:
                margin = float(_os.environ.get("LOOKBACK_MARGIN", "0.15"))
            except Exception:
                margin = 0.15
            need_map: dict[str, int] = {
                "system1": int(200 * (1 + margin)),
                "system2": int(120 * (1 + margin)),
                "system3": int(60 * (1 + margin)),
                "system4": int(80 * (1 + margin)),
                "system5": int(120 * (1 + margin)),
                "system6": int(80 * (1 + margin)),
                "system7": int(80 * (1 + margin)),
            }
            # æˆ¦ç•¥å´ãŒ get_total_days ã‚’å®Ÿè£…ã—ã¦ã„ã‚Œã°å„ªå…ˆ
            custom_need = None
            try:
                fn = getattr(stg, "get_total_days", None)
                if callable(fn):
                    _val = fn(base)
                    if isinstance(_val, int | float):
                        custom_need = int(_val)
                    elif isinstance(_val, str):
                        try:
                            custom_need = int(float(_val))
                        except Exception:
                            custom_need = None
                    else:
                        custom_need = None
            except Exception:
                custom_need = None
            try:
                min_floor = int(_os.environ.get("LOOKBACK_MIN_DAYS", "80"))
            except Exception:
                min_floor = 80
            min_required = custom_need or need_map.get(name, lb_default)
            lookback_days = min(lb_default, max(min_floor, int(min_required)))
            _t0 = __import__("time").time()
            # ãƒ—ãƒ­ã‚»ã‚¹ãƒ—ãƒ¼ãƒ«ä½¿ç”¨æ™‚ã¯ stage_progress ã‚’æ¸¡ã•ãªã„ï¼ˆpickle/__main__å•é¡Œã‚’å›é¿ï¼‰
            _stage_cb = None if use_process_pool else _stage
            _log_cb = None if use_process_pool else _local_log
            df = stg.get_today_signals(
                base,
                market_df=spy_df,
                today=today,
                progress_callback=None,
                log_callback=_log_cb,
                stage_progress=_stage_cb,
                use_process_pool=use_process_pool,
                max_workers=max_workers,
                lookback_days=lookback_days,
            )
            _elapsed = int(max(0, __import__("time").time() - _t0))
            _m, _s = divmod(_elapsed, 60)
            _local_log(f"â±ï¸ {name}: çµŒé {_m}åˆ†{_s}ç§’")
        except Exception as e:  # noqa: BLE001
            _local_log(f"âš ï¸ {name}: ã‚·ã‚°ãƒŠãƒ«æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            # ãƒ—ãƒ­ã‚»ã‚¹ãƒ—ãƒ¼ãƒ«ç•°å¸¸æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆéãƒ—ãƒ¼ãƒ«ï¼‰ã§ä¸€åº¦ã ã‘å†è©¦è¡Œ
            try:
                msg = str(e).lower()
            except Exception:
                msg = ""
            needs_fallback = any(
                k in msg
                for k in [
                    "process pool",
                    "a child process terminated",
                    "terminated abruptly",
                    "forkserver",
                    "__main__",
                ]
            )
            if needs_fallback:
                _local_log("ğŸ›Ÿ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å†è©¦è¡Œ: ãƒ—ãƒ­ã‚»ã‚¹ãƒ—ãƒ¼ãƒ«ç„¡åŠ¹åŒ–ã§å®Ÿè¡Œã—ã¾ã™")
                try:
                    _t0b = __import__("time").time()
                    df = stg.get_today_signals(
                        base,
                        market_df=spy_df,
                        today=today,
                        progress_callback=None,
                        log_callback=_local_log,
                        stage_progress=None,
                        use_process_pool=False,
                        max_workers=None,
                        lookback_days=lookback_days,
                    )
                    _elapsed_b = int(max(0, __import__("time").time() - _t0b))
                    _m2, _s2 = divmod(_elapsed_b, 60)
                    _local_log(f"â±ï¸ {name} (fallback): çµŒé {_m2}åˆ†{_s2}ç§’")
                except Exception as e2:  # noqa: BLE001
                    _local_log(f"âŒ {name}: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚å¤±æ•—: {e2}")
                    df = pd.DataFrame()
            else:
                df = pd.DataFrame()
        if not df.empty:
            if "score_key" in df.columns and len(df):
                first_key = df["score_key"].iloc[0]
            else:
                first_key = None
            asc = _asc_by_score_key(first_key)
            df = df.sort_values("score", ascending=asc, na_position="last")
            df = df.reset_index(drop=True)
        if df is not None and not df.empty:
            msg = f"ğŸ“Š {name}: {len(df)} ä»¶"
        else:
            msg = f"âŒ {name}: 0 ä»¶ ğŸš«"
        _local_log(msg)
        return name, df, msg, logs

    # æŠ½å‡ºé–‹å§‹å‰ã«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é€šéã®ã¾ã¨ã‚ã‚’å‡ºåŠ›
    try:
        setup_summary = []
        for name, val in (
            ("system1", locals().get("s1_setup")),
            (
                "system2",
                max(locals().get("s2_rsi", 0), locals().get("s2_up2", 0)),
            ),
            (
                "system3",
                max(locals().get("s3_close", 0), locals().get("s3_drop", 0)),
            ),
            ("system4", locals().get("s4_close")),
            ("system5", locals().get("s5_close")),
            (
                "system6",
                max(locals().get("s6_ret", 0), locals().get("s6_up2", 0)),
            ),
            ("system7", 1 if ("SPY" in (basic_data or {})) else 0),
        ):
            try:
                if val is not None:
                    setup_summary.append(f"{name}={int(val)}")
            except Exception:
                continue
        if setup_summary:
            _log("ğŸ§© ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é€šéã¾ã¨ã‚: " + ", ".join(setup_summary))
    except Exception:
        pass

    _log("ğŸš€ å„ã‚·ã‚¹ãƒ†ãƒ ã®å½“æ—¥ã‚·ã‚°ãƒŠãƒ«æŠ½å‡ºã‚’é–‹å§‹")
    per_system: dict[str, pd.DataFrame] = {}
    total = len(strategies)
    # äº‹å‰ã«å…¨ã‚·ã‚¹ãƒ†ãƒ ã¸ã‚¹ãƒ†ãƒ¼ã‚¸0%ï¼ˆfilteré–‹å§‹ï¼‰ã‚’åŒæ™‚é€šçŸ¥ï¼ˆUIåŒæœŸè¡¨ç¤ºç”¨ï¼‰
    try:
        cb2 = globals().get("_PER_SYSTEM_STAGE")
    except Exception:
        cb2 = None
    if cb2 and callable(cb2):
        # 0% ã‚¹ãƒ†ãƒ¼ã‚¸ã®ã€Œå¯¾è±¡â†’ã€ã¯ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ç·æ•°ãƒ™ãƒ¼ã‚¹ï¼ˆSPYã¯é™¤å¤–ï¼‰
        try:
            universe_total = sum(1 for s in (symbols or []) if str(s).upper() != "SPY")
        except Exception:
            universe_total = len(symbols) if symbols is not None else 0
            try:
                has_spy = 1 if "SPY" in (symbols or []) else 0
                universe_total = max(0, int(universe_total) - has_spy)
            except Exception:
                pass
        for name in strategies.keys():
            try:
                cb2(name, 0, int(universe_total), None, None, None)
            except Exception:
                pass
    if parallel:
        if progress_callback:
            try:
                progress_callback(5, 8, "run_strategies")
            except Exception:
                pass
        with ThreadPoolExecutor() as executor:
            futures: dict[Future, str] = {}
            for name, stg in strategies.items():
                # systemã”ã¨ã®é–‹å§‹ã‚’é€šçŸ¥
                if per_system_progress:
                    try:
                        per_system_progress(name, "start")
                    except Exception:
                        pass
                # CLIå°‚ç”¨: å„ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹ã‚’å³æ™‚è¡¨ç¤ºï¼ˆUIã«ã¯å‡ºã•ãªã„ï¼‰
                try:
                    _log(f"â–¶ {name} é–‹å§‹", ui=False)
                except Exception:
                    pass
                fut = executor.submit(_run_strategy, name, stg)
                futures[fut] = name
            for _idx, fut in enumerate(as_completed(futures), start=1):
                name, df, msg, logs = fut.result()
                per_system[name] = df
                # å³æ™‚: TRDlistï¼ˆå€™è£œä»¶æ•°ï¼‰ã‚’75%æ®µéšã¨ã—ã¦é€šçŸ¥ï¼ˆä¸Šé™ã¯max_positionsï¼‰
                try:
                    cb2 = globals().get("_PER_SYSTEM_STAGE")
                except Exception:
                    cb2 = None
                if cb2 and callable(cb2):
                    try:
                        try:
                            _mx = int(get_settings(create_dirs=False).risk.max_positions)
                        except Exception:
                            _mx = 10
                        _cand_cnt = (
                            0 if (df is None or getattr(df, "empty", True)) else int(len(df))
                        )
                        if _mx > 0:
                            _cand_cnt = min(int(_cand_cnt), int(_mx))
                        cb2(name, 75, None, None, int(_cand_cnt), None)
                    except Exception:
                        pass
                # UI ãŒç„¡ã„å ´åˆã¯ CLI å‘ã‘ã«ç°¡ç•¥ãƒ­ã‚°ã‚’é›†ç´„å‡ºåŠ›ã€‚UI ãŒã‚ã‚‹å ´åˆã¯å®Œäº†å¾Œã«å†é€ã€‚
                # ï¼ˆUI ã«ã¯ãƒ¯ãƒ¼ã‚«ãƒ¼å®Ÿè¡Œä¸­ã«é€æ¬¡é€ä¿¡æ¸ˆã¿ã®ãŸã‚ã€ã“ã“ã§ã®å†é€ã¯è¡Œã‚ãªã„ï¼‰
                # CLIå°‚ç”¨: ãƒ¯ãƒ¼ã‚«ãƒ¼åé›†ãƒ­ã‚°ã‚’å¸¸ã«å‡ºåŠ›ï¼ˆUIã«ã¯é€ã‚‰ãªã„ï¼‰
                for line in _filter_logs(logs, ui=False):
                    _log(f"[{name}] {line}", ui=False)
                # UI ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒã‚ã‚‹å ´åˆã¯ä½•ã‚‚ã—ãªã„ï¼ˆé‡è¤‡é˜²æ­¢ï¼‰
                # å®Œäº†é€šçŸ¥
                if per_system_progress:
                    try:
                        per_system_progress(name, "done")
                    except Exception:
                        pass
                # CLIå°‚ç”¨: å®Œäº†ã‚’ç°¡æ½”è¡¨ç¤ºï¼ˆä»¶æ•°ä»˜ãã€‚å¤±æ•—æ™‚ã¯ä»¶æ•°ä¸æ˜ã§ã‚‚ç¶šè¡Œï¼‰
                try:
                    _cnt = 0 if (df is None or getattr(df, "empty", True)) else int(len(df))
                except Exception:
                    _cnt = -1
                try:
                    _log(f"âœ… {name} å®Œäº†: {('?' if _cnt < 0 else _cnt)}ä»¶", ui=False)
                except Exception:
                    pass
                # å‰å›çµæœã¯é–‹å§‹æ™‚ã«ã¾ã¨ã‚ã¦å‡ºåŠ›ã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯å‡ºã•ãªã„
                if progress_callback:
                    try:
                        progress_callback(5 + min(_idx, 1), 8, name)
                    except Exception:
                        pass
        if progress_callback:
            try:
                progress_callback(6, 8, "strategies_done")
            except Exception:
                pass
    else:
        for _idx, (name, stg) in enumerate(strategies.items(), start=1):
            if progress_callback:
                try:
                    progress_callback(5, 8, name)
                except Exception:
                    pass
            # é †æ¬¡å®Ÿè¡Œæ™‚ã‚‚é–‹å§‹ã‚’é€šçŸ¥
            if per_system_progress:
                try:
                    per_system_progress(name, "start")
                except Exception:
                    pass
            # CLIå°‚ç”¨: å„ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹ã‚’å³æ™‚è¡¨ç¤ºï¼ˆUIã«ã¯å‡ºã•ãªã„ï¼‰
            try:
                _log(f"â–¶ {name} é–‹å§‹", ui=False)
            except Exception:
                pass
            name, df, msg, logs = _run_strategy(name, stg)
            per_system[name] = df
            # CLIå°‚ç”¨: ãƒ¯ãƒ¼ã‚«ãƒ¼åé›†ãƒ­ã‚°ã‚’å¸¸ã«å‡ºåŠ›ï¼ˆUIã«ã¯é€ã‚‰ãªã„ï¼‰
            for line in _filter_logs(logs, ui=False):
                _log(f"[{name}] {line}", ui=False)
            # å³æ™‚: TRDlistï¼ˆå€™è£œä»¶æ•°ï¼‰ã‚’75%æ®µéšã¨ã—ã¦é€šçŸ¥ï¼ˆä¸Šé™ã¯max_positionsï¼‰
            try:
                cb2 = globals().get("_PER_SYSTEM_STAGE")
            except Exception:
                cb2 = None
            if cb2 and callable(cb2):
                try:
                    try:
                        _mx = int(get_settings(create_dirs=False).risk.max_positions)
                    except Exception:
                        _mx = 10
                    _cand_cnt = 0 if (df is None or getattr(df, "empty", True)) else int(len(df))
                    if _mx > 0:
                        _cand_cnt = min(int(_cand_cnt), int(_mx))
                    cb2(name, 75, None, None, int(_cand_cnt), None)
                except Exception:
                    pass
            if per_system_progress:
                try:
                    per_system_progress(name, "done")
                except Exception:
                    pass
            # CLIå°‚ç”¨: å®Œäº†ã‚’ç°¡æ½”è¡¨ç¤ºï¼ˆä»¶æ•°ä»˜ãï¼‰
            try:
                _cnt = 0 if (df is None or getattr(df, "empty", True)) else int(len(df))
            except Exception:
                _cnt = -1
            try:
                _log(f"âœ… {name} å®Œäº†: {('?' if _cnt < 0 else _cnt)}ä»¶", ui=False)
            except Exception:
                pass
            # å³æ™‚ã®75%å†é€šçŸ¥ã¯è¡Œã‚ãªã„ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰å´ã§ä¸€æ‹¬é€šçŸ¥ï¼‰
            # å‰å›çµæœã¯é–‹å§‹æ™‚ã«ã¾ã¨ã‚ã¦å‡ºåŠ›ã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯å‡ºã•ãªã„
        if progress_callback:
            try:
                progress_callback(6, 8, "strategies_done")
            except Exception:
                pass

    # ã‚·ã‚¹ãƒ†ãƒ åˆ¥ã®é †åºã‚’æ˜ç¤ºï¼ˆ1..7ï¼‰ã«å›ºå®š
    order_1_7 = [f"system{i}" for i in range(1, 8)]
    per_system = {k: per_system.get(k, pd.DataFrame()) for k in order_1_7 if k in per_system}

    # ä¸¦åˆ—å®Ÿè¡Œæ™‚ã¯ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰ã® UI æ›´æ–°ãŒæŠ‘åˆ¶ã•ã‚Œã‚‹ãŸã‚ã€
    # ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å€™è£œä»¶æ•°ï¼ˆTRDlistï¼‰ã‚’75%æ®µéšã¨ã—ã¦é€šçŸ¥ã™ã‚‹
    try:
        cb2 = globals().get("_PER_SYSTEM_STAGE")
    except Exception:
        cb2 = None
    if cb2 and callable(cb2):
        try:
            # UIã®TRDlistè¡¨ç¤ºã¯æœ€å¤§ãƒã‚¸ã‚·ãƒ§ãƒ³æ•°ã‚’è¶…ãˆãªã„ã‚ˆã†ä¸¸ã‚ã‚‹
            try:
                _mx = int(get_settings(create_dirs=False).risk.max_positions)
            except Exception:
                _mx = 10
            for _name in order_1_7:
                # ãƒ¯ãƒ¼ã‚«ãƒ¼ã‹ã‚‰ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆãŒã‚ã‚Œã°å„ªå…ˆï¼ˆå‹ã‚†ã‚‰ãç­‰ã‚’è¶…ãˆã¦ä¿¡é ¼ã§ãã‚‹å€¤ï¼‰
                _cand_cnt = None
                try:
                    _cand_cnt = int(_CAND_COUNT_SNAPSHOT.get(_name))
                except Exception:
                    _cand_cnt = None
                if _cand_cnt is None:
                    _df_sys = per_system.get(_name, pd.DataFrame())
                    _cand_cnt = int(
                        0 if _df_sys is None or getattr(_df_sys, "empty", True) else len(_df_sys)
                    )
                if _mx > 0:
                    _cand_cnt = min(int(_cand_cnt), int(_mx))
                cb2(_name, 75, None, None, int(_cand_cnt), None)
        except Exception:
            pass

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜å‰ã«ã€å½“æ—¥ã®ãƒˆãƒ¬ãƒ¼ãƒ‰å€™è£œTop10ã‚’ç°¡æ˜“å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°/å¯è¦–åŒ–ç”¨ï¼‰
    try:
        all_rows: list[pd.DataFrame] = []
        for _sys_name, df in per_system.items():
            if df is None or df.empty:
                continue
            x = df.copy()
            if "score" in x.columns:
                try:
                    asc = False
                    if "score_key" in x.columns and len(x):
                        asc = _asc_by_score_key(str(x.iloc[0].get("score_key")))
                    x["_sort_val"] = x["score"].astype(float)
                    if not asc:
                        x["_sort_val"] = -x["_sort_val"]
                except Exception:
                    x["_sort_val"] = 0.0
            else:
                x["_sort_val"] = 0.0
            all_rows.append(x)
        if all_rows:
            merged = pd.concat(all_rows, ignore_index=True)
            merged = merged.sort_values("_sort_val", kind="stable", na_position="last")
            top10 = merged.head(10).drop(columns=["_sort_val"], errors="ignore")
            _log("ğŸ“ äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ(Top10, ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜å‰)")
            cols = [
                c
                for c in [
                    "symbol",
                    "system",
                    "side",
                    "entry_date",
                    "entry_price",
                    "stop_price",
                    "score_key",
                    "score",
                ]
                if c in top10.columns
            ]
            if not top10.empty:
                _log(top10[cols].to_string(index=False))
            else:
                _log("(å€™è£œãªã—)")
        # è¿½åŠ : ã‚·ã‚¹ãƒ†ãƒ åˆ¥ã®Top10ã‚’å€‹åˆ¥ã«å‡ºåŠ›ï¼ˆsystem2ã€œsystem6ï¼‰
        try:
            for _sys_name in [f"system{i}" for i in range(2, 7)]:
                _df = per_system.get(_sys_name, pd.DataFrame())
                _log(f"ğŸ“ äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ({_sys_name} Top10, ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜å‰)")
                if _df is None or getattr(_df, "empty", True):
                    _log("(å€™è£œãªã—)")
                    continue
                x = _df.copy()
                if "score" in x.columns:
                    try:
                        asc = False
                        if "score_key" in x.columns and len(x):
                            asc = _asc_by_score_key(str(x.iloc[0].get("score_key")))
                        x["_sort_val"] = x["score"].astype(float)
                        if not asc:
                            x["_sort_val"] = -x["_sort_val"]
                    except Exception:
                        x["_sort_val"] = 0.0
                else:
                    x["_sort_val"] = 0.0
                x = x.sort_values("_sort_val", kind="stable", na_position="last")
                top10_s = x.head(10).drop(columns=["_sort_val"], errors="ignore")
                cols_s = [
                    c
                    for c in [
                        "symbol",
                        "system",
                        "side",
                        "entry_date",
                        "entry_price",
                        "stop_price",
                        "score_key",
                        "score",
                    ]
                    if c in top10_s.columns
                ]
                if not top10_s.empty:
                    _log(top10_s[cols_s].to_string(index=False))
                else:
                    _log("(å€™è£œãªã—)")
        except Exception:
            pass
    except Exception:
        pass

    # --- æ—¥æ¬¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆäº‹å‰ãƒ•ã‚£ãƒ«ã‚¿é€šéæ•°ãƒ»å€™è£œæ•°ï¼‰ã®ä¿å­˜ ---
    try:
        metrics_rows = []
        # äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿é€šéæ•°ï¼ˆå­˜åœ¨ã—ãªã„ã‚·ã‚¹ãƒ†ãƒ ã¯0æ‰±ã„ï¼‰
        prefilter_map = {
            "system1": len(locals().get("system1_syms", []) or []),
            "system2": len(locals().get("system2_syms", []) or []),
            "system3": len(locals().get("system3_syms", []) or []),
            "system4": len(locals().get("system4_syms", []) or []),
            "system5": len(locals().get("system5_syms", []) or []),
            "system6": len(locals().get("system6_syms", []) or []),
            "system7": 1 if ("SPY" in (locals().get("basic_data", {}) or {})) else 0,
        }
        # å€™è£œæ•°ï¼ˆper_systemã®è¡Œæ•°ï¼‰
        for sys_name in order_1_7:
            df_sys = per_system.get(sys_name, pd.DataFrame())
            candidates = int(0 if df_sys is None or getattr(df_sys, "empty", True) else len(df_sys))
            pre_count = int(prefilter_map.get(sys_name, 0))
            metrics_rows.append(
                {
                    "date": locals().get("today"),
                    "system": sys_name,
                    "prefilter_pass": pre_count,
                    "candidates": candidates,
                }
            )
        if metrics_rows:
            metrics_df = pd.DataFrame(metrics_rows)
            try:
                settings_out = get_settings(create_dirs=True)
                out_dir = Path(settings_out.outputs.results_csv_dir)
            except Exception:
                out_dir = Path("results_csv")
            try:
                out_dir.mkdir(parents=True, exist_ok=True)
            except Exception:
                pass
            out_fp = out_dir / "daily_metrics.csv"
            try:
                if out_fp.exists():
                    metrics_df.to_csv(out_fp, mode="a", header=False, index=False, encoding="utf-8")
                else:
                    metrics_df.to_csv(out_fp, index=False, encoding="utf-8")
                _log(f"ğŸ“ˆ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜: {out_fp} ã« {len(metrics_rows)} è¡Œã‚’è¿½è¨˜")
            except Exception as e:
                _log(f"âš ï¸ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜ã«å¤±æ•—: {e}")
            # é€šçŸ¥: æœ€çµ‚ã‚¹ãƒ†ãƒ¼ã‚¸å½¢å¼ï¼ˆTgt/FILpass/STUpass/TRDlist/Entry/Exitï¼‰ã§é€ä¿¡
            try:
                # 0%ã®Tgtã¯ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ç·æ•°ï¼ˆSPYé™¤ãï¼‰
                try:
                    tgt_base = sum(1 for s in (symbols or []) if str(s).upper() != "SPY")
                except Exception:
                    tgt_base = len(symbols) if symbols is not None else 0
                    try:
                        if "SPY" in (symbols or []):
                            tgt_base = max(0, int(tgt_base) - 1)
                    except Exception:
                        pass

                # Exit ä»¶æ•°ã‚’ç°¡æ˜“æ¨å®šï¼ˆAlpaca ã®ä¿æœ‰ãƒã‚¸ã‚·ãƒ§ãƒ³ã¨å„ Strategy ã® compute_exit ã‚’åˆ©ç”¨ï¼‰
                def _estimate_exit_counts_today() -> dict[str, int]:
                    counts: dict[str, int] = {}
                    try:
                        # ä¾¡æ ¼ãƒ­ãƒ¼ãƒ‰é–¢æ•°ã¯å…±é€šãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’åˆ©ç”¨
                        from common.data_loader import load_price as _load_price  # lazy import

                        # SPY ã‹ã‚‰æœ¬æ—¥ã®åŸºæº–æ—¥ï¼ˆæœ€æ–°å–¶æ¥­æ—¥ï¼‰ã‚’æ¨å®š
                        latest_trading_day = None
                        try:
                            spy_df0 = _load_price("SPY", cache_profile="rolling")
                            if spy_df0 is not None and not spy_df0.empty:
                                latest_trading_day = pd.to_datetime(spy_df0.index[-1]).normalize()
                        except Exception:
                            latest_trading_day = None

                        # Alpaca ãƒã‚¸ã‚·ãƒ§ãƒ³å–å¾—ï¼ˆå¤±æ•—æ™‚ã¯ç©ºï¼‰
                        try:
                            client0 = ba.get_client(paper=True)
                            positions0 = list(client0.get_all_positions())
                        except Exception:
                            positions0 = []

                        # ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ—¥ã®ãƒ­ãƒ¼ã‚«ãƒ«è¨˜éŒ²ã¨ system æ¨å®šãƒãƒƒãƒ—
                        entry_map0 = load_entry_dates()
                        sym_map_path0 = Path("data/symbol_system_map.json")
                        try:
                            import json as _json

                            symbol_system_map0 = (
                                _json.loads(sym_map_path0.read_text(encoding="utf-8"))
                                if sym_map_path0.exists()
                                else {}
                            )
                        except Exception:
                            symbol_system_map0 = {}

                        for pos in positions0:
                            try:
                                sym = str(getattr(pos, "symbol", "")).upper()
                                if not sym:
                                    continue
                                qty = int(abs(float(getattr(pos, "qty", 0)) or 0))
                                if qty <= 0:
                                    continue
                                pos_side = str(getattr(pos, "side", "")).lower()
                                # system ã®æ¨å®š
                                system0 = str(symbol_system_map0.get(sym, "")).lower()
                                if not system0:
                                    if sym == "SPY" and pos_side == "short":
                                        system0 = "system7"
                                    else:
                                        continue
                                if system0 == "system7":
                                    continue
                                entry_date_str0 = entry_map0.get(sym)
                                if not entry_date_str0:
                                    continue
                                # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿èª­è¾¼ï¼ˆfullï¼‰
                                dfp = _load_price(sym, cache_profile="full")
                                if dfp is None or dfp.empty:
                                    continue
                                try:
                                    dfp2 = dfp.copy(deep=False)
                                    if "Date" in dfp2.columns:
                                        dfp2.index = pd.Index(
                                            pd.to_datetime(dfp2["Date"]).dt.normalize()
                                        )
                                    else:
                                        dfp2.index = pd.Index(
                                            pd.to_datetime(dfp2.index).normalize()
                                        )
                                except Exception:
                                    continue
                                if latest_trading_day is None and len(dfp2.index) > 0:
                                    latest_trading_day = pd.to_datetime(dfp2.index[-1]).normalize()
                                # ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ—¥ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
                                try:
                                    idx = dfp2.index
                                    ent_dt = pd.to_datetime(entry_date_str0).normalize()
                                    if ent_dt in idx:
                                        ent_arr = idx.get_indexer([ent_dt])
                                    else:
                                        ent_arr = idx.get_indexer([ent_dt], method="bfill")
                                    entry_idx0 = (
                                        int(ent_arr[0]) if len(ent_arr) and ent_arr[0] >= 0 else -1
                                    )
                                    if entry_idx0 < 0:
                                        continue
                                except Exception:
                                    continue

                                # Strategyæ¯ã® entry/stop ã‚’è¿‘ä¼¼ï¼ˆUIã¨åŒç­‰ã®ç°¡æ˜“ç‰ˆï¼‰
                                entry_price0 = None
                                stop_price0 = None
                                try:
                                    prev_close0 = float(
                                        dfp2.iloc[int(max(0, entry_idx0 - 1))]["Close"]
                                    )
                                    if system0 == "system1":
                                        stg0 = System1Strategy()
                                        entry_price0 = float(dfp2.iloc[int(entry_idx0)]["Open"])
                                        atr20 = float(
                                            dfp2.iloc[int(max(0, entry_idx0 - 1))]["ATR20"]
                                        )
                                        stop_mult0 = float(
                                            stg0.config.get("stop_atr_multiple", 5.0)
                                        )
                                        stop_price0 = entry_price0 - stop_mult0 * atr20
                                    elif system0 == "system2":
                                        stg0 = System2Strategy()
                                        entry_price0 = float(dfp2.iloc[int(entry_idx0)]["Open"])
                                        atr = float(dfp2.iloc[int(max(0, entry_idx0 - 1))]["ATR10"])
                                        stop_mult0 = float(
                                            stg0.config.get("stop_atr_multiple", 3.0)
                                        )
                                        stop_price0 = entry_price0 + stop_mult0 * atr
                                    elif system0 == "system6":
                                        stg0 = System6Strategy()
                                        ratio0 = float(
                                            stg0.config.get("entry_price_ratio_vs_prev_close", 1.05)
                                        )
                                        entry_price0 = round(prev_close0 * ratio0, 2)
                                        atr = float(dfp2.iloc[int(max(0, entry_idx0 - 1))]["ATR10"])
                                        stop_mult0 = float(
                                            stg0.config.get("stop_atr_multiple", 3.0)
                                        )
                                        stop_price0 = entry_price0 + stop_mult0 * atr
                                    elif system0 == "system3":
                                        stg0 = System3Strategy()
                                        ratio0 = float(
                                            stg0.config.get("entry_price_ratio_vs_prev_close", 0.93)
                                        )
                                        entry_price0 = round(prev_close0 * ratio0, 2)
                                        atr = float(dfp2.iloc[int(max(0, entry_idx0 - 1))]["ATR10"])
                                        stop_mult0 = float(
                                            stg0.config.get("stop_atr_multiple", 2.5)
                                        )
                                        stop_price0 = entry_price0 - stop_mult0 * atr
                                    elif system0 == "system4":
                                        stg0 = System4Strategy()
                                        entry_price0 = float(dfp2.iloc[int(entry_idx0)]["Open"])
                                        atr40 = float(
                                            dfp2.iloc[int(max(0, entry_idx0 - 1))]["ATR40"]
                                        )
                                        stop_mult0 = float(
                                            stg0.config.get("stop_atr_multiple", 1.5)
                                        )
                                        stop_price0 = entry_price0 - stop_mult0 * atr40
                                    elif system0 == "system5":
                                        stg0 = System5Strategy()
                                        ratio0 = float(
                                            stg0.config.get("entry_price_ratio_vs_prev_close", 0.97)
                                        )
                                        entry_price0 = round(prev_close0 * ratio0, 2)
                                        atr = float(dfp2.iloc[int(max(0, entry_idx0 - 1))]["ATR10"])
                                        stop_mult0 = float(
                                            stg0.config.get("stop_atr_multiple", 3.0)
                                        )
                                        stop_price0 = entry_price0 - stop_mult0 * atr
                                        try:
                                            stg0._last_entry_atr = atr  # type: ignore[attr-defined]
                                        except Exception:
                                            pass
                                    else:
                                        continue
                                except Exception:
                                    continue
                                if entry_price0 is None or stop_price0 is None:
                                    continue
                                try:
                                    exit_price0, exit_date0 = stg0.compute_exit(
                                        dfp2,
                                        int(entry_idx0),
                                        float(entry_price0),
                                        float(stop_price0),
                                    )
                                except Exception:
                                    continue
                                today_norm0 = pd.to_datetime(dfp2.index[-1]).normalize()
                                if latest_trading_day is not None:
                                    today_norm0 = latest_trading_day
                                is_today_exit0 = (
                                    pd.to_datetime(exit_date0).normalize() == today_norm0
                                )
                                if is_today_exit0:
                                    if system0 == "system5":
                                        # System5 ã¯ç¿Œæ—¥å¯„ã‚Šæ±ºæ¸ˆã®ãŸã‚ã‚«ã‚¦ãƒ³ãƒˆå¯¾è±¡å¤–
                                        pass
                                    else:
                                        counts[system0] = counts.get(system0, 0) + 1
                            except Exception:
                                continue
                    except Exception:
                        return {}
                    return counts

                exit_counts_map = _estimate_exit_counts_today()
                # UI ã¸ã‚‚ Exit ä»¶æ•°ã‚’é€ã‚‹ï¼ˆæ—©æœŸã«å¯è¦–åŒ–ï¼‰
                try:
                    cb_exit = globals().get("_PER_SYSTEM_EXIT")
                except Exception:
                    cb_exit = None
                if cb_exit and callable(cb_exit):
                    try:
                        for _nm, _cnt in (exit_counts_map or {}).items():
                            try:
                                cb_exit(_nm, int(_cnt))
                            except Exception:
                                pass
                    except Exception:
                        pass
                # æ—¢ã«é›†è¨ˆæ¸ˆã¿ã®å€¤ã‚’å†æ§‹æˆ
                setup_map = {
                    # System1 ã¯ SPY ã‚²ãƒ¼ãƒˆï¼ˆClose>SMA100ï¼‰ãŒå½ãªã‚‰ 0 æ‰±ã„
                    "system1": int(
                        (
                            locals().get("s1_setup")
                            if (
                                (locals().get("_spy_ok") is None)
                                or (int(locals().get("_spy_ok", 0)) == 1)
                            )
                            else 0
                        )
                        or 0
                    ),
                    "system2": int(max(locals().get("s2_rsi", 0), locals().get("s2_up2", 0))),
                    "system3": int(max(locals().get("s3_close", 0), locals().get("s3_drop", 0))),
                    "system4": int(locals().get("s4_close") or 0),
                    "system5": int(locals().get("s5_close") or 0),
                    "system6": int(max(locals().get("s6_ret", 0), locals().get("s6_up2", 0))),
                    "system7": 1 if ("SPY" in (locals().get("basic_data", {}) or {})) else 0,
                }
                final_counts = {}
                try:
                    _final_df = locals().get("final_df")
                    if (
                        _final_df is not None
                        and not getattr(_final_df, "empty", True)
                        and "system" in _final_df.columns
                    ):
                        final_counts = _final_df.groupby("system").size().to_dict()
                except Exception:
                    final_counts = {}
                lines = []
                for sys_name in order_1_7:
                    tgt = tgt_base if sys_name != "system7" else 1
                    fil = int(prefilter_map.get(sys_name, 0))
                    stu = int(setup_map.get(sys_name, 0))
                    try:
                        _df_trd = per_system.get(sys_name, pd.DataFrame())
                        trd = int(
                            0
                            if _df_trd is None or getattr(_df_trd, "empty", True)
                            else len(_df_trd)
                        )
                    except Exception:
                        trd = 0
                    ent = int(final_counts.get(sys_name, 0))
                    exv = exit_counts_map.get(sys_name)
                    ex_txt = "-" if exv is None else str(int(exv))
                    value = (
                        f"Tgt {tgt} / FIL {fil} / STU {stu} / "
                        f"TRD {trd} / Entry {ent} / Exit {ex_txt}"
                    )
                    lines.append({"name": sys_name, "value": value})
                title = "ğŸ“ˆ æœ¬æ—¥ã®æœ€çµ‚ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆsystemåˆ¥ï¼‰"
                _td = locals().get("today")
                try:
                    _td_str = str(getattr(_td, "date", lambda: None)() or _td)
                except Exception:
                    _td_str = ""
                # fields ã«å„systemã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æ·»ä»˜ã™ã‚‹ãŸã‚ã€æœ¬æ–‡ã¯ç°¡æ½”ã«ã™ã‚‹
                msg = f"å¯¾è±¡æ—¥: {_td_str}"
                notifier = create_notifier(platform="auto", fallback=True)
                notifier.send(title, msg, fields=lines)
            except Exception:
                pass
        # ç°¡æ˜“ãƒ­ã‚°
        try:
            summary = ", ".join(
                [
                    (
                        f"{r['system']}: å¯¾è±¡â†’{r['prefilter_pass']}, "
                        f"tradeå€™è£œæ•°â†’{r['candidates']}"
                    )
                    for r in metrics_rows
                ]
            )
            if summary:
                _log(f"ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ¦‚è¦: {summary}")
        except Exception:
            pass
    except Exception:
        _log("âš ï¸ ãƒ¡ãƒˆãƒªã‚¯ã‚¹é›†è¨ˆã§ä¾‹å¤–ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆå‡¦ç†ç¶šè¡Œï¼‰")

    # 1) æ é…åˆ†ï¼ˆã‚¹ãƒ­ãƒƒãƒˆï¼‰ãƒ¢ãƒ¼ãƒ‰ or 2) é‡‘é¡é…åˆ†ãƒ¢ãƒ¼ãƒ‰
    def _normalize_alloc(d: dict[str, float], default_map: dict[str, float]) -> dict[str, float]:
        try:
            filtered = {k: float(v) for k, v in d.items() if float(v) > 0}
            s = sum(filtered.values())
            if s <= 0:
                filtered = default_map
                s = sum(filtered.values())
            return {k: v / s for k, v in filtered.items()}
        except Exception:
            s = sum(default_map.values())
            return {k: v / s for k, v in default_map.items()}

    defaults_long = {"system1": 0.25, "system3": 0.25, "system4": 0.25, "system5": 0.25}
    defaults_short = {"system2": 0.40, "system6": 0.40, "system7": 0.20}
    try:
        settings_alloc_long = getattr(settings.ui, "long_allocations", {}) or {}
        settings_alloc_short = getattr(settings.ui, "short_allocations", {}) or {}
    except Exception:
        settings_alloc_long, settings_alloc_short = {}, {}
    long_alloc = _normalize_alloc(settings_alloc_long, defaults_long)
    short_alloc = _normalize_alloc(settings_alloc_short, defaults_short)

    _log("ğŸ§· å€™è£œã®é…åˆ†ï¼ˆã‚¹ãƒ­ãƒƒãƒˆæ–¹å¼ or é‡‘é¡é…åˆ†ï¼‰ã‚’å®Ÿè¡Œ")
    if capital_long is None and capital_short is None:
        # æ—§ã‚¹ãƒ­ãƒƒãƒˆæ–¹å¼ï¼ˆå¾Œæ–¹äº’æ›ï¼‰
        max_pos = int(settings.risk.max_positions)
        slots_long = slots_long if slots_long is not None else max_pos
        slots_short = slots_short if slots_short is not None else max_pos

        def _distribute_slots(
            weights: dict[str, float], total_slots: int, counts: dict[str, int]
        ) -> dict[str, int]:
            base = {k: int(total_slots * weights.get(k, 0.0)) for k in weights}
            for k in list(base.keys()):
                if counts.get(k, 0) <= 0:
                    base[k] = 0
                elif base[k] == 0:
                    base[k] = 1
            used = sum(base.values())
            remain = max(0, total_slots - used)
            if remain > 0:
                order = sorted(
                    weights.keys(),
                    key=lambda k: (counts.get(k, 0), weights.get(k, 0.0)),
                    reverse=True,
                )
                idx = 0
                while remain > 0 and order:
                    k = order[idx % len(order)]
                    if counts.get(k, 0) > base.get(k, 0):
                        base[k] += 1
                        remain -= 1
                    idx += 1
                    if idx > 10000:
                        break
            for k in list(base.keys()):
                base[k] = min(base[k], counts.get(k, 0))
            return base

        long_counts = {k: len(per_system.get(k, pd.DataFrame())) for k in long_alloc}
        short_counts = {k: len(per_system.get(k, pd.DataFrame())) for k in short_alloc}
        _log(
            "ğŸ§® æ é…åˆ†: "
            + ", ".join([f"{k}={long_counts.get(k, 0)}" for k in long_alloc])
            + " | "
            + ", ".join([f"{k}={short_counts.get(k, 0)}" for k in short_alloc])
        )
        long_slots = _distribute_slots(long_alloc, slots_long, long_counts)
        short_slots = _distribute_slots(short_alloc, slots_short, short_counts)

        chosen_frames: list[pd.DataFrame] = []
        for name, slot in {**long_slots, **short_slots}.items():
            df = per_system.get(name, pd.DataFrame())
            if df is None or df.empty or slot <= 0:
                continue
            take = df.head(slot).copy()
            take["alloc_weight"] = (
                long_alloc.get(name) or short_alloc.get(name) or 0.0
            )  # noqa: E501
            chosen_frames.append(take)
        final_df = (
            pd.concat(chosen_frames, ignore_index=True)
            if chosen_frames
            else pd.DataFrame()  # noqa: E501
        )
    else:
        # é‡‘é¡é…åˆ†ãƒ¢ãƒ¼ãƒ‰
        _settings = get_settings(create_dirs=False)
        _default_cap = float(getattr(_settings.ui, "default_capital", 100000))
        _ratio = float(getattr(_settings.ui, "default_long_ratio", 0.5))

        _cl = None if capital_long is None or float(capital_long) <= 0 else float(capital_long)
        _cs = None if capital_short is None or float(capital_short) <= 0 else float(capital_short)

        if _cl is None and _cs is None:
            total = _default_cap
            capital_long = total * _ratio
            capital_short = total * (1.0 - _ratio)
        elif _cl is None and _cs is not None:
            total = _cs
            capital_long = total * _ratio
            capital_short = total * (1.0 - _ratio)
        elif _cs is None and _cl is not None:
            total = _cl
            capital_long = total * _ratio
            capital_short = total * (1.0 - _ratio)
        else:
            # mypy/pyrightå¯¾å¿œï¼ˆã“ã®åˆ†å²ã§ã¯ None ã«ãªã‚‰ãªã„ï¼‰
            from typing import cast as _cast

            capital_long = float(_cast(float, capital_long))
            capital_short = float(_cast(float, capital_short))

        strategies_map = {k: v for k, v in strategies.items()}
        _log(f"ğŸ’° é‡‘é¡é…åˆ†: long=${capital_long}, short=${capital_short}")
        # å‚è€ƒ: ã‚·ã‚¹ãƒ†ãƒ åˆ¥ã®äºˆç®—å†…è¨³ã‚’å‡ºåŠ›
        try:
            long_budgets = {
                k: float(capital_long) * float(long_alloc.get(k, 0.0)) for k in long_alloc
            }
            short_budgets = {
                k: float(capital_short) * float(short_alloc.get(k, 0.0)) for k in short_alloc
            }
            _log(
                "ğŸ“Š longäºˆç®—å†…è¨³: " + ", ".join([f"{k}=${v:,.0f}" for k, v in long_budgets.items()])
            )
            _log(
                "ğŸ“Š shortäºˆç®—å†…è¨³: "
                + ", ".join([f"{k}=${v:,.0f}" for k, v in short_budgets.items()])
            )
        except Exception:
            pass
        long_df = _amount_pick(
            {k: per_system.get(k, pd.DataFrame()) for k in long_alloc},
            strategies_map,
            float(capital_long),
            long_alloc,
            side="long",
        )
        short_df = _amount_pick(
            {k: per_system.get(k, pd.DataFrame()) for k in short_alloc},
            strategies_map,
            float(capital_short),
            short_alloc,
            side="short",
        )
        parts = [df for df in [long_df, short_df] if df is not None and not df.empty]  # noqa: E501
        final_df = pd.concat(parts, ignore_index=True) if parts else pd.DataFrame()  # noqa: E501

        # å„ã‚·ã‚¹ãƒ†ãƒ ã®æœ€å¤§ãƒã‚¸ã‚·ãƒ§ãƒ³ä¸Šé™=10 ã‚’å³æ ¼åŒ–
        if not final_df.empty and "system" in final_df.columns:
            final_df = (
                final_df.sort_values(["system", "score"], ascending=[True, True])
                .groupby("system", as_index=False, group_keys=False)
                .head(int(get_settings(create_dirs=False).risk.max_positions))
                .reset_index(drop=True)
            )

    if not final_df.empty:
        # ä¸¦ã³ã¯ side â†’ systemç•ªå· â†’ å„systemã®ã‚¹ã‚³ã‚¢æ–¹å‘ï¼ˆRSIç³»ã®ã¿æ˜‡é †ã€ãã‚Œä»¥å¤–ã¯é™é †ï¼‰
        tmp = final_df.copy()
        if "system" in tmp.columns:
            try:
                tmp["_system_no"] = (
                    tmp["system"].astype(str).str.extract(r"(\d+)").fillna(0).astype(int)
                )
            except Exception:
                tmp["_system_no"] = 0
        # ä¸€æ—¦ side, system ç•ªå·ã§å®‰å®šã‚½ãƒ¼ãƒˆ
        tmp = tmp.sort_values(
            [c for c in ["side", "_system_no"] if c in tmp.columns], kind="stable"
        )
        # system ã”ã¨ã« score ã‚’æ–¹å‘æŒ‡å®šã§ä¸¦ã¹æ›¿ãˆ
        try:
            parts2: list[pd.DataFrame] = []
            for sys_name, g in tmp.groupby("system", sort=False):
                if "score" in g.columns:
                    asc = False
                    try:
                        # system4ï¼ˆRSIç³»ï¼‰ã¯ã‚¹ã‚³ã‚¢å°ã•ã„ã»ã©è‰¯ã„
                        if isinstance(sys_name, str) and sys_name.lower() == "system4":
                            asc = True
                    except Exception:
                        asc = False
                    g = g.sort_values("score", ascending=asc, na_position="last", kind="stable")
                parts2.append(g)
            tmp = pd.concat(parts2, ignore_index=True)
        except Exception:
            pass
        tmp = tmp.drop(columns=["_system_no"], errors="ignore")
        final_df = tmp.reset_index(drop=True)
        # å…ˆé ­ã«é€£ç•ªï¼ˆ1å§‹ã¾ã‚Šï¼‰ã‚’ä»˜ä¸
        try:
            final_df.insert(0, "no", range(1, len(final_df) + 1))
        except Exception:
            pass
        # systemåˆ¥ã®ä»¶æ•°/é‡‘é¡ã‚µãƒãƒªã‚’å‡ºåŠ›
        try:
            if "position_value" in final_df.columns:
                grp = (
                    final_df.groupby("system")["position_value"].agg(["count", "sum"]).reset_index()
                )
                parts = [
                    f"{r['system']}: {int(r['count'])}ä»¶ / ${float(r['sum']):,.0f}"
                    for _, r in grp.iterrows()
                ]
                _log("ğŸ§¾ systemåˆ¥ã‚µãƒãƒª: " + ", ".join(parts))
            else:
                grp = final_df.groupby("system").size().to_dict()
                _log("ğŸ§¾ systemåˆ¥ã‚µãƒãƒª: " + ", ".join([f"{k}: {v}ä»¶" for k, v in grp.items()]))
            # system ã”ã¨ã®æœ€çµ‚ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ•°ã‚’å‡ºåŠ›
            try:
                if isinstance(grp, dict):
                    for k, v in grp.items():
                        _log(f"âœ… {k}: {int(v)} ä»¶")
                else:
                    for _, r in grp.iterrows():
                        _log(f"âœ… {r['system']}: {int(r['count'])} ä»¶")
            except Exception:
                pass
            # è¿½åŠ : ã‚¨ãƒ³ãƒˆãƒªãƒ¼éŠ˜æŸ„ã® system ã”ã¨ã®ã¾ã¨ã‚
            try:
                lines = []
                for sys_name, g in final_df.groupby("system"):
                    syms = ", ".join(list(g["symbol"].astype(str))[:20])
                    lines.append(f"{sys_name}: {syms}")
                if lines:
                    _log("ğŸ§¾ ã‚¨ãƒ³ãƒˆãƒªãƒ¼å†…è¨³:\n" + "\n".join(lines))
            except Exception:
                pass
        except Exception:
            pass
        _log(f"ğŸ“Š æœ€çµ‚å€™è£œä»¶æ•°: {len(final_df)}")
    else:
        _log("ğŸ“­ æœ€çµ‚å€™è£œã¯0ä»¶ã§ã—ãŸ")
    if progress_callback:
        try:
            progress_callback(7, 8, "finalize")
        except Exception:
            pass

    # æœ€çµ‚æ¡ç”¨ä»¶æ•°ï¼ˆEntryï¼‰ã‚’100%æ®µéšã¨ã—ã¦é€šçŸ¥ï¼ˆUI ã‚«ã‚¦ãƒ³ã‚¿æ•´åˆï¼‰
    try:
        cb2 = globals().get("_PER_SYSTEM_STAGE")
    except Exception:
        cb2 = None
    if cb2 and callable(cb2):
        try:
            # per-system å€™è£œï¼ˆTRDlistï¼‰ã¯ä¸Šã§é€šçŸ¥æ¸ˆã¿ã€‚ã“ã“ã§ã¯æœ€çµ‚æ¡ç”¨æ•°ã‚’æ¸¡ã™ã€‚
            final_counts: dict[str, int] = {}
            try:
                if (
                    final_df is not None
                    and not getattr(final_df, "empty", True)
                    and "system" in final_df.columns
                ):
                    final_counts = (
                        final_df.groupby("system").size().to_dict()  # type: ignore[assignment]
                    )
            except Exception:
                final_counts = {}
            for _name in order_1_7:
                _df_sys = per_system.get(_name, pd.DataFrame())
                _cand_cnt = int(
                    0 if _df_sys is None or getattr(_df_sys, "empty", True) else len(_df_sys)
                )
                _final_cnt = int(final_counts.get(_name, 0))
                cb2(_name, 100, None, None, _cand_cnt, _final_cnt)
        except Exception:
            pass

    # é€šçŸ¥ã¯ progress_callback ã®æœ‰ç„¡ã«é–¢ä¿‚ãªãå®Ÿè¡Œã™ã‚‹
    if notify:
        try:
            from tools.notify_signals import send_signal_notification

            send_signal_notification(final_df)
        except Exception:
            _log("âš ï¸ é€šçŸ¥ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # CSV ä¿å­˜ï¼ˆä»»æ„ï¼‰
    if save_csv and not final_df.empty:
        # ãƒ•ã‚¡ã‚¤ãƒ«åãƒ¢ãƒ¼ãƒ‰: date(YYYY-MM-DD) | datetime(YYYY-MM-DD_HHMM) | runid(YYYY-MM-DD_RUNID)
        mode = (csv_name_mode or "date").lower()
        date_str = today.strftime("%Y-%m-%d")
        suffix = date_str
        if mode == "datetime":
            try:
                jst_now = datetime.now(ZoneInfo("Asia/Tokyo"))
            except Exception:
                jst_now = datetime.now()
            suffix = f"{date_str}_{jst_now.strftime('%H%M')}"
        elif mode == "runid":
            try:
                # _run_id ã¯æœ¬é–¢æ•°å…ˆé ­ã§æ¡ç•ªæ¸ˆã¿
                suffix = f"{date_str}_{_run_id}"
            except Exception:
                suffix = date_str

        out_all = signals_dir / f"signals_final_{suffix}.csv"
        final_df.to_csv(out_all, index=False)
        # ã‚·ã‚¹ãƒ†ãƒ åˆ¥
        for name, df in per_system.items():
            if df is None or df.empty:
                continue
            out = signals_dir / f"signals_{name}_{suffix}.csv"
            df.to_csv(out, index=False)
        _log(f"ğŸ’¾ ä¿å­˜: {signals_dir} ã«CSVã‚’æ›¸ãå‡ºã—ã¾ã—ãŸ")
    if progress_callback:
        try:
            progress_callback(8, 8, "done")
        except Exception:
            pass

    # çµ‚äº†ãƒ­ã‚°ï¼ˆUI/CLI åŒæ–¹ã§è¨˜éŒ²ã•ã‚Œã‚‹ï¼‰
    try:
        cnt = 0 if final_df is None else len(final_df)
        _log(f"âœ… ã‚·ã‚°ãƒŠãƒ«æ¤œå‡ºå‡¦ç† çµ‚äº† | æœ€çµ‚å€™è£œ {cnt} ä»¶")
    except Exception:
        pass

    # === CLI ãƒãƒŠãƒ¼ï¼ˆçµ‚äº†ã®æ˜ç¢ºåŒ–ï¼‰===
    try:
        import time as _time

        _end_txt = _time.strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        _end_txt = ""
    try:
        print("#" * 68, flush=True)
    except Exception:
        pass
    _log("# ğŸğŸğŸ  æœ¬æ—¥ã®ã‚·ã‚°ãƒŠãƒ« å®Ÿè¡Œçµ‚äº† (Engine)  ğŸğŸğŸ", ui=False)
    _log(f"# â±ï¸ {_end_txt} | RUN-ID: {_run_id}", ui=False)
    try:
        print("#" * 68 + "\n", flush=True)
    except Exception:
        pass

    # clear callback
    try:
        globals().pop("_LOG_CALLBACK", None)
    except Exception:
        pass

    return final_df, per_system


def main():
    parser = argparse.ArgumentParser(description="å…¨ã‚·ã‚¹ãƒ†ãƒ å½“æ—¥ã‚·ã‚°ãƒŠãƒ«æŠ½å‡ºãƒ»é›†ç´„")
    parser.add_argument(
        "--symbols",
        nargs="*",
        help="å¯¾è±¡ã‚·ãƒ³ãƒœãƒ«ã€‚æœªæŒ‡å®šãªã‚‰è¨­å®šã®auto_tickersã‚’ä½¿ç”¨",
    )
    parser.add_argument(
        "--slots-long",
        type=int,
        default=None,
        help="è²·ã„ã‚µã‚¤ãƒ‰ã®æœ€å¤§æ¡ç”¨æ•°ï¼ˆã‚¹ãƒ­ãƒƒãƒˆæ–¹å¼ï¼‰",
    )
    parser.add_argument(
        "--slots-short",
        type=int,
        default=None,
        help="å£²ã‚Šã‚µã‚¤ãƒ‰ã®æœ€å¤§æ¡ç”¨æ•°ï¼ˆã‚¹ãƒ­ãƒƒãƒˆæ–¹å¼ï¼‰",
    )
    parser.add_argument(
        "--capital-long",
        type=float,
        default=None,
        help=("è²·ã„ã‚µã‚¤ãƒ‰äºˆç®—ï¼ˆãƒ‰ãƒ«ï¼‰ã€‚" "æŒ‡å®šæ™‚ã¯é‡‘é¡é…åˆ†ãƒ¢ãƒ¼ãƒ‰"),
    )
    parser.add_argument(
        "--capital-short",
        type=float,
        default=None,
        help=("å£²ã‚Šã‚µã‚¤ãƒ‰äºˆç®—ï¼ˆãƒ‰ãƒ«ï¼‰ã€‚" "æŒ‡å®šæ™‚ã¯é‡‘é¡é…åˆ†ãƒ¢ãƒ¼ãƒ‰"),
    )
    parser.add_argument(
        "--save-csv",
        action="store_true",
        help="signalsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«CSVã‚’ä¿å­˜ã™ã‚‹",
    )
    parser.add_argument(
        "--parallel",
        action="store_true",
        help="ã‚·ã‚¹ãƒ†ãƒ ã”ã¨ã®å½“æ—¥ã‚·ã‚°ãƒŠãƒ«æŠ½å‡ºã‚’ä¸¦åˆ—å®Ÿè¡Œã™ã‚‹",
    )
    # Alpaca è‡ªå‹•ç™ºæ³¨ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        "--alpaca-submit",
        action="store_true",
        help="Alpaca ã«è‡ªå‹•ç™ºæ³¨ï¼ˆshares å¿…é ˆï¼‰",
    )
    parser.add_argument(
        "--order-type",
        choices=["market", "limit"],
        default="market",
        help="æ³¨æ–‡ç¨®åˆ¥",
    )
    parser.add_argument(
        "--tif",
        choices=["GTC", "DAY"],
        default="GTC",
        help="Time In Force",
    )
    parser.add_argument(
        "--live",
        action="store_true",
        help="ãƒ©ã‚¤ãƒ–å£åº§ã§ç™ºæ³¨ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Paperï¼‰",
    )
    parser.add_argument(
        "--log-file-mode",
        choices=["single", "dated"],
        default=None,
        help="ãƒ­ã‚°ä¿å­˜å½¢å¼: single=å›ºå®š today_signals.log / dated=æ—¥ä»˜åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«",
    )
    parser.add_argument(
        "--csv-name-mode",
        choices=["date", "datetime", "runid"],
        default=None,
        help=(
            "CSVãƒ•ã‚¡ã‚¤ãƒ«åã®å½¢å¼: date=YYYY-MM-DD / "
            "datetime=YYYY-MM-DD_HHMM / runid=YYYY-MM-DD_RUNID"
        ),
    )
    args = parser.parse_args()

    # ãƒ­ã‚°ä¿å­˜å½¢å¼ã‚’æ±ºå®šï¼ˆCLI > ç’°å¢ƒå¤‰æ•° > æ—¢å®šï¼‰
    env_mode = os.environ.get("TODAY_SIGNALS_LOG_MODE", "").strip().lower()
    mode = args.log_file_mode or (env_mode if env_mode in {"single", "dated"} else None) or "dated"
    _configure_today_logger(mode=mode)
    try:
        sel_path = globals().get("_LOG_FILE_PATH")
        _log(f"ğŸ“ ãƒ­ã‚°ä¿å­˜å…ˆ: {sel_path}", ui=False)
    except Exception:
        pass

    final_df, per_system = compute_today_signals(
        args.symbols,
        slots_long=args.slots_long,
        slots_short=args.slots_short,
        capital_long=args.capital_long,
        capital_short=args.capital_short,
        save_csv=args.save_csv,
        csv_name_mode=args.csv_name_mode,
        parallel=args.parallel,
    )

    if final_df.empty:
        _log("ğŸ“­ æœ¬æ—¥ã®æœ€çµ‚å€™è£œã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        _log("\n=== æœ€çµ‚å€™è£œï¼ˆæ¨å¥¨ï¼‰ ===")
        cols = [
            "symbol",
            "system",
            "side",
            "signal_type",
            "entry_date",
            "entry_price",
            "stop_price",
            "shares",
            "position_value",
            "score_key",
            "score",
        ]
        show = [c for c in cols if c in final_df.columns]
        _log(final_df[show].to_string(index=False))
        signals_for_merge = [
            Signal(
                system_id=int(str(r.get("system")).replace("system", "") or 0),
                symbol=str(r.get("symbol")),
                side="BUY" if str(r.get("side")).lower() == "long" else "SELL",
                strength=float(r.get("score", 0.0)),
                meta={},
            )
            for _, r in final_df.iterrows()
        ]
        merge_signals([signals_for_merge], portfolio_state={}, market_state={})
        if args.alpaca_submit:
            # CLIã§ã‚‚å…±é€šãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚’ä½¿ç”¨
            submit_orders_df(
                final_df,
                paper=(not args.live),
                order_type=args.order_type,
                system_order_type=None,
                tif=args.tif,
                retries=2,
                delay=0.5,
                log_callback=_log,
                notify=True,
            )


if __name__ == "__main__":
    main()
