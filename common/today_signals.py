from __future__ import annotations

from collections.abc import Callable
from dataclasses import dataclass, field
import inspect
import math
import os
from pathlib import Path
import time as _t
from typing import Any, Mapping, cast

import numpy as np
import pandas as pd

from common.indicator_access import get_indicator, to_float

try:
    from common.dataframe_utils import round_dataframe
except Exception:  # pragma: no cover - tests may stub cache_manager

    def round_dataframe(df: pd.DataFrame, decimals: int | None) -> pd.DataFrame:
        if decimals is None:
            return df
        try:
            decimals_int = int(decimals)
        except Exception:
            return df
        try:
            return df.copy().round(decimals_int)
        except Exception:
            try:
                return df.round(decimals_int)
            except Exception:
                return df


from common.utils_spy import (
    get_latest_nyse_trading_day,
    get_signal_target_trading_day,
    get_spy_with_indicators,
)
from config.settings import get_settings
from core.system1 import system1_row_passes_setup
from core.system5 import DEFAULT_ATR_PCT_THRESHOLD, format_atr_pct_threshold_label
from strategies.constants import (
    STOP_ATR_MULTIPLE_DEFAULT,
    STOP_ATR_MULTIPLE_SYSTEM1,
    STOP_ATR_MULTIPLE_SYSTEM3,
    STOP_ATR_MULTIPLE_SYSTEM4,
)

# --- Module-level flags (one-time notices) ----------------------------------
# ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®é®®åº¦è¨±å®¹ç·©å’Œãƒ­ã‚°ã¯1ãƒ—ãƒ­ã‚»ã‚¹ä¸­ã«1å›ã ã‘è¡¨ç¤ºã™ã‚‹
_TEST_MODE_FRESHNESS_LOGGED: bool = False


# --- CLIç”¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ­ã‚°é–¢æ•° -----------------------------------------------
def _default_cli_log(message: str) -> None:
    """log_callbackæœªæŒ‡å®šæ™‚ã«CLIã¸ç¢ºå®Ÿã«å‡ºåŠ›ã™ã‚‹ãŸã‚ã®ç°¡æ˜“ãƒ—ãƒªãƒ³ã‚¿ã€‚

    - æ–‡å­—åŒ–ã‘/ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ä¾‹å¤–ã‚’é¿ã‘ã‚‹ãŸã‚ã€å¤±æ•—æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¦å‡ºåŠ›ã€‚
    - flush=True ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«è¡¨ç¤ºã€‚
    """
    try:
        print(str(message), flush=True)
    except Exception:
        try:
            # æœ€ä½é™ã®ASCIIã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            safe = str(message).encode("ascii", errors="replace").decode("ascii")
            print(safe, flush=True)
        except Exception:
            pass


# --- ã‚µã‚¤ãƒ‰å®šç¾©ï¼ˆå£²è²·åŒºåˆ†ï¼‰---
# System1/3/4/5 ã¯è²·ã„æˆ¦ç•¥ã€System2/6/7 ã¯å£²ã‚Šæˆ¦ç•¥ã¨ã—ã¦æ‰±ã†ã€‚
# ä»•æ§˜ï¼ˆdocsï¼‰ã«åˆã‚ã›ã¦ system4 ã¯ãƒ­ãƒ³ã‚°ã«ä¿®æ­£ã€‚
LONG_SYSTEMS = {"system1", "system3", "system4", "system5"}
SHORT_SYSTEMS = {"system2", "system6", "system7"}

STOP_MULTIPLIER_BY_SYSTEM: dict[str, float] = {
    "system1": STOP_ATR_MULTIPLE_SYSTEM1,
    "system2": STOP_ATR_MULTIPLE_DEFAULT,
    "system3": STOP_ATR_MULTIPLE_SYSTEM3,
    "system4": STOP_ATR_MULTIPLE_SYSTEM4,
    "system5": STOP_ATR_MULTIPLE_DEFAULT,
    "system6": STOP_ATR_MULTIPLE_DEFAULT,
    "system7": STOP_ATR_MULTIPLE_DEFAULT,
}

TODAY_SIGNAL_COLUMNS = [
    "symbol",
    "system",
    "side",
    "signal_type",
    "entry_date",
    "entry_price",
    "stop_price",
    "score_key",
    "score",
    "score_rank",
    "score_rank_total",
    "reason",
]

TODAY_TOP_N = 10


@dataclass(frozen=True)
class TodaySignal:
    symbol: str
    system: str
    side: str  # "long" | "short"
    signal_type: str  # "buy" | "sell"
    entry_date: pd.Timestamp
    entry_price: float
    stop_price: float
    score_key: str | None = None
    score: float | None = None
    score_rank: int | None = None
    score_rank_total: int | None = None
    reason: str | None = None
    # é…åˆ†è¨ˆç®—ç”¨ATRå€¤ï¼ˆã‚·ã‚¹ãƒ†ãƒ ã”ã¨ã«ç•°ãªã‚‹ATRã‚’ä½¿ç”¨ï¼‰
    atr10: float | None = None  # System2/3/5/6ã§ä½¿ç”¨
    atr20: float | None = None  # System1ã§ä½¿ç”¨
    atr40: float | None = None  # System4ã§ä½¿ç”¨
    atr50: float | None = None  # System7ã§ä½¿ç”¨


@dataclass
class SkipStats:
    counts: dict[str, int] = field(default_factory=dict)
    samples: dict[str, list[str]] = field(default_factory=dict)
    details: list[dict[str, str]] = field(default_factory=list)

    def record(self, symbol: str, reason: str) -> None:
        reason = str(reason or "unknown")
        symbol = str(symbol or "")
        self.counts[reason] = self.counts.get(reason, 0) + 1
        if symbol:
            bucket = self.samples.setdefault(reason, [])
            if len(bucket) < 5 and symbol not in bucket:
                bucket.append(symbol)
        try:
            self.details.append({"symbol": symbol, "reason": reason})
        except Exception:
            pass

    def callback(self) -> Callable[..., None]:
        def _on_skip(*args: Any, **kwargs: Any) -> None:
            try:
                if len(args) >= 2:
                    symbol = str(args[0])
                    reason = str(args[1])
                elif len(args) == 1:
                    txt = str(args[0])
                    if ":" in txt:
                        symbol, reason = (txt.split(":", 1) + [""])[:2]
                        symbol = symbol.strip()
                        reason = reason.strip()
                    else:
                        symbol = ""
                        reason = txt.strip()
                else:
                    reason = str(kwargs.get("reason", "unknown"))
                    symbol = str(kwargs.get("symbol", ""))
            except Exception:
                reason = "unknown"
                symbol = ""
            self.record(symbol, reason)

        return _on_skip

    def log_summary(
        self,
        system_name: str,
        log_callback: Callable[[str], None] | None,
    ) -> None:
        if not self.counts:
            return
        try:
            sorted_items = sorted(self.counts.items(), key=lambda x: x[1], reverse=True)
        except Exception:
            sorted_items = list(self.counts.items())
        top = sorted_items[:2]
        system_label = str(system_name or "")
        try:
            total = sum(int(v) for _, v in self.counts.items())
        except Exception:
            try:
                total = sum(self.counts.values())
            except Exception:
                total = len(self.counts)
        if log_callback:
            try:
                details = ", ".join([f"{k}: {v}" for k, v in top])
                prefix = f"{system_label}: " if system_label else ""
                log_callback(f"ğŸ§ª {prefix}ã‚¹ã‚­ãƒƒãƒ—çµ±è¨ˆ (è¨ˆ{total}ä»¶): {details}")
                for key, _ in top:
                    samples = self.samples.get(key) or []
                    if samples:
                        log_callback(f"  â†³ ({key}): {', '.join(samples)}")
            except Exception:
                pass
        self._persist_to_csv(system_name, log_callback, sorted_items)

    def _persist_to_csv(
        self,
        system_name: str,
        log_callback: Callable[[str], None] | None,
        sorted_items: list[tuple[str, int]],
    ) -> None:
        if not sorted_items:
            return
        try:
            pass  # pandas and os are already imported at the top
        except Exception:
            return
        rows: list[dict[str, Any]] = []
        for reason, count in sorted_items:
            rows.append(
                {
                    "reason": reason,
                    "count": int(count),
                    "examples": ", ".join(self.samples.get(reason, [])),
                }
            )
        if not rows:
            return
        try:
            settings = get_settings(create_dirs=True)
            out_dir_obj = getattr(settings.outputs, "results_csv_dir", None)
        except Exception:
            out_dir_obj = None
        out_dir = str(out_dir_obj or "results_csv")
        try:
            os.makedirs(out_dir, exist_ok=True)
        except Exception:
            pass
        summary_path = os.path.join(out_dir, f"skip_summary_{system_name}.csv")
        try:
            try:
                settings = get_settings(create_dirs=True)
                round_dec = getattr(settings.cache, "round_decimals", None)
            except Exception:
                round_dec = None
            try:
                out_df = round_dataframe(pd.DataFrame(rows), round_dec)
            except Exception:
                out_df = pd.DataFrame(rows)
            out_df.to_csv(summary_path, index=False, encoding="utf-8")
            if log_callback:
                log_callback(f"ğŸ“ ã‚¹ã‚­ãƒƒãƒ—çµ±è¨ˆCSVã‚’ä¿å­˜ {summary_path}")
        except Exception:
            pass
        if not self.details:
            return
        details_path = os.path.join(out_dir, f"skip_details_{system_name}.csv")
        try:
            try:
                settings = get_settings(create_dirs=True)
                round_dec = getattr(settings.cache, "round_decimals", None)
            except Exception:
                round_dec = None
            try:
                out_df = round_dataframe(pd.DataFrame(self.details), round_dec)
            except Exception:
                out_df = pd.DataFrame(self.details)
            out_df.to_csv(details_path, index=False, encoding="utf-8")
            if log_callback:
                log_callback(f"ğŸ“ ã‚¹ã‚­ãƒƒãƒ—è©³ç´°CSVã‚’ä¿å­˜ {details_path}")
        except Exception:
            pass


@dataclass
class PrepareDataResult:
    prepared: dict[str, pd.DataFrame]
    skip_stats: SkipStats
    early_exit_frame: pd.DataFrame | None = None
    early_exit_reason: str | None = None


@dataclass
class CandidateExtraction:
    candidates_by_date: dict | None
    market_df: pd.DataFrame | None
    early_exit_frame: pd.DataFrame | None = None
    zero_reason: str | None = None
    diagnostics: dict[str, Any] | None = None


@dataclass
class CandidateSelection:
    key_map: dict[pd.Timestamp, object]
    target_date: pd.Timestamp | None
    fallback_reason: str | None
    total_candidates_today: int
    zero_reason: str | None = None


def _normalize_today(today: pd.Timestamp | None) -> pd.Timestamp:
    if today is None:
        base = get_signal_target_trading_day()
    else:
        try:
            base = pd.Timestamp(today)
        except Exception:
            base = get_signal_target_trading_day()
    if getattr(base, "tzinfo", None) is not None:
        try:
            base = base.tz_convert(None)
        except (TypeError, ValueError, AttributeError):
            try:
                base = base.tz_localize(None)
            except Exception:
                base = pd.Timestamp(base.to_pydatetime().replace(tzinfo=None))
    # Ensure precise type for static checkers
    try:
        normed = base.normalize()
        return pd.Timestamp(normed)
    except Exception:
        return pd.Timestamp(base)


def _slice_data_for_lookback(
    raw_data_dict: dict[str, pd.DataFrame],
    lookback_days: int | None,
) -> dict[str, pd.DataFrame]:
    if (
        lookback_days is None
        or lookback_days <= 0
        or not isinstance(raw_data_dict, dict)
    ):
        return raw_data_dict
    sliced: dict[str, pd.DataFrame] = {}
    for sym, df in raw_data_dict.items():
        try:
            if df is None or getattr(df, "empty", True):
                continue
            x = df.copy()
            if "Date" in x.columns:
                idx = pd.to_datetime(x["Date"], errors="coerce").dt.normalize()
                x.index = pd.Index(idx)
            else:
                x.index = pd.to_datetime(x.index, errors="coerce").normalize()
            x = x[~x.index.isna()]
            x = x.tail(int(lookback_days))
            sliced[sym] = x
        except Exception:
            sliced[sym] = df
    return sliced


def _normalize_prepared_dict(
    prepared_dict: dict[str, pd.DataFrame],
) -> dict[str, pd.DataFrame]:
    try:
        if not isinstance(prepared_dict, dict):
            return prepared_dict
        fixed: dict[str, pd.DataFrame] = {}
        for sym, df in prepared_dict.items():
            try:
                x = df.copy()
                if "Date" in x.columns:
                    idx = pd.to_datetime(x["Date"], errors="coerce").dt.normalize()
                else:
                    idx = pd.to_datetime(x.index, errors="coerce").normalize()
                x.index = pd.Index(idx)
                x = x[~x.index.isna()]
                x = x.sort_index()
                if getattr(x.index, "has_duplicates", False):
                    x = x[~x.index.duplicated(keep="last")]
                fixed[sym] = x
            except Exception:
                fixed[sym] = df
        return fixed
    except Exception:
        return prepared_dict


def _prepare_strategy_data(
    strategy: Any,
    sliced_dict: dict[str, pd.DataFrame],
    *,
    progress_callback: Callable[..., None] | None,
    log_callback: Callable[[str], None] | None,
    use_process_pool: bool,
    max_workers: int | None,
    lookback_days: int | None,
) -> PrepareDataResult:
    skip_stats = SkipStats()
    skip_callback = skip_stats.callback()

    try:
        # latest_only ãƒ’ãƒ³ãƒˆã‚’ prepare_data ã«ä¼æ’­ï¼ˆå„æˆ¦ç•¥å´ã§æœªå¯¾å¿œãªã‚‰ç„¡è¦–ã•ã‚Œã‚‹ï¼‰
        prepared_dict = strategy.prepare_data(
            sliced_dict,
            progress_callback=progress_callback,
            log_callback=log_callback,
            skip_callback=skip_callback,
            use_process_pool=use_process_pool,
            max_workers=max_workers,
            lookback_days=lookback_days,
            reuse_indicators=True,
            latest_only=True,
        )
    except Exception as exc:
        system_name = str(getattr(strategy, "SYSTEM_NAME", ""))
        try:
            if log_callback:
                log_callback(
                    f"âš ï¸ {system_name}: å‰å‡¦ç†å¤±æ•—ã®ãŸã‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å†è©¦è¡Œã—ã¾ã™ ({exc})"
                )
        except Exception:
            pass
        try:
            prepared_dict = strategy.prepare_data(
                sliced_dict,
                progress_callback=progress_callback,
                log_callback=log_callback,
                skip_callback=skip_callback,
                use_process_pool=False,
                max_workers=None,
                lookback_days=lookback_days,
                reuse_indicators=False,
                latest_only=True,
            )
        except Exception as exc2:
            reason_code = "prepare_fail: å…¥åŠ›ä¸å‚™ã®ãŸã‚å‡¦ç†ä¸­æ–­"
            try:
                if log_callback:
                    log_callback(f"ğŸ›‘ {system_name}: {reason_code} ({exc2})")
            except Exception:
                pass
            empty = _empty_today_signals_frame(reason_code)
            return PrepareDataResult(
                {},
                skip_stats,
                empty,
                reason_code,
            )

    prepared_dict = prepared_dict or {}
    normalized = _normalize_prepared_dict(prepared_dict)
    return PrepareDataResult(normalized, skip_stats)


def _detect_last_trading_day(df: pd.DataFrame) -> pd.Timestamp | None:
    """Return the normalized last trading day from the given frame."""

    if df is None or getattr(df, "empty", True):
        return None
    try:
        if isinstance(df.index, pd.DatetimeIndex) and len(df.index):
            idx = pd.to_datetime(df.index, errors="coerce").normalize()
            idx = idx[~idx.isna()]
            if len(idx):
                # Use max() to safely get a scalar Timestamp
                last_val = idx.max()
                return pd.Timestamp(last_val)
    except Exception:
        pass
    try:
        if "Date" in df.columns:
            series = pd.to_datetime(df["Date"], errors="coerce").dt.normalize()
            series = series.dropna()
            if len(series):
                try:
                    return pd.Timestamp(series.iloc[-1])
                except Exception:
                    try:
                        return pd.Timestamp(pd.to_datetime(series.iloc[-1]))
                    except Exception:
                        return None
    except Exception:
        pass
    return None


def _filter_by_data_freshness(
    prepared: dict[str, pd.DataFrame] | pd.DataFrame | None,
    today: pd.Timestamp,
    skip_stats: SkipStats | None,
    log_callback: Callable[[str], None] | None,
) -> tuple[
    dict[str, pd.DataFrame] | pd.DataFrame | None,
    list[tuple[str, pd.Timestamp]],
    list[tuple[str, pd.Timestamp]],
]:
    """Remove symbols older than 1 month and emit freshness alerts."""

    if not isinstance(prepared, dict) or not prepared:
        return prepared, [], []

    try:
        prev_trading_day = get_latest_nyse_trading_day(
            pd.Timestamp(today) - pd.Timedelta(days=1)
        )
    except Exception:
        prev_trading_day = pd.Timestamp(today).normalize() - pd.Timedelta(days=1)

    # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰æ™‚ã¯é®®åº¦ãƒã‚§ãƒƒã‚¯ã‚’å¤§å¹…ã«ç·©å’Œï¼ˆ365å–¶æ¥­æ—¥ â‰ˆ 1.5å¹´ï¼‰
    try:
        from config.environment import get_env_config

        env = get_env_config()
        # test_mode ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯é®®åº¦ãƒã‚§ãƒƒã‚¯ã‚’ç·©å’Œ
        if env.test_mode in ("mini", "quick", "sample"):
            month_cutoff = pd.Timestamp(prev_trading_day) - pd.Timedelta(days=365 * 1.5)
            global _TEST_MODE_FRESHNESS_LOGGED
            if (not _TEST_MODE_FRESHNESS_LOGGED) and log_callback:
                try:
                    log_callback(
                        f"ğŸ§ª [TEST-MODE={env.test_mode}] é®®åº¦è¨±å®¹ã‚’1.5å¹´ã«ç·©å’Œã—ã¾ã—ãŸ"
                    )
                except Exception:
                    pass
                _TEST_MODE_FRESHNESS_LOGGED = True
        else:
            month_cutoff = pd.Timestamp(prev_trading_day) - pd.DateOffset(months=1)
    except Exception:
        try:
            month_cutoff = pd.Timestamp(prev_trading_day) - pd.DateOffset(months=1)
        except Exception:
            month_cutoff = pd.Timestamp(prev_trading_day) - pd.Timedelta(days=30)

    stale_alerts: list[tuple[str, pd.Timestamp]] = []
    stale_suppressed: list[tuple[str, pd.Timestamp]] = []

    for sym, df in list(prepared.items()):
        last_day = _detect_last_trading_day(df)
        if last_day is None:
            continue
        try:
            last_day_norm = pd.Timestamp(last_day).normalize()
        except Exception:
            last_day_norm = None
        if last_day_norm is None:
            continue
        if last_day_norm <= month_cutoff:
            prepared.pop(sym, None)
            stale_suppressed.append((str(sym), last_day_norm))
            if skip_stats is not None:
                try:
                    skip_stats.record(str(sym), "stale_over_month")
                except Exception:
                    pass
        elif last_day_norm < prev_trading_day:
            stale_alerts.append((str(sym), last_day_norm))

    def _format_preview(items: list[tuple[str, pd.Timestamp]]) -> str:
        preview_parts: list[str] = []
        for sym, day in items[:5]:
            try:
                preview_parts.append(f"{sym}({day.date()})")
            except Exception:
                preview_parts.append(str(sym))
        return ", ".join(preview_parts)

    if stale_suppressed and log_callback:
        try:
            preview = _format_preview(stale_suppressed)
            suffix = f" (ä¾‹: {preview})" if preview else ""
            log_callback(
                "ğŸ”• ãƒ‡ãƒ¼ã‚¿é®®åº¦: æœ€çµ‚æ—¥ãŒ1ãƒ¶æœˆä»¥ä¸Šå‰ã®ãŸã‚é™¤å¤–: "
                f"{len(stale_suppressed)} éŠ˜æŸ„{suffix}"
            )
        except Exception:
            pass

    if stale_alerts and log_callback:
        try:
            preview = _format_preview(stale_alerts)
            suffix = f" (ä¾‹: {preview})" if preview else ""
            ref_label = str(pd.Timestamp(prev_trading_day).date())
            log_callback(
                "âš ï¸ ãƒ‡ãƒ¼ã‚¿é®®åº¦è­¦å‘Š: ç›´è¿‘å–¶æ¥­æ—¥"
                f"({ref_label})ã®ãƒ‡ãƒ¼ã‚¿æœªæ›´æ–°: "
                f"{len(stale_alerts)} éŠ˜æŸ„{suffix}"
            )
        except Exception:
            pass

    return prepared, stale_alerts, stale_suppressed


def _log_elapsed(
    log_callback: Callable[[str], None] | None,
    message: str,
    start_time: float,
) -> None:
    if not log_callback:
        return
    try:
        em, es = divmod(int(max(0, _t.time() - start_time)), 60)
        log_callback(f"{message}ï¼šçµŒé {em}åˆ†{es}ç§’")
    except Exception:
        pass


def _apply_shortability_filter(
    system_name: str,
    prepared: dict[str, pd.DataFrame] | pd.DataFrame | None,
    skip_stats: SkipStats,
    log_callback: Callable[[str], None] | None,
) -> dict[str, pd.DataFrame] | pd.DataFrame | None:
    name = (system_name or "").lower()
    if name not in {"system2", "system6"}:
        return prepared
    if not isinstance(prepared, dict) or not prepared:
        return prepared

    symbols = [sym for sym in prepared.keys() if str(sym).upper() != "SPY"]
    if not symbols:
        return prepared

    try:
        from common import broker_alpaca as ba

        client_short = ba.get_client(paper=True)
        shortable_map = ba.get_shortable_map(
            client_short,
            [str(sym).upper() for sym in symbols],
        )
    except Exception:
        shortable_map = {}

    if not shortable_map:
        return prepared

    removed: list[str] = []
    for sym in list(symbols):
        sym_upper = str(sym).upper()
        if not bool(shortable_map.get(sym_upper, False)):
            prepared.pop(sym, None)
            removed.append(sym_upper)
            skip_stats.record(sym_upper, "not_shortable")

    if not removed:
        return prepared

    if log_callback:
        try:
            preview = ", ".join(sorted(removed)[:5])
            suffix = "" if len(removed) <= 5 else f" ã»ã‹{len(removed) - 5}ä»¶"
            log_callback(
                f"ğŸš« {name}: ã‚·ãƒ§ãƒ¼ãƒˆä¸å¯ã§é™¤å¤–: {len(removed)} ä»¶"
                + (f" (ä¾‹: {preview}{suffix})" if preview else "")
            )
        except Exception:
            pass

    try:
        settings = get_settings(create_dirs=True)
        results_dir = Path(getattr(settings.outputs, "results_csv_dir", "results_csv"))
    except Exception:
        results_dir = Path("results_csv")

    try:
        results_dir.mkdir(parents=True, exist_ok=True)
        df_excluded = pd.DataFrame({"symbol": sorted(set(removed))})
        df_excluded["reason"] = "not_shortable"
        fp = results_dir / f"shortability_excluded_{name}.csv"
        df_excluded.to_csv(fp, index=False, encoding="utf-8")
        if log_callback:
            try:
                log_callback(f"ğŸ“ {name}: ã‚·ãƒ§ãƒ¼ãƒˆä¸å¯ã®é™¤å¤–éŠ˜æŸ„CSVã‚’ä¿å­˜: {fp}")
            except Exception:
                pass
    except Exception:
        pass

    return prepared


def _compute_filter_pass(
    system_name: str,
    prepared: dict[str, pd.DataFrame] | pd.DataFrame | None,
    today: pd.Timestamp,
    log_callback: Callable[[str], None] | None,
) -> int:
    try:
        prev_trading_day = get_latest_nyse_trading_day(
            pd.Timestamp(today) - pd.Timedelta(days=1)
        )

        def _last_filter_on_date(x: pd.DataFrame) -> bool:
            try:
                if getattr(x, "empty", True) or "filter" not in x.columns:
                    return False
                if "Date" in x.columns:
                    dt_vals = (
                        pd.to_datetime(x["Date"], errors="coerce")
                        .dt.normalize()
                        .to_numpy()
                    )
                    mask = dt_vals == prev_trading_day
                    rows = x.loc[mask]
                else:
                    idx_vals = (
                        pd.to_datetime(x.index, errors="coerce").normalize().to_numpy()
                    )
                    mask = idx_vals == prev_trading_day
                    rows = x.loc[mask]
                if len(rows) == 0:
                    rows = x.tail(1)
                if len(rows) == 0:
                    return False
                return bool(rows.iloc[-1].get("filter"))
            except Exception:
                return False

        if isinstance(prepared, dict):
            filter_pass = sum(int(_last_filter_on_date(df)) for df in prepared.values())
        elif isinstance(prepared, pd.DataFrame):
            filter_pass = int(_last_filter_on_date(prepared))
        else:
            filter_pass = 0
        try:
            if str(system_name).lower() == "system7":
                filter_pass = (
                    1 if (isinstance(prepared, dict) and ("SPY" in prepared)) else 0
                )
        except Exception:
            pass
    except Exception:
        filter_pass = 0
    if log_callback:
        try:
            log_callback(f"ğŸ§ª ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒã‚§ãƒƒã‚¯å®Œäº†ï¼š{filter_pass} éŠ˜æŸ„")
        except Exception:
            pass
    return int(filter_pass)


def _generate_candidates_for_system(
    strategy: Any,
    prepared: dict[str, pd.DataFrame] | pd.DataFrame | None,
    *,
    system_name: str,
    market_df: pd.DataFrame | None,
    filter_pass: int,
    progress_callback: Callable[..., None] | None,
    log_callback: Callable[[str], None] | None,
) -> CandidateExtraction:
    gen_fn = getattr(strategy, "generate_candidates")
    params = inspect.signature(gen_fn).parameters
    needs_market_df = "market_df" in params
    accepts_kwargs = any(
        p.kind == inspect.Parameter.VAR_KEYWORD for p in params.values()
    )
    can_override_top_n = "top_n" in params or accepts_kwargs
    market_df_local = market_df
    market_df_arg = market_df
    candidates_by_date: dict | None = None

    if needs_market_df and system_name == "system4":
        needs_fallback = market_df_arg is None or getattr(market_df_arg, "empty", False)
        if needs_fallback and isinstance(prepared, dict):
            maybe_spy = prepared.get("SPY")
            if isinstance(maybe_spy, pd.DataFrame) and not getattr(
                maybe_spy, "empty", True
            ):
                market_df_arg = maybe_spy
                needs_fallback = False
        if needs_fallback:
            try:
                cached_spy = get_spy_with_indicators()
            except Exception:
                cached_spy = None
            if cached_spy is not None and not getattr(cached_spy, "empty", True):
                market_df_arg = cached_spy
                market_df_local = cached_spy
                if log_callback:
                    try:
                        log_callback(
                            "ğŸ›Ÿ System4: SPYãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰è£œå®Œã—ã¾ã—ãŸ"
                        )
                    except Exception:
                        pass
        if market_df_arg is None or getattr(market_df_arg, "empty", False):
            if log_callback:
                try:
                    log_callback(
                        "âš ï¸ System4: SPYãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚å€™è£œæŠ½å‡ºã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™"
                    )
                except Exception:
                    pass
            return CandidateExtraction(
                None,
                market_df_arg,
                _empty_today_signals_frame(),
            )

    if log_callback:
        try:
            log_callback(f"ğŸ§© ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒã‚§ãƒƒã‚¯é–‹å§‹ï¼š{filter_pass} éŠ˜æŸ„")
        except Exception:
            pass

    t1 = _t.time()
    call_kwargs: dict[str, Any] = {
        "progress_callback": progress_callback,
        "log_callback": log_callback,
        "latest_only": True,  # å½“æ—¥ã‚·ã‚°ãƒŠãƒ«æŠ½å‡ºæ™‚ã¯æœ€æ–°è¡Œã®ã¿å‡¦ç†
    }
    # Only add top_n if not already in the function signature as keyword argument
    if can_override_top_n and "top_n" not in params:
        call_kwargs["top_n"] = TODAY_TOP_N
    # request diagnostics when supported by underlying core functions
    if "include_diagnostics" in params:
        call_kwargs["include_diagnostics"] = True

    if needs_market_df and market_df_arg is not None:
        market_df_local = market_df_arg
        result = gen_fn(
            prepared,
            market_df=market_df_arg,
            **call_kwargs,
        )
    elif needs_market_df:
        result = gen_fn(
            prepared,
            **call_kwargs,
        )
    else:
        result = gen_fn(
            prepared,
            **call_kwargs,
        )

    candidates_by_date = None
    diagnostics_payload: dict[str, Any] | None = None

    if isinstance(result, tuple):
        if len(result) >= 3:
            candidates_by_date = result[0]
            diagnostics_payload = result[2]
        elif len(result) == 2:
            candidates_by_date = result[0]
        elif len(result) == 1:
            candidates_by_date = result[0]
    else:
        candidates_by_date = result

    if diagnostics_payload is None:
        diagnostics_payload = getattr(strategy, "last_diagnostics", None)

    if not candidates_by_date:
        zero_reason = "no_candidates_generated"
        if log_callback:
            try:
                log_callback("âš ï¸ å€™è£œãŒ1ä»¶ã‚‚ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼ˆæˆ¦ç•¥æŠ½å‡ºå´ï¼‰")
            except Exception:
                pass
        return CandidateExtraction(
            candidates_by_date,
            market_df_local,
            None,
            zero_reason,
            diagnostics_payload,
        )

    _log_elapsed(log_callback, "â±ï¸ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—/å€™è£œæŠ½å‡º å®Œäº†", t1)

    return CandidateExtraction(
        candidates_by_date, market_df_local, diagnostics=diagnostics_payload
    )


def _compute_setup_pass(
    system_name: str,
    prepared: dict[str, pd.DataFrame] | pd.DataFrame | None,
    market_df: pd.DataFrame | None,
    filter_pass: int,
    today: pd.Timestamp,
    log_callback: Callable[[str], None] | None,
    candidate_diagnostics: dict[str, object] | None = None,
) -> int:
    try:
        prev_trading_day = get_latest_nyse_trading_day(
            pd.Timestamp(today) - pd.Timedelta(days=1)
        )

        def _last_row(x: pd.DataFrame) -> pd.Series | None:
            try:
                if "Date" in x.columns:
                    dt_vals = (
                        pd.to_datetime(x["Date"], errors="coerce")
                        .dt.normalize()
                        .to_numpy()
                    )
                    mask = dt_vals == prev_trading_day
                    rows = x.loc[mask]
                else:
                    idx_vals = (
                        pd.to_datetime(x.index, errors="coerce").normalize().to_numpy()
                    )
                    mask = idx_vals == prev_trading_day
                    rows = x.loc[mask]
                if len(rows) == 0:
                    rows = x.tail(1)
                if len(rows) == 0:
                    return None
                return cast(pd.Series, rows.iloc[-1])
            except Exception:
                return None

        if isinstance(prepared, dict):
            items = list(prepared.items())
        elif isinstance(prepared, pd.DataFrame):
            items = [("", prepared)]
        else:
            items = []
        latest_rows: dict[str, pd.Series] = {}
        for sym, df in items:
            if df is None or getattr(df, "empty", True):
                continue
            row = _last_row(df)
            if row is None:
                continue
            # symbol æƒ…å ±ã‚’ Series ã«åŸ‹ã‚è¾¼ã‚€ï¼ˆå¾Œæ®µã®åˆ¤å®š/ãƒ‡ãƒãƒƒã‚°ã§åˆ©ç”¨ï¼‰
            try:
                if "symbol" not in row:
                    # copy() ã§å…ƒ DataFrame ã‚’æ±šã•ãªã„
                    row = row.copy()
                    row["symbol"] = str(sym)
            except Exception:
                pass
            latest_rows[str(sym)] = row

        def _count_if(rows: list[pd.Series], fn: Callable[[pd.Series], bool]) -> int:
            cnt = 0
            for row in rows:
                try:
                    if fn(row):
                        cnt += 1
                except Exception:
                    continue
            return cnt

        rows_list = list(latest_rows.values())
        name = str(system_name).lower()
        setup_pass = 0

        if name == "system1":
            allow_fallback = False
            if isinstance(candidate_diagnostics, dict):
                mode = str(candidate_diagnostics.get("mode", "")).lower()
                allow_fallback = mode == "latest_only"

            filter_ok_count = 0
            setup_flag_true = 0
            fallback_count = 0
            roc200_positive = 0
            final_pass_count = 0
            reason_counts: dict[str, int] = {}

            for symbol, row in latest_rows.items():
                passed, flags, reason = system1_row_passes_setup(
                    row, allow_fallback=allow_fallback
                )
                if flags["filter_ok"]:
                    filter_ok_count += 1
                if flags["setup_flag"]:
                    setup_flag_true += 1
                if flags["fallback_ok"]:
                    fallback_count += 1
                if flags["roc200_positive"]:
                    roc200_positive += 1
                if passed:
                    final_pass_count += 1
                elif reason:
                    reason_counts[reason] = reason_counts.get(reason, 0) + 1

            try:
                spy_df = get_spy_with_indicators(
                    market_df if market_df is not None else None
                )
            except Exception:
                spy_df = None
            spy_gate_bool = _make_spy_gate(spy_df, column="sma100")
            if spy_gate_bool is True:
                spy_gate = 1
            elif spy_gate_bool is False:
                spy_gate = 0
            else:
                spy_gate = None

            setup_pass = final_pass_count if spy_gate != 0 else 0

            if log_callback:
                try:
                    spy_label = "-" if spy_gate is None else str(int(spy_gate))
                    parts = [
                        f"ãƒ•ã‚£ãƒ«ã‚¿é€šé={filter_pass}",
                        f"å†è¨ˆç®—ãƒ•ã‚£ãƒ«ã‚¿={filter_ok_count}",
                        f"setupåˆ—True={setup_flag_true}",
                        f"fallbacké€šé={fallback_count}",
                        f"ROC200>0={roc200_positive}",
                        f"æœ€çµ‚å€™è£œ={final_pass_count}",
                        f"SPY>SMA100: {spy_label}",
                    ]
                    if reason_counts:
                        top_items = sorted(
                            reason_counts.items(), key=lambda kv: kv[1], reverse=True
                        )[:2]
                        parts.append(
                            "é™¤å¤–ç†ç”±=" + ", ".join(f"{k}:{v}" for k, v in top_items)
                        )
                    log_callback("ğŸ§© system1ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é›†è¨ˆ: " + ", ".join(parts))
                except Exception:
                    pass
        elif name == "system2":

            def _rsi_ok(row: pd.Series) -> bool:
                try:
                    row_map = cast(Mapping[str, Any], row)
                    vv = to_float(get_indicator(row_map, "rsi3"))
                    return (not np.isnan(vv)) and vv > 90
                except Exception:
                    return False

            def _two_up_ok(row: pd.Series) -> bool:
                # è¤‡æ•°ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã® OR åˆ¤å®šï¼ˆæŒ‡æ¨™ãã®ã‚‚ã®ãŒãƒ–ãƒ¼ãƒ«/æ•°å€¤ ã„ãšã‚Œã§ã‚‚ True åˆ¤å®šï¼‰
                row_map = cast(Mapping[str, Any], row)
                return bool(
                    get_indicator(row_map, "twodayup")
                    or get_indicator(row_map, "uptwodays")
                )

            filtered_rows = [
                r for r in rows_list if ("filter" not in r) or bool(r.get("filter"))
            ]
            rsi_pass = _count_if(filtered_rows, _rsi_ok)
            two_up_pass = _count_if(
                filtered_rows, lambda r: _rsi_ok(r) and _two_up_ok(r)
            )
            setup_pass = two_up_pass
            if log_callback:
                try:
                    log_callback(
                        "ğŸ§© system2ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é›†è¨ˆ: "
                        f"ãƒ•ã‚£ãƒ«ã‚¿é€šé={filter_pass}, RSI3>90: {rsi_pass}, "
                        f"TwoDayUp: {two_up_pass}"
                    )
                except Exception:
                    pass
        elif name == "system3":
            filtered_rows = [
                r for r in rows_list if ("filter" not in r) or bool(r.get("filter"))
            ]

            def _close_ok(row: pd.Series) -> bool:
                try:
                    c = to_float(row.get("Close"))
                    row_map = cast(Mapping[str, Any], row)
                    s = to_float(get_indicator(row_map, "sma150"))
                    return (not np.isnan(c)) and (not np.isnan(s)) and c > s
                except Exception:
                    return False

            def _drop_ok(row: pd.Series) -> bool:
                try:
                    row_map = cast(Mapping[str, Any], row)
                    d = to_float(get_indicator(row_map, "drop3d"))
                    return (not np.isnan(d)) and d >= 0.125
                except Exception:
                    return False

            close_pass = _count_if(filtered_rows, _close_ok)
            drop_pass = _count_if(filtered_rows, lambda r: _close_ok(r) and _drop_ok(r))
            setup_pass = drop_pass
            if log_callback:
                try:
                    log_callback(
                        "ğŸ§© system3ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é›†è¨ˆ: "
                        f"ãƒ•ã‚£ãƒ«ã‚¿é€šé={filter_pass}, Close>SMA150: {close_pass}, "
                        f"3æ—¥ä¸‹è½ç‡â‰§12.5%: {drop_pass}"
                    )
                except Exception:
                    pass
        elif name == "system4":

            def _above_sma(row: pd.Series) -> bool:
                try:
                    c = to_float(row.get("Close"))
                    row_map = cast(Mapping[str, Any], row)
                    s = to_float(get_indicator(row_map, "sma200"))
                    return (
                        (("filter" not in row) or bool(row.get("filter")))
                        and (not np.isnan(c))
                        and (not np.isnan(s))
                        and c > s
                    )
                except Exception:
                    return False

            above_sma = _count_if(rows_list, _above_sma)
            spy_gate_val: int | None = None
            try:
                spy_source: pd.DataFrame | None = None
                if isinstance(market_df, pd.DataFrame) and not getattr(
                    market_df, "empty", False
                ):
                    spy_source = market_df
                elif isinstance(prepared, dict):
                    v = prepared.get("SPY")
                    spy_source = v if isinstance(v, pd.DataFrame) else None
                spy_with = get_spy_with_indicators(spy_source)
            except Exception:
                spy_with = None
            try:
                spy_gate_val = _make_spy_gate(
                    _normalize_daily_index(spy_with) if spy_with is not None else None
                )
                if spy_gate_val is False:
                    spy_gate_val = 0
                elif spy_gate_val is True:
                    spy_gate_val = 1
            except Exception:
                spy_gate_val = None

            setup_pass = above_sma if spy_gate_val != 0 else 0
            if log_callback:
                try:
                    spy_label = "-" if spy_gate_val is None else str(int(spy_gate_val))
                    log_callback(
                        "ğŸ§© system4ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é›†è¨ˆ: "
                        + f"ãƒ•ã‚£ãƒ«ã‚¿é€šé={filter_pass}, SPY>SMA200: {spy_label}, "
                        + f"Close>SMA200: {above_sma}"
                    )
                except Exception:
                    pass
        elif name == "system5":
            threshold_label = format_atr_pct_threshold_label()
            s5_total = len(rows_list)
            s5_av = 0
            s5_dv = 0
            s5_atr = 0
            for row in rows_list:
                try:
                    av_val = row.get("AvgVolume50")
                    if av_val is None or pd.isna(av_val) or float(av_val) <= 500_000:
                        continue
                    s5_av += 1
                    dv_val = row.get("DollarVolume50")
                    if dv_val is None or pd.isna(dv_val) or float(dv_val) <= 2_500_000:
                        continue
                    s5_dv += 1
                    atr_pct_val = row.get("ATR_Pct")
                    if (
                        atr_pct_val is not None
                        and not pd.isna(atr_pct_val)
                        and float(atr_pct_val) > DEFAULT_ATR_PCT_THRESHOLD
                    ):
                        s5_atr += 1
                except Exception:
                    continue
            if log_callback:
                try:
                    log_callback(
                        "ğŸ§ª system5é›†è¨ˆ: "
                        + f"å¯¾è±¡={s5_total}, AvgVol50>500k: {s5_av}, "
                        + f"DV50>2.5M: {s5_dv}, {threshold_label}: {s5_atr}"
                    )
                except Exception:
                    pass

            def _price_ok(row: pd.Series) -> bool:
                try:
                    c = to_float(row.get("Close"))
                    row_map = cast(Mapping[str, Any], row)
                    s = to_float(get_indicator(row_map, "sma100"))
                    a = to_float(get_indicator(row_map, "atr10"))
                    return (
                        (("filter" not in row) or bool(row.get("filter")))
                        and (not np.isnan(c) and not np.isnan(s) and not np.isnan(a))
                        and (c > s + a)
                    )
                except Exception:
                    return False

            def _adx_ok(row: pd.Series) -> bool:
                try:
                    row_map = cast(Mapping[str, Any], row)
                    vv = to_float(get_indicator(row_map, "adx7"))
                    return (not np.isnan(vv)) and vv > 55
                except Exception:
                    return False

            def _rsi_ok(row: pd.Series) -> bool:
                try:
                    row_map = cast(Mapping[str, Any], row)
                    vv = to_float(get_indicator(row_map, "rsi3"))
                    return (not np.isnan(vv)) and vv < 50
                except Exception:
                    return False

            price_pass = _count_if(rows_list, _price_ok)
            adx_pass = _count_if(rows_list, lambda r: _price_ok(r) and _adx_ok(r))
            rsi_pass = _count_if(
                rows_list, lambda r: _price_ok(r) and _adx_ok(r) and _rsi_ok(r)
            )
            setup_pass = rsi_pass
            if log_callback:
                try:
                    log_callback(
                        "ğŸ§© system5ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é›†è¨ˆ: "
                        + f"ãƒ•ã‚£ãƒ«ã‚¿é€šé={filter_pass}, Close>SMA100+ATR10: {price_pass}, "
                        + f"ADX7>55: {adx_pass}, RSI3<50: {rsi_pass}"
                    )
                except Exception:
                    pass
        elif name == "system6":
            filtered_rows = [
                r for r in rows_list if ("filter" not in r) or bool(r.get("filter"))
            ]

            def _ret_ok(row: pd.Series) -> bool:
                try:
                    row_map = cast(Mapping[str, Any], row)
                    vv = to_float(get_indicator(row_map, "return_6d"))
                    return (not np.isnan(vv)) and vv > 0.20
                except Exception:
                    return False

            def _up_two(row: pd.Series) -> bool:
                row_map = cast(Mapping[str, Any], row)
                return bool(
                    get_indicator(row_map, "uptwodays")
                    or get_indicator(row_map, "twodayup")
                )

            ret_pass = _count_if(filtered_rows, _ret_ok)
            up_pass = _count_if(filtered_rows, lambda r: _ret_ok(r) and _up_two(r))
            setup_pass = up_pass
            if log_callback:
                try:
                    msg = (
                        "ğŸ§© system6ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é›†è¨ˆ: "
                        f"ãƒ•ã‚£ãƒ«ã‚¿é€šé={filter_pass}, "
                        f"return_6d>20%: {ret_pass}, "
                        f"UpTwoDays: {up_pass}"
                    )
                    log_callback(msg)
                except Exception:
                    pass
        elif name == "system7":
            spy_present = 1 if "SPY" in latest_rows else 0
            setup_pass = spy_present
            if log_callback:
                try:
                    msg = f"ğŸ§© system7ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é›†è¨ˆ: SPYå­˜åœ¨={spy_present}"
                    if spy_present:
                        try:
                            val = latest_rows.get("SPY", pd.Series())
                            if isinstance(val, pd.Series):
                                setup_flag = bool(val.get("setup", 0))
                            else:
                                setup_flag = False
                            msg += f", setup={int(setup_flag)}"
                        except Exception:
                            pass
                    log_callback(msg)
                except Exception:
                    pass
        else:
            setup_pass = _count_if(
                rows_list,
                lambda r: bool(r.get("setup")) if "setup" in r else False,
            )

        try:
            setup_pass = int(setup_pass)
        except Exception:
            setup_pass = 0
    except Exception:
        setup_pass = 0
    return int(setup_pass)


def _diagnose_setup_zero_reason(
    system_name: str,
    filter_pass: int,
    prepared: dict[str, pd.DataFrame] | pd.DataFrame | None,
    market_df: pd.DataFrame | None,
) -> str | None:
    """è£œåŠ©: ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é€šé0ä»¶æ™‚ã®ä»£è¡¨çš„ãªç†ç”±ã‚’æ¨æ¸¬ã™ã‚‹ã€‚"""

    try:
        if int(filter_pass) <= 0:
            return None
    except Exception:
        return None

    try:
        system_lower = str(system_name).lower()
    except Exception:
        system_lower = ""

    if system_lower not in {"system1", "system4"}:
        return None

    try:
        spy_source: pd.DataFrame | None
        if isinstance(market_df, pd.DataFrame):
            spy_source = market_df
        elif isinstance(prepared, dict):
            _tmp = prepared.get("SPY")
            spy_source = _tmp if isinstance(_tmp, pd.DataFrame) else None
        else:
            spy_source = None
    except Exception:
        spy_source = None

    try:
        spy_with = get_spy_with_indicators(spy_source)
    except Exception:
        spy_with = None

    column = "SMA100" if system_lower == "system1" else "SMA200"
    try:
        normalized = _normalize_daily_index(spy_with) if spy_with is not None else None
        gate = _make_spy_gate(normalized, column=column)
    except Exception:
        gate = None

    if gate is False:
        return f"setup_fail: SPY close <= {column}"

    return None


def _select_candidate_date(
    candidates_by_date: dict | None,
    today: pd.Timestamp,
    _filter_pass: int,
    setup_pass: int,
    log_callback: Callable[[str], None] | None,
) -> CandidateSelection:
    try:
        key_map: dict[pd.Timestamp, object] = {}
        cand_keys = list((candidates_by_date or {}).keys())
        for _k in cand_keys:
            try:
                _raw_ts = pd.to_datetime(_k, errors="coerce")
                if pd.isna(_raw_ts):
                    continue
                _ts = pd.Timestamp(_raw_ts)
                if getattr(_ts, "tzinfo", None) is not None:
                    try:
                        _ts = _ts.tz_localize(None)
                    except Exception:
                        try:
                            _ts = pd.Timestamp(_ts.to_pydatetime().replace(tzinfo=None))
                        except Exception:
                            continue
                _ts = _ts.normalize()
                if _ts not in key_map:
                    key_map[_ts] = _k
            except Exception:
                continue
        candidate_dates = sorted(list(key_map.keys()), reverse=True)
    except Exception:
        key_map = {}
        candidate_dates = []

    target_date: pd.Timestamp | None = None
    fallback_reason: str | None = None

    def _collect_recent_days(
        anchor: pd.Timestamp | None, count: int
    ) -> list[pd.Timestamp]:
        if anchor is None or count <= 0:
            return []
        out: list[pd.Timestamp] = []
        seen: set[pd.Timestamp] = set()
        cur = pd.Timestamp(anchor).normalize()
        while len(out) < count:
            if cur in seen:
                break
            out.append(cur)
            seen.add(cur)
            prev = get_latest_nyse_trading_day(cur - pd.Timedelta(days=1))
            prev = pd.Timestamp(prev).normalize()
            if prev >= cur:
                break
            cur = prev
        return out

    try:
        primary_days = _collect_recent_days(today, 3)
        for dt in primary_days:
            if dt in candidate_dates:
                target_date = dt
                break

        if target_date is None:
            try:
                settings = get_settings(create_dirs=False)
                cfg = getattr(settings, "cache", None)
                rolling_cfg = getattr(cfg, "rolling", None)
                max_stale = getattr(
                    rolling_cfg,
                    "max_staleness_days",
                    getattr(rolling_cfg, "max_stale_days", 2),
                )
                stale_limit = int(max_stale)
            except Exception:
                stale_limit = 2
            fallback_window = max(len(primary_days), stale_limit + 3)
            extended_days = _collect_recent_days(today, fallback_window)
            for dt in extended_days:
                if dt in candidate_dates:
                    target_date = dt
                    if dt not in primary_days:
                        fallback_reason = "recent"
                    break

        if target_date is None and candidate_dates:
            today_norm = pd.Timestamp(today).normalize()
            past_candidates = [d for d in candidate_dates if d <= today_norm]
            if past_candidates:
                target_date = max(past_candidates)
                if fallback_reason is None:
                    fallback_reason = "latest_past"
            else:
                target_date = max(candidate_dates)
                if fallback_reason is None:
                    fallback_reason = "latest_any"

        if log_callback:
            try:
                _cands_str = ", ".join([str(d.date()) for d in candidate_dates[:5]])
                _search_str = ", ".join([str(d.date()) for d in primary_days])
                _chosen = str(target_date.date()) if target_date is not None else "None"
                fallback_msg = ""
                if fallback_reason:
                    fallback_labels = {
                        "recent": "ç›´è¿‘å–¶æ¥­æ—¥ã«å€™è£œãŒç„¡ã„ãŸã‚éå»æ—¥ã‚’æ¡ç”¨",
                        "latest_past": "æ¢ç´¢ç¯„å›²å¤–ã®æœ€æ–°éå»æ—¥ã‚’æ¡ç”¨",
                        "latest_any": "æœªæ¥æ—¥ã—ã‹å­˜åœ¨ã—ãªã„ãŸã‚å€™è£œæœ€çµ‚æ—¥ã‚’æ¡ç”¨",
                    }
                    label = fallback_labels.get(fallback_reason, fallback_reason)
                    fallback_msg = f" | ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {label}"
                log_callback(
                    "ğŸ—“ï¸ å€™è£œæ—¥æ¢ç´¢: "
                    f"{_cands_str} | æ¢ç´¢æ—¥: {_search_str} | æ¡ç”¨: {_chosen}{fallback_msg}"
                )
            except Exception:
                pass
    except Exception:
        target_date = None
        fallback_reason = None

    try:
        if target_date is not None and target_date in key_map:
            orig_key = key_map[target_date]
            total_candidates_today = len(
                (candidates_by_date or {}).get(orig_key, []) or []
            )
        else:
            total_candidates_today = 0
    except Exception:
        total_candidates_today = 0

    try:
        if int(setup_pass) <= 0:
            total_candidates_today = 0
    except Exception:
        total_candidates_today = 0

    try:
        max_pos_ui = int(get_settings(create_dirs=False).risk.max_positions)
    except Exception:
        max_pos_ui = 10
    if total_candidates_today and max_pos_ui > 0:
        total_candidates_today = min(int(total_candidates_today), int(max_pos_ui))

    if log_callback:
        try:
            log_callback(f"ğŸ§© ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒã‚§ãƒƒã‚¯å®Œäº†ï¼š{setup_pass} éŠ˜æŸ„")
            log_callback(f"ğŸ§® å€™è£œç”Ÿæˆæ¸ˆã¿ï¼ˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é€šéï¼‰ï¼š{setup_pass} éŠ˜æŸ„")
            log_callback(
                f"ğŸ§® TRDlistç›¸å½“ï¼ˆç›´è¿‘å–¶æ¥­æ—¥æ™‚ç‚¹ã®å€™è£œæ•°ï¼‰ï¼š{total_candidates_today} éŠ˜æŸ„"
            )
        except Exception:
            pass

    # If there are no candidates, try to infer a reason for diagnostics
    zero_reason: str | None = None
    try:
        if int(total_candidates_today) == 0:
            if not key_map:
                zero_reason = "no_candidate_dates"
            else:
                zero_reason = "no_candidates_on_target_date"
    except Exception:
        zero_reason = None

    if int(total_candidates_today) == 0 and log_callback:
        try:
            if zero_reason:
                log_callback(f"â„¹ï¸ å€™è£œ0ä»¶ç†ç”±: {zero_reason}")
        except Exception:
            pass

    return CandidateSelection(
        key_map,
        target_date,
        fallback_reason,
        int(total_candidates_today),
        zero_reason,
    )


def _format_entry_skip_reason(debug_info: dict[str, Any] | None) -> str:
    if not debug_info:
        return "entry_stop_failed"
    reason = str(debug_info.get("reason") or "entry_stop_failed")
    fallback_reason = debug_info.get("fallback_reason")
    if fallback_reason:
        reason = f"{reason}:{fallback_reason}"
    details = debug_info.get("details")
    if isinstance(details, dict):
        missing_cols = details.get("missing_columns")
        if missing_cols:
            try:
                missing_iter = sorted(str(col) for col in missing_cols)
            except Exception:
                missing_iter = [str(missing_cols)]
            joined = ",".join(missing_iter)
            if joined:
                reason += f"[missing={joined}]"
        note = details.get("note")
        if note:
            reason += f"[{note}]"
    return reason


def _log_entry_skip_summary(
    stats: SkipStats,
    system_name: str,
    log_callback: Callable[[str], None] | None,
) -> None:
    if not stats.counts or log_callback is None:
        return
    try:
        sorted_items = sorted(stats.counts.items(), key=lambda x: x[1], reverse=True)
    except Exception:
        sorted_items = list(stats.counts.items())
    top = sorted_items[:3]
    system_label = str(system_name or "")
    try:
        total = sum(int(v) for _, v in stats.counts.items())
    except Exception:
        try:
            total = sum(stats.counts.values())
        except Exception:
            total = len(stats.counts)
    try:
        summary = ", ".join([f"{key}: {count}" for key, count in top])
        if summary:
            prefix = f"{system_label}: " if system_label else ""
            log_callback(f"âš ï¸ {prefix}ã‚¨ãƒ³ãƒˆãƒªãƒ¼è¨ˆç®—ã§å€™è£œé™¤å¤– (è¨ˆ{total}ä»¶): {summary}")
        for key, _ in top:
            samples = stats.samples.get(key) or []
            if samples:
                log_callback(f"  â†³ ({key}): {', '.join(samples)}")
    except Exception:
        pass


def _attach_entry_skip_attrs(frame: pd.DataFrame, stats: SkipStats) -> None:
    if not stats.counts:
        return
    try:
        frame.attrs["entry_skip_counts"] = dict(stats.counts)
    except Exception:
        pass
    try:
        if stats.samples:
            frame.attrs["entry_skip_samples"] = {
                key: list(value) for key, value in stats.samples.items()
            }
    except Exception:
        pass
    try:
        if stats.details:
            frame.attrs["entry_skip_details"] = list(stats.details[:50])
    except Exception:
        pass


def _build_today_signals_dataframe(
    strategy: Any,
    prepared: dict[str, pd.DataFrame] | pd.DataFrame | None,
    candidates_by_date: dict | None,
    selection: CandidateSelection,
    system_name: str,
    side: str,
    signal_type: str,
    log_callback: Callable[[str], None] | None,
) -> tuple[pd.DataFrame, int]:
    if selection.total_candidates_today <= 0:
        return _empty_today_signals_frame(), 0
    if not candidates_by_date:
        return _empty_today_signals_frame(), 0

    target_date = selection.target_date
    key_map = selection.key_map
    if target_date is not None and target_date in key_map:
        orig_key = key_map[target_date]
        today_raw = candidates_by_date.get(orig_key, [])
    else:
        today_raw = []

    # Normalize candidate payloads to a list[dict].
    # Some systems return {date: [{...}, {...}]}, others return {date: {symbol: {...}}}.
    today_candidates: list[dict] = []
    if isinstance(today_raw, list):
        # Expect a list of dicts
        today_candidates = [c for c in today_raw if isinstance(c, dict)]
    elif isinstance(today_raw, dict):
        # Expect a symbol->payload dict; inject symbol into each payload
        for _sym, _payload in today_raw.items():
            sym_str = str(_sym) if _sym is not None else ""
            if isinstance(_payload, dict):
                rec = dict(_payload)
                rec.setdefault("symbol", sym_str)
                # also attach the candidate date so we can derive entry_date later
                if target_date is not None and "date" not in rec:
                    rec["date"] = target_date
                today_candidates.append(rec)
            else:
                base = {"symbol": sym_str, "value": _payload}
                if target_date is not None:
                    base["date"] = target_date
                today_candidates.append(base)
    else:
        today_candidates = []
    if not today_candidates:
        return _empty_today_signals_frame(), 0

    entry_skip_stats = SkipStats()

    rows: list[TodaySignal] = []
    date_cache: dict[str, np.ndarray] = {}
    rank_cache: dict[
        tuple[str, pd.Timestamp, bool],
        tuple[list[tuple[str, float]], dict[str, int]],
    ] = {}

    def _find_column_ci(frame: pd.DataFrame, key: str) -> str | None:
        """Return the actual column name in frame matching key case-insensitively."""
        if not isinstance(key, str) or frame is None:
            return None
        cols = getattr(frame, "columns", [])
        if key in cols:
            return key
        key_lower = key.lower()
        for col in cols:
            if isinstance(col, str) and col.lower() == key_lower:
                return col
        return None

    def _get_normalized_dates(symbol: str, frame: pd.DataFrame) -> np.ndarray | None:
        cached = date_cache.get(symbol)
        if cached is not None:
            return cached
        if frame is None or getattr(frame, "empty", True):
            return None
        try:
            if "Date" in frame.columns:
                raw = pd.to_datetime(frame["Date"], errors="coerce")
                normalized = raw.dt.normalize()
            else:
                raw = pd.to_datetime(frame.index, errors="coerce")
                normalized = raw.normalize()
            values = normalized.to_numpy()
        except Exception:
            return None
        # Help static checkers: ensure ndarray type
        try:
            arr = cast(np.ndarray, values)
        except Exception:
            arr = np.asarray(values)
        date_cache[symbol] = arr
        return arr

    for c in today_candidates:
        sym = c.get("symbol")
        if not sym:
            entry_skip_stats.record("", "missing_symbol")
            continue
        # Guard against prepared being None or containing None entries
        if not isinstance(prepared, dict) or sym not in prepared:
            entry_skip_stats.record(str(sym), "missing_prepared_frame")
            continue
        df = prepared.get(sym)
        if df is None or getattr(df, "empty", True):
            entry_skip_stats.record(str(sym), "prepared_frame_empty")
            continue
        # Prefill candidate with last available Close
        # (and a common ATR) when entry_price is absent.
        try:
            if c.get("entry_price") is None:
                close_ci = _find_column_ci(df, "Close")
                if close_ci is not None and close_ci in df.columns:
                    last_close_ser = pd.to_numeric(
                        df[close_ci], errors="coerce"
                    ).dropna()
                    last_close_ser = last_close_ser[last_close_ser > 0]
                    if not last_close_ser.empty:
                        c["entry_price"] = float(last_close_ser.iloc[-1])
            # Optionally provide an ATR value hint to reduce fallback cost
            if all(k not in c for k in ("ATR20", "atr20", "atr10", "ATR10")):
                for k in ("ATR20", "atr20", "ATR10", "atr10", "ATR14", "atr14"):
                    ci = _find_column_ci(df, k)
                    if ci is None or ci not in df.columns:
                        continue
                    atr_ser = pd.to_numeric(df[ci], errors="coerce").dropna()
                    atr_ser = atr_ser[atr_ser > 0]
                    if not atr_ser.empty:
                        c[k] = float(atr_ser.iloc[-1])
                        break
        except Exception:
            pass
        debug_info: dict[str, Any] = {}
        comp = _compute_entry_stop(strategy, df, c, side, debug=debug_info)
        if not comp:
            reason_label = _format_entry_skip_reason(debug_info)
            entry_skip_stats.record(str(sym), reason_label)
            continue
        entry, stop = comp
        skey, sval, _asc = _score_from_candidate(system_name, c)

        try:
            if (system_name == "system1") and (
                skey is None or str(skey).upper() != "ROC200"
            ):
                skey = "ROC200"
        except Exception:
            pass

        signal_date_ts: pd.Timestamp | None = None
        try:
            if "Date" in c and c.get("Date") is not None:
                date_arg: Any = c.get("Date")
                tmp = pd.to_datetime(date_arg, errors="coerce")
                if not pd.isna(tmp):
                    signal_date_ts = pd.Timestamp(tmp).normalize()
        except Exception:
            pass
        if signal_date_ts is None:
            try:
                ed_arg: Any = c.get("entry_date")
                ed = pd.to_datetime(ed_arg, errors="coerce")
                if isinstance(ed, pd.Timestamp) and not pd.isna(ed):
                    signal_date_ts = get_latest_nyse_trading_day(
                        pd.Timestamp(ed).normalize() - pd.Timedelta(days=1)
                    )
            except Exception:
                signal_date_ts = None

        rank_val: int | None = None
        total_for_rank: int = 0
        try:
            raw_rank = c.get("rank")
            if raw_rank is not None and not pd.isna(raw_rank):
                rank_val = int(raw_rank)
        except Exception:
            rank_val = None
        try:
            raw_total = c.get("rank_total")
            if raw_total is not None and not pd.isna(raw_total):
                total_for_rank = int(raw_total)
        except Exception:
            total_for_rank = 0
        if skey is not None:
            if sval is None or (isinstance(sval, float) and pd.isna(sval)):
                try:
                    if signal_date_ts is not None:
                        dt_vals = _get_normalized_dates(str(sym), df)
                        if dt_vals is not None:
                            mask = dt_vals == signal_date_ts
                            if mask.any():
                                row = df.loc[mask]
                                if not row.empty:
                                    ci = _find_column_ci(row, skey)
                                    if ci is not None and ci in row.columns:
                                        _v = row.iloc[0][ci]
                                        if _v is not None and not pd.isna(_v):
                                            sval = float(_v)
                except Exception:
                    pass
            if (system_name == "system1") and (
                sval is None or (isinstance(sval, float) and pd.isna(sval))
            ):
                try:
                    ci2 = _find_column_ci(df, skey)
                    if ci2 is not None and ci2 in df.columns:
                        _v = pd.Series(df[ci2]).dropna().tail(1).iloc[0]
                        sval = float(_v)
                except Exception:
                    pass

            try:
                needs_rank_eval = (
                    rank_val is None or total_for_rank == 0 or sval is None
                )
                if signal_date_ts is not None and needs_rank_eval:
                    if isinstance(prepared, dict):
                        cache_key = (str(skey), signal_date_ts, bool(_asc))
                        cached_vals = rank_cache.get(cache_key)
                        if cached_vals is None:
                            vals: list[tuple[str, float]] = []
                            for psym, pdf in prepared.items():
                                if pdf is None or getattr(pdf, "empty", True):
                                    continue
                                try:
                                    dt_vals = _get_normalized_dates(str(psym), pdf)
                                    if dt_vals is None:
                                        continue
                                    mask = dt_vals == signal_date_ts
                                    if not mask.any():
                                        continue
                                    row = pdf.loc[mask]
                                    ci_inner = _find_column_ci(row, skey)
                                    if (
                                        row.empty
                                        or ci_inner is None
                                        or ci_inner not in row.columns
                                    ):
                                        continue
                                    val = row.iloc[0][ci_inner]
                                    if val is None or pd.isna(val):
                                        continue
                                    vals.append((str(psym), float(val)))
                                except Exception:
                                    continue
                            if vals:
                                vals_sorted = sorted(
                                    vals, key=lambda x: x[1], reverse=not _asc
                                )
                                ranks = {
                                    name: idx + 1
                                    for idx, (name, _) in enumerate(vals_sorted)
                                }
                            else:
                                vals_sorted = []
                                ranks = {}
                            cached_vals = (vals_sorted, ranks)
                            rank_cache[cache_key] = cached_vals
                        vals_sorted, ranks = cached_vals
                        if total_for_rank == 0:
                            total_for_rank = len(vals_sorted)
                        if rank_val is None:
                            rank_val = ranks.get(str(sym))
                        if (
                            sval is None
                            and rank_val is not None
                            and 0 < rank_val <= len(vals_sorted)
                        ):
                            sval = float(vals_sorted[rank_val - 1][1])
            except Exception:
                pass

        reason_parts: list[str] = []
        if system_name == "system1":
            if rank_val is not None and int(rank_val) <= 10:
                formatted = _format_rank_reason("ROC200", rank_val, total_for_rank)
                if formatted:
                    reason_parts = [formatted]
                else:
                    reason_parts = ["ROC200ãŒä¸Šä½ã®ãŸã‚"]
            else:
                reason_parts = ["ROC200ãŒä¸Šä½ã®ãŸã‚"]
        elif system_name == "system2":
            if rank_val is not None and skey is not None:
                label = _label_for_score_key(skey)
                formatted = _format_rank_reason(label, rank_val, total_for_rank)
                if formatted:
                    reason_parts = [formatted]
            if not reason_parts:
                reason_parts = ["ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ãŒå¼·ãéç†±ã®ãŸã‚"]
        elif system_name == "system3":
            if rank_val is not None and skey is not None:
                label = _label_for_score_key(skey)
                formatted = _format_rank_reason(label, rank_val, total_for_rank)
                if formatted:
                    reason_parts = [formatted]
            if not reason_parts:
                reason_parts = ["ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒé«˜ãæ¡ä»¶ä¸€è‡´ã®ãŸã‚"]
        elif system_name == "system4":
            if rank_val is not None:
                formatted = _format_rank_reason(
                    "RSI4", rank_val, total_for_rank, nuance="ä½æ°´æº–"
                )
                if formatted:
                    reason_parts = [formatted]
            if not reason_parts:
                reason_parts = ["SPYä¸Šæ˜‡å±€é¢ã®æŠ¼ã—ç›®å€™è£œã®ãŸã‚"]
        elif system_name == "system5":
            if rank_val is not None and skey is not None:
                label = _label_for_score_key(skey)
                formatted = _format_rank_reason(label, rank_val, total_for_rank)
                if formatted:
                    reason_parts = [formatted]
            if not reason_parts:
                reason_parts = ["ADXãŒå¼·ãã€åç™ºæœŸå¾…ã®ãŸã‚"]
        elif system_name == "system6":
            if rank_val is not None:
                formatted = _format_rank_reason(
                    "éå»6æ—¥é¨°è½ç‡", rank_val, total_for_rank
                )
                if formatted:
                    reason_parts = [formatted]
            if not reason_parts:
                reason_parts = ["çŸ­æœŸä¸‹è½ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆã‚·ãƒ§ãƒ¼ãƒˆï¼‰æ¡ä»¶ä¸€è‡´ã®ãŸã‚"]
        elif system_name == "system7":
            reason_parts = ["SPYãŒ50æ—¥å®‰å€¤ã‚’æ›´æ–°ã—ãŸãŸã‚ï¼ˆãƒ˜ãƒƒã‚¸ï¼‰"]
        else:
            if skey is not None and rank_val is not None:
                label = _label_for_score_key(skey)
                formatted = _format_rank_reason(label, rank_val, total_for_rank)
                if formatted:
                    reason_parts = [formatted]
                elif rank_val <= 10:
                    reason_parts = [f"{label}ãŒ{rank_val}ä½ã®ãŸã‚"]
                else:
                    total_label = total_for_rank if total_for_rank > 0 else "?"
                    reason_parts = [f"rank={rank_val}/{total_label}"]
            elif skey is not None:
                try:
                    if sval is not None and not (
                        isinstance(sval, float) and pd.isna(sval)
                    ):
                        reason_parts.append("ã‚¹ã‚³ã‚¢æ¡ä»¶ã‚’æº€ãŸã—ãŸãŸã‚")
                except Exception:
                    reason_parts.append("ã‚¹ã‚³ã‚¢æ¡ä»¶ã‚’æº€ãŸã—ãŸãŸã‚")

        if not reason_parts:
            reason_parts.append("æ¡ä»¶ä¸€è‡´ã®ãŸã‚")

        reason_text = "; ".join(reason_parts)

        # Resolve entry_date; if missing, derive from candidate date
        try:
            _ed_raw: Any = c.get("entry_date")
            _ed = pd.Timestamp(_ed_raw) if _ed_raw is not None else None
        except Exception:
            _ed = None
        if _ed is None or (isinstance(_ed, pd.Timestamp) and pd.isna(_ed)):
            # derive from 'date' field when available
            try:
                cand_dt_raw: Any = c.get("date") or c.get("Date")
                cand_dt_ts = pd.to_datetime(cand_dt_raw, errors="coerce")
                if not pd.isna(cand_dt_ts):
                    cand_dt_norm = pd.Timestamp(cand_dt_ts).normalize()
                    try:
                        from common.utils_spy import (
                            resolve_signal_entry_date as _res_entry,
                        )

                        _ed = _res_entry(cand_dt_norm)
                    except Exception:
                        _ed = cand_dt_norm
            except Exception:
                _ed = None
        if _ed is None or (isinstance(_ed, pd.Timestamp) and pd.isna(_ed)):
            continue
        entry_date_norm = pd.Timestamp(_ed).normalize()

        # å…¨ATRå€¤ã‚’å€™è£œã‹ã‚‰å–å¾—ï¼ˆé…åˆ†è¨ˆç®—ç”¨ï¼‰
        # ã‚·ã‚¹ãƒ†ãƒ ã”ã¨ã«ç•°ãªã‚‹ATRã‚’ä½¿ç”¨: S1=atr20, S2/3/5/6=atr10, S4=atr40, S7=atr50
        atr10_val = None
        atr20_val = None
        atr40_val = None
        atr50_val = None

        try:
            # atr10
            for key in ("atr10", "ATR10", "atr_10", "ATR_10"):
                if key in c:
                    raw = c.get(key)
                    if raw is not None and not (
                        isinstance(raw, float) and pd.isna(raw)
                    ):
                        atr10_val = float(raw)
                        break

            # atr20
            for key in ("atr20", "ATR20", "atr_20", "ATR_20"):
                if key in c:
                    raw = c.get(key)
                    if raw is not None and not (
                        isinstance(raw, float) and pd.isna(raw)
                    ):
                        atr20_val = float(raw)
                        break

            # atr40
            for key in ("atr40", "ATR40", "atr_40", "ATR_40"):
                if key in c:
                    raw = c.get(key)
                    if raw is not None and not (
                        isinstance(raw, float) and pd.isna(raw)
                    ):
                        atr40_val = float(raw)
                        break

            # atr50
            for key in ("atr50", "ATR50", "atr_50", "ATR_50"):
                if key in c:
                    raw = c.get(key)
                    if raw is not None and not (
                        isinstance(raw, float) and pd.isna(raw)
                    ):
                        atr50_val = float(raw)
                        break
        except Exception:
            pass

        rows.append(
            TodaySignal(
                symbol=str(sym),
                system=system_name,
                side=side,
                signal_type=signal_type,
                entry_date=entry_date_norm,
                entry_price=float(entry),
                stop_price=float(stop),
                score_key=skey,
                score=(
                    None
                    if sval is None or (isinstance(sval, float) and pd.isna(sval))
                    else float(sval)
                ),
                score_rank=None if rank_val is None else int(rank_val),
                score_rank_total=(None if total_for_rank <= 0 else int(total_for_rank)),
                reason=reason_text,
                atr10=atr10_val,
                atr20=atr20_val,
                atr40=atr40_val,
                atr50=atr50_val,
            )
        )

    if not rows:
        _log_entry_skip_summary(entry_skip_stats, system_name, log_callback)
        top_reason: str | None = None
        if entry_skip_stats.counts:
            try:
                top_reason = max(
                    entry_skip_stats.counts.items(), key=lambda item: item[1]
                )[0]
            except Exception:
                try:
                    top_reason = next(iter(entry_skip_stats.counts.keys()), None)
                except Exception:
                    top_reason = None
        frame_empty = _empty_today_signals_frame(
            f"entry_stop_failed:{top_reason}" if top_reason else None
        )
        _attach_entry_skip_attrs(frame_empty, entry_skip_stats)
        return frame_empty, 0

    out = pd.DataFrame([r.__dict__ for r in rows])
    _attach_entry_skip_attrs(out, entry_skip_stats)
    _log_entry_skip_summary(entry_skip_stats, system_name, log_callback)

    try:
        max_pos = int(get_settings(create_dirs=False).risk.max_positions)
    except Exception:
        max_pos = 10
    if max_pos > 0 and not out.empty:

        def _sort_val(row: pd.Series) -> float:
            sc = row.get("score")
            sk = row.get("score_key")
            if sc is None or (isinstance(sc, float) and pd.isna(sc)):
                return float("inf")
            return float(sc) if _asc_by_score_key(sk) else -float(sc)

        out["_sort_val"] = out.apply(_sort_val, axis=1)
        out = (
            out.sort_values("_sort_val")
            .head(max_pos)
            .drop(columns=["_sort_val"])
            .reset_index(drop=True)
        )
    final_count = len(out)

    if log_callback:
        try:
            log_callback(f"ğŸ§® ãƒˆãƒ¬ãƒ¼ãƒ‰å€™è£œé¸å®šå®Œäº†ï¼ˆå½“æ—¥ï¼‰ï¼š{final_count} éŠ˜æŸ„")
        except Exception:
            pass

    return out, final_count


def _empty_today_signals_frame(reason: str | None = None) -> pd.DataFrame:
    frame = pd.DataFrame(columns=TODAY_SIGNAL_COLUMNS)
    if reason is not None:
        try:
            frame.attrs["zero_reason"] = str(reason)
        except Exception:
            frame.attrs["zero_reason"] = "unknown"
    return frame


def _normalize_daily_index(df: pd.DataFrame) -> pd.DataFrame:
    x = df.copy()
    if "Date" in x.columns:
        idx = pd.to_datetime(x["Date"], errors="coerce").dt.normalize()
        x.index = pd.Index(idx)
    else:
        x.index = pd.to_datetime(x.index, errors="coerce").normalize()
    x = x[~x.index.isna()]
    try:
        x = x.sort_index()
    except Exception:
        pass
    try:
        if getattr(x.index, "has_duplicates", False):
            x = x[~x.index.duplicated(keep="last")]
    except Exception:
        pass
    return x


def _make_spy_gate(spy_df: pd.DataFrame | None, column: str = "SMA200") -> bool | None:
    if spy_df is None or getattr(spy_df, "empty", True):
        return None
    try:
        last_row = spy_df.iloc[-1]
    except Exception:
        return None
    try:
        close_val = pd.to_numeric(
            pd.Series([last_row.get("Close")]), errors="coerce"
        ).iloc[0]
        sma_val = pd.to_numeric(
            pd.Series([last_row.get(column)]), errors="coerce"
        ).iloc[0]
    except Exception:
        return None
    if pd.isna(close_val) or pd.isna(sma_val):
        return None
    try:
        return bool(float(close_val) > float(sma_val))
    except Exception:
        return None


def _infer_side(system_name: str) -> str:
    name = (system_name or "").lower()
    if name in SHORT_SYSTEMS:
        return "short"
    return "long"


def _score_from_candidate(
    system_name: str, candidate: dict
) -> tuple[str | None, float | None, bool]:
    """
    å€™è£œãƒ¬ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã‚¹ã‚³ã‚¢é …ç›®ã¨ä¸¦ã³é †ï¼ˆæ˜‡é †ã‹ï¼‰ã‚’æ¨å®šã—ã¦è¿”ã™ã€‚
    æˆ»ã‚Šå€¤: (score_key, score_value, asc)
    """
    name = (system_name or "").lower()
    # System7 ã¯ SPY å°‚ç”¨ãƒ˜ãƒƒã‚¸ã€‚ATR50 ã¯ã‚¹ãƒˆãƒƒãƒ—è¨ˆç®—ç”¨ã®ãŸã‚ã€
    # ã‚¹ã‚³ã‚¢/ç†ç”±ã«ã¯ä½¿ç”¨ã—ãªã„ï¼ˆã‚¹ã‚³ã‚¢æ¬„ã¯ç©ºã«ã™ã‚‹ï¼‰ã€‚
    if name == "system7":
        return None, None, False
    # ã‚·ã‚¹ãƒ†ãƒ åˆ¥ã®ä»£è¡¨ã‚¹ã‚³ã‚¢
    key_order: list[tuple[list[str], bool]] = [
        (["ROC200"], False),  # s1: å¤§ãã„ã»ã©è‰¯ã„
        (["ADX7"], False),  # s2,s5: å¤§ãã„ã»ã©è‰¯ã„
        (["Drop3D"], False),  # s3: å¤§ãã„ã»ã©è‰¯ã„ï¼ˆä¸‹è½ç‡ï¼‰
        (["RSI4"], True),  # s4: å°ã•ã„ã»ã©è‰¯ã„
        (["return_6d"], False),  # s6: å¤§ãã„ã»ã©è‰¯ã„
        (["ATR50"], False),  # s7: å‚è€ƒ
    ]
    # system å›ºæœ‰å„ªå…ˆé †ä½
    if name == "system4":
        key_order = [(["RSI4"], True), (["ATR40"], True)] + key_order
    elif name == "system2":
        key_order = [(["ADX7"], False), (["RSI3"], False)] + key_order
    elif name == "system5":
        key_order = [(["ADX7"], False), (["ATR10"], True)] + key_order
    elif name == "system6":
        key_order = [(["return_6d"], False), (["ATR10"], True)] + key_order

    # Case-insensitive key lookup
    try:
        ci_map: dict[str, tuple[str, object]] = {}
        for ck, cv in candidate.items():
            if isinstance(ck, str):
                low = ck.lower()
                if low not in ci_map:
                    ci_map[low] = (ck, cv)
    except Exception:
        ci_map = {}

    def _get_ci(k: str) -> tuple[str, object] | None:
        if k in candidate:
            return k, candidate.get(k)
        low = k.lower()
        return ci_map.get(low)

    for keys, asc in key_order:
        for k in keys:
            found = _get_ci(k)
            if found is None:
                continue
            actual_key, v = found
            if v is None:
                return actual_key, None, asc
            if isinstance(v, (int, float, str)):
                try:
                    return actual_key, float(v), asc
                except Exception:
                    return actual_key, None, asc
            else:
                return actual_key, None, asc
    # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    return None, None, False


def _label_for_score_key(key: str | None) -> str:
    """ã‚¹ã‚³ã‚¢ã‚­ãƒ¼ã®æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã‚’è¿”ã™ï¼ˆæ—¢çŸ¥ã®ã‚‚ã®ã®ã¿ç°¡æ½”è¡¨ç¤ºï¼‰ã€‚"""
    if key is None:
        return "ã‚¹ã‚³ã‚¢"
    k = str(key).upper()
    mapping = {
        "ROC200": "ROC200",
        "ADX7": "ADX",
        "RSI4": "RSI4",
        "RSI3": "RSI3",
        "DROP3D": "3æ—¥ä¸‹è½ç‡",
        "RETURN_6D": "éå»6æ—¥é¨°è½ç‡",
        "ATR10": "ATR10",
        "ATR20": "ATR20",
        "ATR40": "ATR40",
        "ATR50": "ATR50",
    }
    return mapping.get(k, k)


def _format_rank_reason(
    label: str,
    rank: int | None,
    total: int,
    *,
    nuance: str | None = None,
) -> str | None:
    """ãƒ©ãƒ³ã‚­ãƒ³ã‚°æƒ…å ±ã‚’å«ã‚€ç†ç”±æ–‡ã‚’ç”Ÿæˆã™ã‚‹ã€‚"""

    if rank is None:
        return None
    try:
        rank_val = int(rank)
    except Exception:
        return None
    try:
        total_val = int(total)
    except Exception:
        total_val = 0

    base_label = str(label or "ã‚¹ã‚³ã‚¢")
    if total_val > 0:
        if nuance:
            return f"{base_label}ãŒ{rank_val}ä½ï¼ˆå…¨{total_val}éŠ˜æŸ„ä¸­ã€{nuance}ï¼‰ã®ãŸã‚"
        return f"{base_label}ãŒ{rank_val}ä½ï¼ˆå…¨{total_val}éŠ˜æŸ„ä¸­ï¼‰ã®ãŸã‚"
    if nuance:
        return f"{base_label}ãŒ{rank_val}ä½ï¼ˆ{nuance}ï¼‰ã®ãŸã‚"
    return f"{base_label}ãŒ{rank_val}ä½ã®ãŸã‚"


def _asc_by_score_key(score_key: str | None) -> bool:
    """ã‚¹ã‚³ã‚¢ã‚­ãƒ¼ã”ã¨ã®æ˜‡é †/é™é †ã‚’åˆ¤å®šã€‚"""
    return bool(score_key and score_key.upper() in {"RSI4"})


def _atr_column_candidates(df: pd.DataFrame, system_name: str | None) -> list[str]:
    def _is_numeric_atr(col: str) -> bool:
        return col.upper().startswith("ATR") and any(ch.isdigit() for ch in col)

    base_order = ("ATR20", "ATR10", "ATR40", "ATR50", "ATR14")
    system_specific = {
        "system1": ("ATR20", "ATR10", "ATR14", "ATR40", "ATR50"),
        "system2": ("ATR10", "ATR20", "ATR14", "ATR40", "ATR50"),
        "system3": ("ATR10", "ATR20", "ATR14", "ATR40", "ATR50"),
        "system4": ("ATR40", "ATR20", "ATR10", "ATR50", "ATR14"),
        "system5": ("ATR10", "ATR20", "ATR14", "ATR40", "ATR50"),
        "system6": ("ATR10", "ATR20", "ATR14", "ATR40", "ATR50"),
        "system7": ("ATR50", "ATR40", "ATR20", "ATR10", "ATR14"),
    }

    name = (system_name or "").lower()
    preferred = system_specific.get(name, base_order)
    ordered: list[str] = []
    for col in preferred:
        if isinstance(col, str) and col in df.columns and _is_numeric_atr(col):
            ordered.append(col)
    for col in df.columns:
        if not isinstance(col, str):
            continue
        if col in ordered or not col.upper().startswith("ATR"):
            continue
        if not any(ch.isdigit() for ch in col):
            continue
        ordered.append(col)
    return ordered


def _resolve_stop_atr_multiple(strategy: Any, system_name: str) -> float:
    name = (system_name or "").lower()
    try:
        config = getattr(strategy, "config", None)
    except Exception:
        config = None
    if config is not None:
        candidate = None
        try:
            if isinstance(config, dict):
                candidate = config.get("stop_atr_multiple")
            elif hasattr(config, "get"):
                candidate = config.get("stop_atr_multiple")
            else:
                candidate = getattr(config, "stop_atr_multiple", None)
        except Exception:
            candidate = getattr(config, "stop_atr_multiple", None)
        if candidate is not None:
            try:
                value = float(candidate)
            except (TypeError, ValueError):
                value = None
            else:
                if value is not None and math.isfinite(value) and value > 0:
                    return float(value)
    try:
        fallback = STOP_MULTIPLIER_BY_SYSTEM.get(name, STOP_ATR_MULTIPLE_DEFAULT)
        return float(fallback)
    except Exception:
        return float(STOP_ATR_MULTIPLE_DEFAULT)


def _compute_entry_stop(
    strategy: Any,
    df: pd.DataFrame,
    candidate: dict,
    side: str,
    *,
    debug: dict[str, Any] | None = None,
) -> tuple[float, float] | None:
    def _set_reason(reason: str) -> None:
        if debug is not None and reason and "reason" not in debug:
            debug["reason"] = reason

    def _record_detail(key: str, value: Any) -> None:
        if debug is None:
            return
        details = debug.setdefault("details", {})
        if key not in details:
            details[key] = value

    def _set_fallback_reason(reason: str) -> None:
        if debug is not None and reason and "fallback_reason" not in debug:
            debug["fallback_reason"] = reason

    try:
        system_name = str(getattr(strategy, "SYSTEM_NAME", "")).lower()
    except Exception:
        system_name = ""

    # strategy ç‹¬è‡ªã® compute_entry ãŒã‚ã‚Œã°å„ªå…ˆ
    try:
        _fn = getattr(strategy, "compute_entry", None)
    except Exception:
        _fn = None
    if callable(_fn):
        try:
            res = _fn(df, candidate, 0.0)
            if res and isinstance(res, tuple) and len(res) == 2:
                e, st = float(res[0]), float(res[1])
                if e > 0 and (
                    (side == "short" and st > e) or (side == "long" and e > st)
                ):
                    return round(e, 4), round(st, 4)
        except Exception as exc:
            _record_detail("strategy_compute_entry_error", str(exc))

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å½“æ—¥å§‹å€¤ Â± stop_atr_multiple * ATR
    def _as_positive(value: Any) -> float | None:
        try:
            val = float(value)
        except (TypeError, ValueError):
            return None
        if not math.isfinite(val) or val <= 0:
            return None
        return val

    def _latest_positive(series: pd.Series | None) -> float | None:
        if series is None:
            return None
        try:
            numeric = pd.to_numeric(series, errors="coerce").dropna()
        except Exception:
            return None
        numeric = numeric[numeric > 0]
        if numeric.empty:
            return None
        val = float(numeric.iloc[-1])
        if not math.isfinite(val) or val <= 0:
            return None
        return val

    def _infer_atr_window(name: str | None, default: int = 14) -> int:
        if not name:
            return default
        digits = "".join(ch for ch in str(name) if ch.isdigit())
        if not digits:
            return default
        try:
            window = int(digits)
        except ValueError:
            return default
        return max(1, window)

    def _get_series_ci(frame: pd.DataFrame | None, key: str) -> pd.Series | None:
        if frame is None:
            return None
        cols = getattr(frame, "columns", [])
        if key in cols:
            try:
                return frame[key]
            except Exception:
                pass
        lower = key.lower()
        for col in cols:
            if isinstance(col, str) and col.lower() == lower:
                try:
                    return frame[col]
                except Exception:
                    try:
                        return frame.get(col)
                    except Exception:
                        continue
        try:
            val = frame.get(lower)
            return val if isinstance(val, pd.Series) else None
        except Exception:
            return None

    def _get_value_ci(series: pd.Series | None, key: str) -> Any:
        if series is None:
            return None
        try:
            if key in series:
                return series.get(key)
        except Exception:
            pass
        lower = key.lower()
        for col in getattr(series, "index", []):
            if isinstance(col, str) and col.lower() == lower:
                try:
                    return series[col]
                except Exception:
                    try:
                        return series.get(col)
                    except Exception:
                        return None
        try:
            return series.get(lower)
        except Exception:
            return None

    def _fallback_atr(frame: pd.DataFrame, window: int) -> float | None:
        if frame is None or frame.empty:
            _set_fallback_reason("empty_frame")
            return None
        col_map: dict[str, str] = {}
        for col in getattr(frame, "columns", []):
            if isinstance(col, str):
                lower = col.lower()
                if lower not in col_map:
                    col_map[lower] = col
        required = {"high", "low", "close"}
        missing_lower = [c for c in required if c not in col_map]
        if missing_lower:
            _set_fallback_reason("missing_columns")
            formatted = [m.capitalize() for m in missing_lower]
            _record_detail("missing_columns", formatted)
            return None
        try:
            high = pd.to_numeric(frame[col_map["high"]], errors="coerce")
            low = pd.to_numeric(frame[col_map["low"]], errors="coerce")
            close = pd.to_numeric(frame[col_map["close"]], errors="coerce")
        except Exception as exc:
            _set_fallback_reason("numeric_conversion_failed")
            _record_detail("note", f"fallback_numeric_error:{exc}")
            return None
        tr = pd.concat(
            [
                high - low,
                (high - close.shift()).abs(),
                (low - close.shift()).abs(),
            ],
            axis=1,
        ).max(axis=1)
        if tr.dropna().empty:
            _set_fallback_reason("no_true_range")
            return None
        window_val = max(1, int(window or 14))
        _record_detail("atr_window", window_val)
        min_periods = min(window_val, max(2, min(5, len(tr))))
        atr_series = tr.rolling(window_val, min_periods=min_periods).mean()
        result = _latest_positive(atr_series)
        if result is None:
            _set_fallback_reason("no_positive_atr")
        return result

    entry_ts = None
    if isinstance(candidate, dict):
        try:
            raw = candidate.get("entry_date")
            if raw is not None:
                tmp = pd.to_datetime(raw, errors="coerce")
                if not pd.isna(tmp):
                    entry_ts = tmp
        except Exception:
            entry_ts = None
    else:
        try:
            tmp = pd.to_datetime(candidate, errors="coerce")
            if not pd.isna(tmp):
                entry_ts = tmp
        except Exception:
            entry_ts = None

    entry_idx = -1
    if entry_ts is not None:
        try:
            idxer = df.index.get_indexer([entry_ts])
            entry_idx = int(idxer[0]) if len(idxer) else -1
        except Exception:
            entry_idx = -1

    atr_candidates = _atr_column_candidates(df, system_name)
    atr_column = atr_candidates[0] if atr_candidates else None
    atr_window = _infer_atr_window(atr_column)

    entry: float | None = None
    atr_val: float | None = None
    if 0 <= entry_idx < len(df):
        row = df.iloc[entry_idx]
        entry = _as_positive(_get_value_ci(row, "Open"))
        if entry is not None:
            _record_detail("entry_source", "row_open")
        if entry_idx > 0:
            prev_row = df.iloc[max(entry_idx - 1, 0)]
            for col in atr_candidates:
                candidate_val = _as_positive(_get_value_ci(prev_row, col))
                if candidate_val is not None:
                    atr_val = candidate_val
                    atr_column = col
                    atr_window = _infer_atr_window(col, atr_window)
                    try:
                        _record_detail("atr_window", int(atr_window))
                    except Exception:
                        pass
                    _record_detail("atr_source", f"prev_row:{col}")
                    break
    else:
        # Entry day not found (likely next trading day not yet in df).
        # Use latest series fallback explicitly.
        try:
            # Prefer previous day's Close as entry fallback
            close_col = None
            for col in getattr(df, "columns", []):
                if isinstance(col, str) and col.lower() == "close":
                    close_col = col
                    break
            if close_col is not None:
                series = pd.to_numeric(df[close_col], errors="coerce").dropna()
                series = series[series > 0]
                if not series.empty:
                    entry = float(series.iloc[-1])
                    _record_detail("entry_source", "prev_close_fallback")
        except Exception:
            pass
        if entry is None:
            try:
                open_col = None
                for col in getattr(df, "columns", []):
                    if isinstance(col, str) and col.lower() == "open":
                        open_col = col
                        break
                if open_col is not None:
                    series = pd.to_numeric(df[open_col], errors="coerce").dropna()
                    series = series[series > 0]
                    if not series.empty:
                        entry = float(series.iloc[-1])
                        _record_detail("entry_source", "prev_open_fallback")
            except Exception:
                pass
        # Also pick latest positive ATR from available ATR columns if needed
        if atr_val is None and atr_column:
            try:
                atr_series_tmp = pd.to_numeric(df[atr_column], errors="coerce").dropna()
                atr_series_tmp = atr_series_tmp[atr_series_tmp > 0]
                if not atr_series_tmp.empty:
                    atr_val = float(atr_series_tmp.iloc[-1])
                    try:
                        _record_detail(
                            "atr_window",
                            int(_infer_atr_window(atr_column, atr_window)),
                        )
                    except Exception:
                        pass
                    _record_detail("atr_source", f"latest:{atr_column}")
            except Exception:
                pass

    if isinstance(candidate, dict):
        if entry is None:
            for key in ("entry_price", "open", "close", "price", "last_price"):
                if key in candidate:
                    entry_candidate = _as_positive(candidate.get(key))
                    if entry_candidate is not None:
                        entry = entry_candidate
                        _record_detail("entry_source", f"candidate:{key}")
                        break
        if atr_val is None:
            for key, value in candidate.items():
                if not isinstance(key, str):
                    continue
                if "atr" not in key.lower():
                    continue
                atr_candidate = _as_positive(value)
                if atr_candidate is not None:
                    atr_val = atr_candidate
                    atr_window = _infer_atr_window(key, atr_window)
                    try:
                        _record_detail("atr_window", int(atr_window))
                    except Exception:
                        pass
                    _record_detail("atr_source", f"candidate:{key}")
                    break

    if entry is None:
        close_series = _get_series_ci(df, "Close")
        entry = _latest_positive(close_series)
        if entry is not None:
            _record_detail("entry_source", "close_series")
    if entry is None:
        open_series = _get_series_ci(df, "Open")
        entry = _latest_positive(open_series)
        if entry is not None:
            _record_detail("entry_source", "open_series")
    if entry is None:
        _set_reason("entry_price_missing")
        return None

    if atr_val is None and atr_column:
        atr_series: pd.Series | None = _get_series_ci(df, atr_column)
        if atr_series is None:
            try:
                val = df.get(atr_column)
                atr_series = val if isinstance(val, pd.Series) else None
            except Exception:
                atr_series = None
        atr_val = _latest_positive(atr_series)
        if atr_val is not None:
            try:
                _record_detail(
                    "atr_window",
                    int(_infer_atr_window(atr_column, atr_window)),
                )
            except Exception:
                pass
            _record_detail("atr_source", f"column:{atr_column}")
    if atr_val is None:
        atr_val = _fallback_atr(df, atr_window)
        if atr_val is not None:
            _record_detail("atr_source", f"fallback:{atr_window}")
    if atr_val is None:
        _set_reason("atr_missing")
        return None

    mult = _resolve_stop_atr_multiple(strategy, system_name)
    stop = entry - mult * atr_val if side == "long" else entry + mult * atr_val
    if (side == "long" and stop >= entry) or (side == "short" and stop <= entry):
        _set_reason("invalid_stop")
        return None

    return round(entry, 4), round(stop, 4)


def get_today_signals_for_strategy(
    strategy: Any,
    raw_data_dict: dict[str, pd.DataFrame],
    *,
    market_df: pd.DataFrame | None = None,
    today: pd.Timestamp | None = None,
    progress_callback: Callable[..., None] | None = None,
    log_callback: Callable[[str], None] | None = None,
    stage_progress: (
        Callable[[int, int | None, int | None, int | None, int | None], None] | None
    ) = None,
    use_process_pool: bool = False,
    max_workers: int | None = None,
    lookback_days: int | None = None,
) -> pd.DataFrame:
    """
    å„ Strategy ã® prepare_data / generate_candidates ã‚’æµç”¨ã—ã€
    æœ€æ–°å–¶æ¥­æ—¥ã®å€™è£œã®ã¿ã‚’ DataFrame ã§è¿”ã™ã€‚

    æˆ»ã‚Šå€¤ã‚«ãƒ©ãƒ :
        - symbol, system, side, signal_type,
          entry_date, entry_price, stop_price,
          score_key, score
    """
    try:
        system_name = str(getattr(strategy, "SYSTEM_NAME", "")).lower()
    except Exception:
        system_name = ""
    side = _infer_side(system_name)
    signal_type = "sell" if side == "short" else "buy"

    # CLIå®Ÿè¡Œæ™‚ãªã©ã§log_callbackæœªæŒ‡å®šã®å ´åˆã¯ã€æ¨™æº–å‡ºåŠ›ã¸å‡ºã™ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’é©ç”¨
    if log_callback is None:
        log_callback = _default_cli_log

    today_ts = _normalize_today(today)

    total_symbols = len(raw_data_dict)
    if log_callback is not None:
        try:
            log_callback(f"ğŸ§ª ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒã‚§ãƒƒã‚¯é–‹å§‹ï¼š{total_symbols} éŠ˜æŸ„")
        except Exception:
            pass
    try:
        if stage_progress:
            stage_progress(0, total_symbols, None, None, None)
    except Exception:
        pass

    t0 = _t.time()
    sliced_dict = _slice_data_for_lookback(raw_data_dict, lookback_days)

    prepare_result = _prepare_strategy_data(
        strategy,
        sliced_dict,
        progress_callback=progress_callback,
        log_callback=log_callback,
        use_process_pool=use_process_pool,
        max_workers=max_workers,
        lookback_days=lookback_days,
    )
    if prepare_result.early_exit_frame is not None:
        if (log_callback is not None) and prepare_result.early_exit_reason:
            try:
                log_callback(f"ğŸ›ˆ ä¸­æ–­ç†ç”±ã‚³ãƒ¼ãƒ‰: {prepare_result.early_exit_reason}")
            except Exception:
                pass
        return prepare_result.early_exit_frame

    prepared: dict[str, pd.DataFrame] | pd.DataFrame | None = prepare_result.prepared
    prepared = _apply_shortability_filter(
        system_name, prepared, prepare_result.skip_stats, log_callback
    )
    prepared, _stale_alerts, _stale_suppressed = _filter_by_data_freshness(
        prepared,
        today_ts,
        prepare_result.skip_stats,
        log_callback,
    )

    _log_elapsed(log_callback, "â±ï¸ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼/å‰å‡¦ç†å®Œäº†", t0)
    prepare_result.skip_stats.log_summary(system_name, log_callback)

    filter_pass = _compute_filter_pass(system_name, prepared, today_ts, log_callback)
    try:
        if stage_progress:
            stage_progress(25, filter_pass, None, None, None)
    except Exception:
        pass

    candidates = _generate_candidates_for_system(
        strategy,
        prepared,
        system_name=system_name,
        market_df=market_df,
        filter_pass=filter_pass,
        progress_callback=progress_callback,
        log_callback=log_callback,
    )
    candidate_diagnostics = candidates.diagnostics
    if candidates.early_exit_frame is not None:
        try:
            if stage_progress:
                stage_progress(75, filter_pass, None, None, None)
                stage_progress(100, filter_pass, None, 0, 0)
        except Exception:
            pass
        return candidates.early_exit_frame

    market_df = candidates.market_df
    candidates_by_date = candidates.candidates_by_date

    setup_pass = _compute_setup_pass(
        system_name,
        prepared,
        market_df,
        filter_pass,
        today_ts,
        log_callback,
        candidate_diagnostics,
    )
    try:
        setup_pass = int(setup_pass)
    except Exception:
        setup_pass = 0

    try:
        if stage_progress:
            stage_progress(50, filter_pass, setup_pass, None, None)
    except Exception:
        pass

    setup_zero_reason: str | None = None
    try:
        if setup_pass == 0:
            setup_zero_reason = _diagnose_setup_zero_reason(
                system_name,
                filter_pass,
                prepared,
                market_df,
            )
    except Exception:
        setup_zero_reason = None

    if setup_pass <= 0:
        if log_callback is not None:
            try:
                if setup_zero_reason:
                    log_callback(f"ğŸ›ˆ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸æˆç«‹: {setup_zero_reason}")
                log_callback(
                    "â­ï¸ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—0ä»¶ã®ãŸã‚ã‚¨ãƒ³ãƒˆãƒªãƒ¼å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã€"
                    "ã‚¨ã‚°ã‚¸ãƒƒãƒˆåˆ¤å®šã®ã¿å®Ÿæ–½ã—ã¾ã™"
                )
            except Exception:
                pass
        try:
            if stage_progress:
                stage_progress(75, filter_pass, setup_pass, 0, None)
        except Exception:
            pass
        try:
            if stage_progress:
                stage_progress(100, filter_pass, setup_pass, 0, 0)
        except Exception:
            pass
        empty_frame = _empty_today_signals_frame(setup_zero_reason or "setup_pass_zero")
        if candidate_diagnostics is not None:
            try:
                empty_frame.attrs["candidate_diagnostics"] = candidate_diagnostics
            except Exception:
                pass
        return empty_frame

    selection = _select_candidate_date(
        candidates_by_date,
        today_ts,
        filter_pass,
        setup_pass,
        log_callback,
    )
    try:
        if stage_progress:
            stage_progress(
                75,
                filter_pass,
                setup_pass,
                selection.total_candidates_today,
                None,
            )
    except Exception:
        pass

    signals_df, final_count = _build_today_signals_dataframe(
        strategy,
        prepared,
        candidates_by_date,
        selection,
        system_name,
        side,
        signal_type,
        log_callback,
    )

    # Emit diagnostic log if selection or extraction indicated zero candidates
    try:
        if getattr(selection, "zero_reason", None):
            if log_callback is not None:
                try:
                    log_callback(f"ğŸ›ˆ é¸å®šçµæœ: å€™è£œ0ä»¶ç†ç”±: {selection.zero_reason}")
                except Exception:
                    pass
        elif hasattr(candidates, "zero_reason") and getattr(
            candidates, "zero_reason", None
        ):
            if log_callback is not None:
                try:
                    log_callback(f"ğŸ›ˆ æŠ½å‡ºçµæœ: å€™è£œ0ä»¶ç†ç”±: {candidates.zero_reason}")
                except Exception:
                    pass
    except Exception:
        pass

    try:
        if stage_progress:
            stage_progress(
                100,
                filter_pass,
                setup_pass,
                selection.total_candidates_today,
                final_count,
            )
    except Exception:
        pass

    if candidate_diagnostics is not None and signals_df is not None:
        try:
            signals_df.attrs["candidate_diagnostics"] = candidate_diagnostics
        except Exception:
            pass

    return signals_df


def run_all_systems_today(
    symbols: list[str] | None,
    *,
    slots_long: int | None = None,
    slots_short: int | None = None,
    capital_long: float | None = None,
    capital_short: float | None = None,
    save_csv: bool = False,
    csv_name_mode: str | None = None,
    notify: bool = True,
    log_callback: Callable[[str], None] | None = None,
    progress_callback: Callable[[int, int, str], None] | None = None,
    per_system_progress: Callable[[str, str], None] | None = None,
    symbol_data: dict[str, pd.DataFrame] | None = None,
    parallel: bool = False,
) -> tuple[pd.DataFrame, dict[str, pd.DataFrame]]:
    """scripts.run_all_systems_today.compute_today_signals ã®ãƒ©ãƒƒãƒ‘ãƒ¼ã€‚"""
    # é€²æ— JSONL ã¸ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ã‚¤ãƒ™ãƒ³ãƒˆã‚’ï¼ˆå®‰å…¨ã«ï¼‰å‡ºã™
    try:
        from common.progress_events import emit_phase as _emit_phase
    except Exception:
        _emit_phase = None  # type: ignore
    try:
        from scripts.run_all_systems_today import compute_today_signals as _compute
    except ImportError:
        # Streamlitãªã©ã‹ã‚‰ã®å®Ÿè¡Œæ™‚ã«ãƒ‘ã‚¹ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã®å›é¿ç­–
        from pathlib import Path
        import sys

        project_root = Path(__file__).parent.parent
        if str(project_root) not in sys.path:
            sys.path.insert(0, str(project_root))
        from scripts.run_all_systems_today import compute_today_signals as _compute

    # log_callback ãŒæœªæŒ‡å®šãªã‚‰ CLI ã¸å‡ºã™ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ã†
    if log_callback is None:
        log_callback = _default_cli_log

    # ãƒ•ã‚§ãƒ¼ã‚º: start
    try:
        if _emit_phase is not None:
            _emit_phase("ui_wrapper", status="start")
    except Exception:
        pass

    result = _compute(
        symbols,
        slots_long=slots_long,
        slots_short=slots_short,
        capital_long=capital_long,
        capital_short=capital_short,
        save_csv=save_csv,
        csv_name_mode=csv_name_mode,
        notify=notify,
        log_callback=log_callback,
        progress_callback=progress_callback,
        per_system_progress=per_system_progress,
        symbol_data=symbol_data,
        parallel=parallel,
    )

    # ãƒ•ã‚§ãƒ¼ã‚º: complete
    try:
        if _emit_phase is not None:
            _emit_phase("ui_wrapper", status="complete")
    except Exception:
        pass
    return cast(tuple[pd.DataFrame, dict[str, pd.DataFrame]], result)


compute_today_signals = run_all_systems_today


__all__ = [
    "get_today_signals_for_strategy",
    "LONG_SYSTEMS",
    "SHORT_SYSTEMS",
    "run_all_systems_today",
    "compute_today_signals",
]
