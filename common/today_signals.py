from __future__ import annotations

from collections.abc import Callable
from dataclasses import dataclass
import inspect
import time as _t
from typing import Any, cast
import numpy as np

import pandas as pd

from config.settings import get_settings
from core.system5 import (
    DEFAULT_ATR_PCT_THRESHOLD,
    format_atr_pct_threshold_label,
)
from common.utils_spy import get_spy_with_indicators

# --- ã‚µã‚¤ãƒ‰å®šç¾©ï¼ˆå£²è²·åŒºåˆ†ï¼‰---
# System1/3/5 ã¯è²·ã„æˆ¦ç•¥ã€System2/4/6/7 ã¯å£²ã‚Šæˆ¦ç•¥ã¨ã—ã¦æ‰±ã†ã€‚
LONG_SYSTEMS = {"system1", "system3", "system5"}
SHORT_SYSTEMS = {"system2", "system4", "system6", "system7"}

# fast-path åˆ¤å®šã«ä½¿ç”¨ã™ã‚‹å¿…é ˆåˆ—
_FAST_PATH_REQUIRED_COLUMNS = {"filter", "setup"}


@dataclass(frozen=True)
class TodaySignal:
    symbol: str
    system: str
    side: str  # "long" | "short"
    signal_type: str  # "buy" | "sell"
    entry_date: pd.Timestamp
    entry_price: float
    stop_price: float
    score_key: str | None = None
    score: float | None = None
    reason: str | None = None


def _missing_fast_path_columns(data_dict: dict[str, pd.DataFrame]) -> set[str]:
    """é«˜é€ŸçµŒè·¯ã«å¿…è¦ãªåˆ—ãŒæƒã£ã¦ã„ã‚‹ã‹ã‚’åˆ¤å®šã—ã€ä¸è¶³é›†åˆã‚’è¿”ã™ã€‚"""

    if not isinstance(data_dict, dict) or not data_dict:
        return set(_FAST_PATH_REQUIRED_COLUMNS)

    missing: set[str] = set()
    has_valid_frame = False
    for df in data_dict.values():
        if df is None or getattr(df, "empty", True):
            continue
        has_valid_frame = True
        try:
            cols = {str(c).strip().lower() for c in df.columns}
        except Exception:
            missing.update(_FAST_PATH_REQUIRED_COLUMNS)
            continue
        for col in _FAST_PATH_REQUIRED_COLUMNS:
            if col not in cols:
                missing.add(col)

    if not has_valid_frame:
        return set(_FAST_PATH_REQUIRED_COLUMNS)
    return missing


def _is_fast_path_viable(
    data_dict: dict[str, pd.DataFrame]
) -> tuple[bool, set[str]]:
    """é«˜é€ŸçµŒè·¯ã§ candidate æŠ½å‡ºãŒå¯èƒ½ã‹åˆ¤å®šã—ã€(bool, ä¸è¶³åˆ—) ã‚’è¿”ã™ã€‚"""

    missing = _missing_fast_path_columns(data_dict)
    return len(missing) == 0, missing


def _infer_side(system_name: str) -> str:
    name = (system_name or "").lower()
    if name in SHORT_SYSTEMS:
        return "short"
    return "long"


def _score_from_candidate(
    system_name: str, candidate: dict
) -> tuple[str | None, float | None, bool]:
    """
    å€™è£œãƒ¬ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã‚¹ã‚³ã‚¢é …ç›®ã¨ä¸¦ã³é †ï¼ˆæ˜‡é †ã‹ï¼‰ã‚’æ¨å®šã—ã¦è¿”ã™ã€‚
    æˆ»ã‚Šå€¤: (score_key, score_value, asc)
    """
    name = (system_name or "").lower()
    # System7 ã¯ SPY å°‚ç”¨ãƒ˜ãƒƒã‚¸ã€‚ATR50 ã¯ã‚¹ãƒˆãƒƒãƒ—è¨ˆç®—ç”¨ã®ãŸã‚ã€
    # ã‚¹ã‚³ã‚¢/ç†ç”±ã«ã¯ä½¿ç”¨ã—ãªã„ï¼ˆã‚¹ã‚³ã‚¢æ¬„ã¯ç©ºã«ã™ã‚‹ï¼‰ã€‚
    if name == "system7":
        return None, None, False
    # ã‚·ã‚¹ãƒ†ãƒ åˆ¥ã®ä»£è¡¨ã‚¹ã‚³ã‚¢
    key_order: list[tuple[list[str], bool]] = [
        (["ROC200"], False),  # s1: å¤§ãã„ã»ã©è‰¯ã„
        (["ADX7"], False),  # s2,s5: å¤§ãã„ã»ã©è‰¯ã„
        (["Drop3D"], False),  # s3: å¤§ãã„ã»ã©è‰¯ã„ï¼ˆä¸‹è½ç‡ï¼‰
        (["RSI4"], True),  # s4: å°ã•ã„ã»ã©è‰¯ã„
        (["Return6D"], False),  # s6: å¤§ãã„ã»ã©è‰¯ã„
        (["ATR50"], False),  # s7: å‚è€ƒ
    ]
    # system å›ºæœ‰å„ªå…ˆé †ä½
    if name == "system4":
        key_order = [(["RSI4"], True), (["ATR40"], True)] + key_order
    elif name == "system2":
        key_order = [(["ADX7"], False), (["RSI3"], False)] + key_order
    elif name == "system5":
        key_order = [(["ADX7"], False), (["ATR10"], True)] + key_order
    elif name == "system6":
        key_order = [(["Return6D"], False), (["ATR10"], True)] + key_order

    for keys, asc in key_order:
        for k in keys:
            if k in candidate:
                v = candidate.get(k)
                if v is None:
                    return k, None, asc
                if isinstance(v, (int, float, str)):
                    try:
                        return k, float(v), asc
                    except Exception:
                        return k, None, asc
                else:
                    return k, None, asc
    # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    return None, None, False


def _label_for_score_key(key: str | None) -> str:
    """ã‚¹ã‚³ã‚¢ã‚­ãƒ¼ã®æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã‚’è¿”ã™ï¼ˆæ—¢çŸ¥ã®ã‚‚ã®ã®ã¿ç°¡æ½”è¡¨ç¤ºï¼‰ã€‚"""
    if key is None:
        return "ã‚¹ã‚³ã‚¢"
    k = str(key).upper()
    mapping = {
        "ROC200": "ROC200",
        "ADX7": "ADX",
        "RSI4": "RSI4",
        "RSI3": "RSI3",
        "DROP3D": "3æ—¥ä¸‹è½ç‡",
        "RETURN6D": "éå»6æ—¥é¨°è½ç‡",
        "ATR10": "ATR10",
        "ATR20": "ATR20",
        "ATR40": "ATR40",
        "ATR50": "ATR50",
    }
    return mapping.get(k, k)


def _asc_by_score_key(score_key: str | None) -> bool:
    """ã‚¹ã‚³ã‚¢ã‚­ãƒ¼ã”ã¨ã®æ˜‡é †/é™é †ã‚’åˆ¤å®šã€‚"""
    return bool(score_key and score_key.upper() in {"RSI4"})


def _pick_atr_col(df: pd.DataFrame) -> str | None:
    for col in ("ATR20", "ATR10", "ATR40", "ATR50", "ATR14"):
        if col in df.columns:
            return col
    return None


def _compute_entry_stop(
    strategy, df: pd.DataFrame, candidate: dict, side: str
) -> tuple[float, float] | None:
    # strategy ç‹¬è‡ªã® compute_entry ãŒã‚ã‚Œã°å„ªå…ˆ
    try:
        _fn = strategy.compute_entry  # type: ignore[attr-defined]
    except Exception:
        _fn = None
    if callable(_fn):
        try:
            res = _fn(df, candidate, 0.0)
            if res and isinstance(res, tuple) and len(res) == 2:
                entry, stop = float(res[0]), float(res[1])
                if entry > 0 and (
                    (side == "short" and stop > entry)
                    or (side == "long" and entry > stop)
                ):
                    return round(entry, 4), round(stop, 4)
        except Exception:
            pass

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å½“æ—¥å§‹å€¤ Â± 3*ATR
    try:
        entry_ts = pd.Timestamp(candidate["entry_date"])
    except Exception:
        return None
    try:
        idxer = df.index.get_indexer([entry_ts])
        entry_idx = int(idxer[0]) if len(idxer) else -1
    except Exception:
        return None
    if entry_idx <= 0 or entry_idx >= len(df):
        return None
    try:
        entry = float(df.iloc[entry_idx]["Open"])
    except Exception:
        return None
    atr_col = _pick_atr_col(df)
    if not atr_col:
        return None
    try:
        atr = float(df.iloc[entry_idx - 1][atr_col])
    except Exception:
        return None
    mult = 3.0
    stop = entry - mult * atr if side == "long" else entry + mult * atr
    return round(entry, 4), round(stop, 4)


def get_today_signals_for_strategy(
    strategy,
    raw_data_dict: dict[str, pd.DataFrame],
    *,
    market_df: pd.DataFrame | None = None,
    today: pd.Timestamp | None = None,
    progress_callback: Callable[..., None] | None = None,
    log_callback: Callable[[str], None] | None = None,
    stage_progress: (
        Callable[[int, int | None, int | None, int | None, int | None], None] | None
    ) = None,
    use_process_pool: bool = False,
    max_workers: int | None = None,
    lookback_days: int | None = None,
) -> pd.DataFrame:
    """
    å„ Strategy ã® prepare_data / generate_candidates ã‚’æµç”¨ã—ã€
    æœ€æ–°å–¶æ¥­æ—¥ã®å€™è£œã®ã¿ã‚’ DataFrame ã§è¿”ã™ã€‚

    æˆ»ã‚Šå€¤ã‚«ãƒ©ãƒ :
        - symbol, system, side, signal_type,
          entry_date, entry_price, stop_price,
          score_key, score
    """
    from common.utils_spy import get_latest_nyse_trading_day

    try:
        system_name = str(strategy.SYSTEM_NAME).lower()  # type: ignore[attr-defined]
    except Exception:
        system_name = ""
    side = _infer_side(system_name)
    signal_type = "sell" if side == "short" else "buy"

    # å–å¼•æ—¥
    if today is None:
        today = get_latest_nyse_trading_day()
    try:
        today_ts = pd.Timestamp(today)
    except Exception:
        today_ts = get_latest_nyse_trading_day()
    if getattr(today_ts, "tzinfo", None) is not None:
        try:
            today_ts = today_ts.tz_convert(None)
        except (TypeError, ValueError, AttributeError):
            try:
                today_ts = today_ts.tz_localize(None)
            except Exception:
                today_ts = pd.Timestamp(today_ts.to_pydatetime().replace(tzinfo=None))
    today = today_ts.normalize()

    # æº–å‚™
    total_symbols = len(raw_data_dict)
    if log_callback:
        try:
            log_callback(f"ğŸ§ª ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒã‚§ãƒƒã‚¯é–‹å§‹ï¼š{total_symbols} éŠ˜æŸ„")
        except Exception:
            pass
    # 0% -> 25%
    try:
        if stage_progress:
            # 0% ã‚¹ãƒ†ãƒ¼ã‚¸ã§ã¯å¯¾è±¡éŠ˜æŸ„æ•°ã‚’ç¬¬1å¼•æ•°ã«æ¸¡ã™ï¼ˆUI å´ã§ "å¯¾è±¡â†’n" è¡¨ç¤ºã«ä½¿ç”¨ï¼‰
            stage_progress(0, total_symbols, None, None, None)
    except Exception:
        pass
    t0 = _t.time()
    # ãƒ«ãƒƒã‚¯ãƒãƒƒã‚¯æœ€é©åŒ–ï¼šå¿…è¦æ—¥æ•°ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°å„DFã‚’æœ«å°¾Nè¡Œã«ã‚¹ãƒ©ã‚¤ã‚¹
    sliced_dict = raw_data_dict
    try:
        if (
            lookback_days is not None
            and lookback_days > 0
            and isinstance(raw_data_dict, dict)
        ):
            sliced: dict[str, pd.DataFrame] = {}
            for _sym, _df in raw_data_dict.items():
                try:
                    if _df is None or getattr(_df, "empty", True):
                        continue
                    x = _df.copy()
                    if "Date" in x.columns:
                        idx = pd.to_datetime(x["Date"], errors="coerce").dt.normalize()
                        x.index = pd.Index(idx)
                    else:
                        x.index = pd.to_datetime(x.index, errors="coerce").normalize()
                    # ä¸æ­£ãªæ—¥æ™‚ã¯é™¤å¤–
                    x = x[~x.index.isna()]
                    # æœ«å°¾Nå–¶æ¥­æ—¥ç›¸å½“ã‚’æŠ½å‡º
                    x = x.tail(int(lookback_days))
                    sliced[_sym] = x
                except Exception:
                    sliced[_sym] = _df
            sliced_dict = sliced
    except Exception:
        sliced_dict = raw_data_dict

    prepared_dict: dict[str, pd.DataFrame] | None = None
    fast_path_used = False
    fast_missing: set[str] = set()
    try:
        fast_ok, fast_missing = _is_fast_path_viable(sliced_dict)
    except Exception:
        fast_ok = False
        fast_missing = set()
    if fast_ok:
        try:
            prepared_dict = {
                sym: df.copy()
                for sym, df in sliced_dict.items()
                if df is not None and not getattr(df, "empty", True)
            }
            fast_path_used = True
            if log_callback:
                log_callback("âš¡ é«˜é€Ÿãƒ‘ã‚¹: æ—¢å­˜ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã‚’å†åˆ©ç”¨ã—ã¾ã™")
        except Exception:
            prepared_dict = None
            fast_path_used = False

    # ã‚¹ã‚­ãƒƒãƒ—ç†ç”±ã®åé›†ï¼ˆsystemã”ã¨ã«é›†è¨ˆï¼‰
    _skip_counts: dict[str, int] = {}
    _skip_samples: dict[str, list[str]] = {}
    _skip_details: list[dict[str, str]] = []

    def _on_skip(*args, **kwargs):
        try:
            if len(args) >= 2:
                _sym = str(args[0])
                _reason = str(args[1])
            elif len(args) == 1:
                # "SYM: reason" å½¢å¼ã‹ã‚‰ç†ç”±ã ã‘æŠ½å‡º
                txt = str(args[0])
                _sym, _reason = (
                    (txt.split(":", 1) + [""])[:2] if ":" in txt else ("", txt)
                )
                _sym = _sym.strip()
                _reason = _reason.strip()
            else:
                _reason = str(kwargs.get("reason", "unknown"))
                _sym = str(kwargs.get("symbol", ""))
        except Exception:
            _reason = "unknown"
            _sym = ""
        _skip_counts[_reason] = _skip_counts.get(_reason, 0) + 1
        if _sym:
            if _reason not in _skip_samples:
                _skip_samples[_reason] = []
            if len(_skip_samples[_reason]) < 5 and _sym not in _skip_samples[_reason]:
                _skip_samples[_reason].append(_sym)
        try:
            _skip_details.append(
                {"symbol": str(_sym or ""), "reason": str(_reason or "")}
            )
        except Exception:
            pass

    if not fast_path_used or prepared_dict is None:
        if fast_missing and log_callback:
            try:
                missing_list = ", ".join(sorted(fast_missing))
                log_callback(
                    "âš ï¸ é«˜é€Ÿãƒ‘ã‚¹ã‚’åˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆå¿…é ˆåˆ—ä¸è¶³: "
                    + (missing_list or "ä¸æ˜")
                    + "ï¼‰ã€‚å†è¨ˆç®—ã—ã¾ã™ã€‚"
                )
            except Exception:
                pass
        try:
            prepared_dict = strategy.prepare_data(
                sliced_dict,
                progress_callback=progress_callback,
                log_callback=log_callback,
                skip_callback=_on_skip,
                use_process_pool=use_process_pool,
                max_workers=max_workers,
                lookback_days=lookback_days,
            )
        except Exception as e:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: éãƒ—ãƒ¼ãƒ« + å†è¨ˆç®—ï¼ˆreuse_indicators=Falseï¼‰ã§å†è©¦è¡Œ
            try:
                if log_callback:
                    log_callback(
                        f"âš ï¸ {system_name}: å‰å‡¦ç†å¤±æ•—ã®ãŸã‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆéãƒ—ãƒ¼ãƒ«ãƒ»å†è¨ˆç®—ï¼‰: {e}"
                    )
            except Exception:
                pass
            try:
                prepared_dict = strategy.prepare_data(
                    sliced_dict,
                    progress_callback=progress_callback,
                    log_callback=log_callback,
                    skip_callback=_on_skip,
                    use_process_pool=False,
                    max_workers=None,
                    lookback_days=lookback_days,
                    reuse_indicators=False,
                )
            except Exception as e2:
                # ã“ã“ã§å¤±æ•—ã—ãŸã‚‰ç©ºã®çµæœã‚’è¿”ã™ï¼ˆå¾Œæ®µã¯0ä»¶ã§æµã‚Œã‚‹ï¼‰
                try:
                    if log_callback:
                        log_callback(
                            f"âš ï¸ {system_name}: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚å¤±æ•—ï¼ˆä¸­æ–­ï¼‰: {e2}"
                        )
                except Exception:
                    pass
                return pd.DataFrame(
                    columns=[
                        "symbol",
                        "system",
                        "side",
                        "signal_type",
                        "entry_date",
                        "entry_price",
                        "stop_price",
                        "score_key",
                        "score",
                    ]
                )
    if prepared_dict is None:
        prepared_dict = {}

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ­£è¦åŒ–ãƒ»æ˜‡é †ãƒ»é‡è¤‡é™¤å»ï¼ˆpandas ã®å†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é–¢é€£ã‚¨ãƒ©ãƒ¼å¯¾ç­–ï¼‰
    try:
        if isinstance(prepared_dict, dict):
            _fixed: dict[str, pd.DataFrame] = {}
            for _sym, _df in prepared_dict.items():
                try:
                    x = _df.copy()
                    if "Date" in x.columns:
                        idx = pd.to_datetime(x["Date"], errors="coerce").dt.normalize()
                    else:
                        idx = pd.to_datetime(x.index, errors="coerce").normalize()
                    x.index = pd.Index(idx)
                    # æ¬ æãƒ»éå˜èª¿ãƒ»é‡è¤‡ã‚’æ•´ç†
                    x = x[~x.index.isna()]
                    x = x.sort_index()
                    if getattr(x.index, "has_duplicates", False):
                        x = x[~x.index.duplicated(keep="last")]
                    _fixed[_sym] = x
                except Exception:
                    _fixed[_sym] = _df
            prepared_dict = _fixed
    except Exception:
        pass

    prepared = prepared_dict
    try:
        if log_callback:
            em, es = divmod(int(max(0, _t.time() - t0)), 60)
            log_callback(f"â±ï¸ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼/å‰å‡¦ç† å®Œäº†ï¼ˆçµŒé {em}åˆ†{es}ç§’ï¼‰")
    except Exception:
        pass
    # ã‚¹ã‚­ãƒƒãƒ—å†…è¨³ã®è¦ç´„ï¼ˆå­˜åœ¨æ™‚ã®ã¿ï¼‰
    try:
        if log_callback and _skip_counts:
            # ä¸Šä½2ä»¶ã®ã¿ã‚’ç°¡æ½”ã«è¡¨ç¤º
            sorted_items = sorted(
                _skip_counts.items(), key=lambda x: x[1], reverse=True
            )
            top = sorted_items[:2]
            details = ", ".join([f"{k}: {v}" for k, v in top])
            log_callback(f"ğŸ§ª ã‚¹ã‚­ãƒƒãƒ—å†…è¨³: {details}")
            # ã‚µãƒ³ãƒ—ãƒ«éŠ˜æŸ„å‡ºåŠ›
            for k, _ in top:
                samples = _skip_samples.get(k) or []
                if samples:
                    log_callback(f"  â†³ ä¾‹({k}): {', '.join(samples)}")
            # è¿½åŠ : å…¨ã‚¹ã‚­ãƒƒãƒ—ã®CSVã‚’ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰ã€‚UI/CLIä¸¡æ–¹ã§ãƒ‘ã‚¹ã‚’å‡ºåŠ›ã€‚
            try:
                import pandas as _pd
                from config.settings import get_settings as _gs

                _rows = []
                for _reason, _cnt in sorted_items:
                    _rows.append(
                        {
                            "reason": _reason,
                            "count": int(_cnt),
                            "examples": ", ".join(_skip_samples.get(_reason, [])),
                        }
                    )
                if _rows:
                    _df = _pd.DataFrame(_rows)
                    try:
                        _settings = _gs(create_dirs=True)
                        _dir = getattr(_settings.outputs, "results_csv_dir", None)
                    except Exception:
                        _dir = None
                    import os as _os

                    _out_dir = str(_dir or "results_csv")
                    try:
                        _os.makedirs(_out_dir, exist_ok=True)
                    except Exception:
                        pass
                    _fp = _os.path.join(_out_dir, f"skip_summary_{system_name}.csv")
                    try:
                        _df.to_csv(_fp, index=False, encoding="utf-8")
                        log_callback(f"ğŸ“ ã‚¹ã‚­ãƒƒãƒ—å†…è¨³CSVã‚’ä¿å­˜: {_fp}")
                    except Exception:
                        pass
                    # per-symbol ã®è©³ç´°ï¼ˆsymbol, reasonï¼‰ã‚‚ä¿å­˜
                    try:
                        if _skip_details:
                            _df2 = _pd.DataFrame(_skip_details)
                            _fp2 = _os.path.join(
                                _out_dir, f"skip_details_{system_name}.csv"
                            )
                            _df2.to_csv(_fp2, index=False, encoding="utf-8")
                            log_callback(f"ğŸ“ ã‚¹ã‚­ãƒƒãƒ—è©³ç´°CSVã‚’ä¿å­˜: {_fp2}")
                    except Exception:
                        pass
            except Exception:
                pass
    except Exception:
        pass
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é€šéä»¶æ•°ï¼ˆNYSEã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã®å‰å–¶æ¥­æ—¥ã‚’å„ªå…ˆã€‚ç„¡ã„å ´åˆã¯æœ€çµ‚è¡Œï¼‰ã€‚
    try:
        # å‰å–¶æ¥­æ—¥ï¼ˆå½“æ—¥ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã®ã‚·ã‚°ãƒŠãƒ«ã¯å‰å–¶æ¥­æ—¥ã®çµ‚å€¤ã§åˆ¤å®šï¼‰
        prev_trading_day = get_latest_nyse_trading_day(
            pd.Timestamp(today) - pd.Timedelta(days=1)
        )

        def _last_filter_on_date(x: pd.DataFrame) -> bool:
            try:
                if getattr(x, "empty", True) or "filter" not in x.columns:
                    return False
                # Dateåˆ—ãŒã‚ã‚Œã°å„ªå…ˆã€ç„¡ã‘ã‚Œã°indexã§æ¯”è¼ƒ
                if "Date" in x.columns:
                    dt_vals = (
                        pd.to_datetime(x["Date"], errors="coerce")
                        .dt.normalize()
                        .to_numpy()
                    )
                    mask = dt_vals == prev_trading_day
                    sel = pd.Series(np.asarray(x.loc[mask, "filter"]))
                else:
                    idx_vals = (
                        pd.to_datetime(x.index, errors="coerce").normalize().to_numpy()
                    )
                    mask = idx_vals == prev_trading_day
                    sel = pd.Series(np.asarray(x.loc[mask, "filter"]))
                if sel.size > 0:
                    v = sel.iloc[-1]
                    return bool(False if pd.isna(v) else bool(v))
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€çµ‚è¡Œ
                v = pd.Series(x["filter"]).tail(1).iloc[0]
                return bool(False if pd.isna(v) else bool(v))
            except Exception:
                return False

        filter_pass = sum(int(_last_filter_on_date(df)) for df in prepared.values())
        # System7 ã¯ SPY å›ºå®šã®ãŸã‚ã€SPYãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ãƒ•ã‚£ãƒ«ã‚¿é€šé=1ã¨ã—ã¦æ‰±ã†
        try:
            if str(system_name).lower() == "system7":
                filter_pass = 1 if ("SPY" in (prepared or {})) else 0
        except Exception:
            pass
    except Exception:
        filter_pass = 0
    if log_callback:
        try:
            log_callback(f"ğŸ§ª ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒã‚§ãƒƒã‚¯å®Œäº†ï¼š{filter_pass} éŠ˜æŸ„")
        except Exception:
            pass
    try:
        if stage_progress:
            stage_progress(25, filter_pass, None, None, None)
    except Exception:
        pass

    # å€™è£œç”Ÿæˆï¼ˆmarket_df ã‚’å¿…è¦ã¨ã™ã‚‹å®Ÿè£…ã«é…æ…®ï¼‰
    gen_fn = strategy.generate_candidates  # type: ignore[attr-defined]
    params = inspect.signature(gen_fn).parameters
    if log_callback:
        try:
            log_callback(f"ğŸ§© ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒã‚§ãƒƒã‚¯é–‹å§‹ï¼š{filter_pass} éŠ˜æŸ„")
        except Exception:
            pass
    t1 = _t.time()
    if "market_df" in params and market_df is not None:
        candidates_by_date, _ = gen_fn(
            prepared,
            market_df=market_df,
            progress_callback=progress_callback,
            log_callback=log_callback,
        )
    else:
        candidates_by_date, _ = gen_fn(
            prepared,
            progress_callback=progress_callback,
            log_callback=log_callback,
        )
    try:
        if log_callback:
            em, es = divmod(int(max(0, _t.time() - t1)), 60)
            log_callback(f"â±ï¸ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—/å€™è£œæŠ½å‡º å®Œäº†ï¼ˆçµŒé {em}åˆ†{es}ç§’ï¼‰")
    except Exception:
        pass

    # ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é€šéä»¶æ•°ï¼ˆNYSEã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã®å‰å–¶æ¥­æ—¥ã‚’å„ªå…ˆã€‚ç„¡ã‘ã‚Œã°æœ€çµ‚è¡Œï¼‰
    try:
        prev_trading_day = get_latest_nyse_trading_day(
            pd.Timestamp(today) - pd.Timedelta(days=1)
        )

        def _last_row(x: pd.DataFrame) -> pd.Series | None:
            try:
                if "Date" in x.columns:
                    dt_vals = (
                        pd.to_datetime(x["Date"], errors="coerce")
                        .dt.normalize()
                        .to_numpy()
                    )
                    mask = dt_vals == prev_trading_day
                    rows = x.loc[mask]
                else:
                    idx_vals = (
                        pd.to_datetime(x.index, errors="coerce")
                        .normalize()
                        .to_numpy()
                    )
                    mask = idx_vals == prev_trading_day
                    rows = x.loc[mask]
                if len(rows) == 0:
                    rows = x.tail(1)
                if len(rows) == 0:
                    return None
                return rows.iloc[-1]
            except Exception:
                return None

        if isinstance(prepared, dict):
            items = list(prepared.items())
        elif isinstance(prepared, pd.DataFrame):
            items = [("", prepared)]
        else:
            items = []
        latest_rows: dict[str, pd.Series] = {}
        for sym, df in items:
            if df is None or getattr(df, "empty", True):
                continue
            row = _last_row(df)
            if row is None:
                continue
            latest_rows[str(sym)] = row

        def _count_if(rows: list[pd.Series], fn: Callable[[pd.Series], bool]) -> int:
            cnt = 0
            for row in rows:
                try:
                    if fn(row):
                        cnt += 1
                except Exception:
                    continue
            return cnt

        rows_list = list(latest_rows.values())
        name = str(system_name).lower()
        setup_pass = 0

        if name == "system1":
            filtered_rows = [r for r in rows_list if bool(r.get("filter"))]

            def _sma_ok(row: pd.Series) -> bool:
                try:
                    return float(row.get("SMA25", 0)) > float(row.get("SMA50", 0))
                except Exception:
                    return False

            sma_pass = _count_if(filtered_rows, _sma_ok)
            spy_source = market_df if market_df is not None else None
            try:
                spy_df = get_spy_with_indicators(spy_source)
            except Exception:
                spy_df = None

            spy_gate: int | None
            try:
                if spy_df is None or getattr(spy_df, "empty", True):
                    spy_gate = None
                else:
                    last_row = spy_df.iloc[-1]
                    close_val = float(last_row.get("Close", float("nan")))
                    sma_val = float(last_row.get("SMA100", float("nan")))
                    if np.isnan(close_val) or np.isnan(sma_val):
                        spy_gate = None
                    else:
                        spy_gate = 1 if close_val > sma_val else 0
            except Exception:
                spy_gate = None

            setup_pass = sma_pass if spy_gate != 0 else 0

            if log_callback:
                spy_label = "-" if spy_gate is None else str(int(spy_gate))
                try:
                    log_callback(
                        "ğŸ§© system1ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: "
                        + f"ãƒ•ã‚£ãƒ«ã‚¿é€šé={filter_pass}, SPY>SMA100: {spy_label}, "
                        + f"SMA25>SMA50: {sma_pass}"
                    )
                except Exception:
                    pass
        elif name == "system2":
            def _rsi_ok(row: pd.Series) -> bool:
                try:
                    return float(row.get("RSI3", 0)) > 90
                except Exception:
                    return False

            def _two_up_ok(row: pd.Series) -> bool:
                return bool(row.get("TwoDayUp"))

            filtered_rows = [r for r in rows_list if bool(r.get("filter"))]
            rsi_pass = _count_if(filtered_rows, _rsi_ok)
            two_up_pass = _count_if(
                filtered_rows, lambda r: _rsi_ok(r) and _two_up_ok(r)
            )
            setup_pass = two_up_pass
            if log_callback:
                try:
                    log_callback(
                        "ğŸ§© system2ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: "
                        + f"ãƒ•ã‚£ãƒ«ã‚¿é€šé={filter_pass}, RSI3>90: {rsi_pass}, "
                        + f"TwoDayUp: {two_up_pass}"
                    )
                except Exception:
                    pass
        elif name == "system3":
            filtered_rows = [r for r in rows_list if bool(r.get("filter"))]

            def _close_ok(row: pd.Series) -> bool:
                try:
                    return float(row.get("Close", 0)) > float(row.get("SMA150", 0))
                except Exception:
                    return False

            def _drop_ok(row: pd.Series) -> bool:
                try:
                    return float(row.get("Drop3D", 0)) >= 0.125
                except Exception:
                    return False

            close_pass = _count_if(filtered_rows, _close_ok)
            drop_pass = _count_if(
                filtered_rows, lambda r: _close_ok(r) and _drop_ok(r)
            )
            setup_pass = drop_pass
            if log_callback:
                try:
                    log_callback(
                        "ğŸ§© system3ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: "
                        + f"ãƒ•ã‚£ãƒ«ã‚¿é€šé={filter_pass}, Close>SMA150: {close_pass}, "
                        + f"3æ—¥ä¸‹è½ç‡>=12.5%: {drop_pass}"
                    )
                except Exception:
                    pass
        elif name == "system4":
            def _above_sma(row: pd.Series) -> bool:
                try:
                    return bool(row.get("filter")) and (
                        float(row.get("Close", 0)) > float(row.get("SMA200", 0))
                    )
                except Exception:
                    return False

            above_sma = _count_if(rows_list, _above_sma)
            setup_pass = above_sma
            if log_callback:
                try:
                    log_callback(
                        "ğŸ§© system4ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: "
                        + f"ãƒ•ã‚£ãƒ«ã‚¿é€šé={filter_pass}, Close>SMA200: {above_sma}"
                    )
                except Exception:
                    pass
        elif name == "system5":
            threshold_label = format_atr_pct_threshold_label()
            s5_total = len(rows_list)
            s5_av = 0
            s5_dv = 0
            s5_atr = 0
            for row in rows_list:
                try:
                    av_val = row.get("AvgVolume50")
                    if av_val is None or pd.isna(av_val) or float(av_val) <= 500_000:
                        continue
                    s5_av += 1
                    dv_val = row.get("DollarVolume50")
                    if dv_val is None or pd.isna(dv_val) or float(dv_val) <= 2_500_000:
                        continue
                    s5_dv += 1
                    atr_pct_val = row.get("ATR_Pct")
                    if (
                        atr_pct_val is not None
                        and not pd.isna(atr_pct_val)
                        and float(atr_pct_val) > DEFAULT_ATR_PCT_THRESHOLD
                    ):
                        s5_atr += 1
                except Exception:
                    continue
            if log_callback:
                try:
                    log_callback(
                        "ğŸ§ª system5å†…è¨³: "
                        + f"å¯¾è±¡={s5_total}, AvgVol50>500k: {s5_av}, "
                        + f"DV50>2.5M: {s5_dv}, {threshold_label}: {s5_atr}"
                    )
                except Exception:
                    pass

            def _price_ok(row: pd.Series) -> bool:
                try:
                    return bool(row.get("filter")) and (
                        float(row.get("Close", 0))
                        > float(row.get("SMA100", 0)) + float(row.get("ATR10", 0))
                    )
                except Exception:
                    return False

            def _adx_ok(row: pd.Series) -> bool:
                try:
                    return float(row.get("ADX7", 0)) > 55
                except Exception:
                    return False

            def _rsi_ok(row: pd.Series) -> bool:
                try:
                    return float(row.get("RSI3", 100)) < 50
                except Exception:
                    return False

            price_pass = _count_if(rows_list, _price_ok)
            adx_pass = _count_if(rows_list, lambda r: _price_ok(r) and _adx_ok(r))
            rsi_pass = _count_if(
                rows_list, lambda r: _price_ok(r) and _adx_ok(r) and _rsi_ok(r)
            )
            setup_pass = rsi_pass
            if log_callback:
                try:
                    log_callback(
                        "ğŸ§© system5ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: "
                        + f"ãƒ•ã‚£ãƒ«ã‚¿é€šé={filter_pass}, Close>SMA100+ATR10: {price_pass}, "
                        + f"ADX7>55: {adx_pass}, RSI3<50: {rsi_pass}"
                    )
                except Exception:
                    pass
        elif name == "system6":
            filtered_rows = [r for r in rows_list if bool(r.get("filter"))]

            def _ret_ok(row: pd.Series) -> bool:
                try:
                    return float(row.get("Return6D", 0)) > 0.20
                except Exception:
                    return False

            def _up_two(row: pd.Series) -> bool:
                return bool(row.get("UpTwoDays"))

            ret_pass = _count_if(filtered_rows, _ret_ok)
            up_pass = _count_if(filtered_rows, lambda r: _ret_ok(r) and _up_two(r))
            setup_pass = up_pass
            if log_callback:
                try:
                    msg = (
                        "ğŸ§© system6ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: "
                        f"ãƒ•ã‚£ãƒ«ã‚¿é€šé={filter_pass}, "
                        f"Return6D>20%: {ret_pass}, "
                        f"UpTwoDays: {up_pass}"
                    )
                    log_callback(msg)
                except Exception:
                    pass
        elif name == "system7":
            spy_present = 1 if "SPY" in latest_rows else 0
            setup_pass = spy_present
            if log_callback:
                try:
                    msg = f"ğŸ§© system7ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å†…è¨³: SPYå­˜åœ¨={spy_present}"
                    if spy_present:
                        try:
                            val = latest_rows.get("SPY", pd.Series())
                            if isinstance(val, pd.Series):
                                setup_flag = bool(val.get("setup", 0))
                            else:
                                setup_flag = False
                            msg += f", setup={int(setup_flag)}"
                        except Exception:
                            pass
                    log_callback(msg)
                except Exception:
                    pass
        else:
            setup_pass = _count_if(
                rows_list,
                lambda r: bool(r.get("setup")) if "setup" in r else False,
            )

        try:
            setup_pass = int(setup_pass)
        except Exception:
            setup_pass = 0
    except Exception:
        setup_pass = 0
    try:
        if stage_progress:
            stage_progress(50, filter_pass, setup_pass, None, None)
    except Exception:
        pass
    # ãƒˆãƒ¬ãƒ¼ãƒ‰å€™è£œä»¶æ•°ï¼ˆå½“æ—¥ã®ã¿ï¼‰â†’ UIè¡¨ç¤ºã¯æœ€å¤§ãƒã‚¸ã‚·ãƒ§ãƒ³æ•°ã«åˆã‚ã›ã¦ä¸Šé™10ã«ä¸¸ã‚ã‚‹
    # å€™è£œã‚­ãƒ¼å‹ã®ã‚†ã‚‰ãï¼ˆstr/date/Timestampï¼‰ã‚’å¸åã™ã‚‹ãŸã‚ã€
    # æ­£è¦åŒ–Timestampâ†’å…ƒã‚­ãƒ¼ã®ãƒãƒƒãƒ—ã‚’ä½œæˆã—ã¦ã‹ã‚‰é¸æŠãƒ»å‚ç…§ã™ã‚‹
    try:
        key_map: dict[pd.Timestamp, object] = {}
        cand_keys = list((candidates_by_date or {}).keys())
        for _k in cand_keys:
            try:
                _raw_ts = pd.to_datetime(_k, errors="coerce")
                if pd.isna(_raw_ts):
                    continue
                _ts = pd.Timestamp(_raw_ts)
                if getattr(_ts, "tzinfo", None) is not None:
                    try:
                        _ts = _ts.tz_localize(None)
                    except Exception:
                        try:
                            _ts = pd.Timestamp(
                                _ts.to_pydatetime().replace(tzinfo=None)
                            )
                        except Exception:
                            continue
                _ts = _ts.normalize()
                if _ts not in key_map:
                    key_map[_ts] = _k
            except Exception:
                continue
        candidate_dates = sorted(list(key_map.keys()), reverse=True)
    except Exception:
        key_map = {}
        candidate_dates = []

    target_date: pd.Timestamp | None = None
    fallback_reason: str | None = None

    def _collect_recent_days(
        anchor: pd.Timestamp | None, count: int
    ) -> list[pd.Timestamp]:
        if anchor is None or count <= 0:
            return []
        out: list[pd.Timestamp] = []
        seen: set[pd.Timestamp] = set()
        cur = pd.Timestamp(anchor).normalize()
        while len(out) < count:
            if cur in seen:
                break
            out.append(cur)
            seen.add(cur)
            prev = get_latest_nyse_trading_day(cur - pd.Timedelta(days=1))
            prev = pd.Timestamp(prev).normalize()
            if prev >= cur:
                break
            cur = prev
        return out

    try:
        primary_days = _collect_recent_days(today, 3)
        for dt in primary_days:
            if dt in candidate_dates:
                target_date = dt
                break

        if target_date is None:
            try:
                settings = get_settings(create_dirs=False)
                cfg = getattr(settings, "cache", None)
                rolling_cfg = getattr(cfg, "rolling", None)
                max_stale = getattr(
                    rolling_cfg,
                    "max_staleness_days",
                    getattr(rolling_cfg, "max_stale_days", 2),
                )
                stale_limit = int(max_stale)
            except Exception:
                stale_limit = 2
            fallback_window = max(len(primary_days), stale_limit + 3)
            extended_days = _collect_recent_days(today, fallback_window)
            for dt in extended_days:
                if dt in candidate_dates:
                    target_date = dt
                    if dt not in primary_days:
                        fallback_reason = "recent"
                    break

        if target_date is None and candidate_dates:
            today_norm = (
                pd.Timestamp(today).normalize() if today is not None else None
            )
            past_candidates = [
                d
                for d in candidate_dates
                if today_norm is None or d <= today_norm
            ]
            if past_candidates:
                target_date = max(past_candidates)
                if fallback_reason is None:
                    fallback_reason = "latest_past"
            else:
                target_date = max(candidate_dates)
                if fallback_reason is None:
                    fallback_reason = "latest_any"

        if log_callback:
            try:
                _cands_str = ", ".join([str(d.date()) for d in candidate_dates[:5]])
                _search_str = ", ".join([str(d.date()) for d in primary_days])
                _chosen = str(target_date.date()) if target_date is not None else "None"
                fallback_msg = ""
                if fallback_reason:
                    fallback_labels = {
                        "recent": "ç›´è¿‘å–¶æ¥­æ—¥ã«å€™è£œãŒç„¡ã„ãŸã‚éå»æ—¥ã‚’æ¡ç”¨",
                        "latest_past": "æ¢ç´¢ç¯„å›²å¤–ã®æœ€æ–°éå»æ—¥ã‚’æ¡ç”¨",
                        "latest_any": "æœªæ¥æ—¥ã—ã‹å­˜åœ¨ã—ãªã„ãŸã‚å€™è£œæœ€çµ‚æ—¥ã‚’æ¡ç”¨",
                    }
                    label = fallback_labels.get(fallback_reason, fallback_reason)
                    fallback_msg = f" | ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {label}"
                log_callback(
                    "ğŸ—“ï¸ å€™è£œæ—¥ï¼ˆæœ€æ–°ä¸Šä½ï¼‰: "
                    f"{_cands_str} | æ¢ç´¢é †: {_search_str} | æ¡ç”¨: {_chosen}{fallback_msg}"
                )
            except Exception:
                pass
    except Exception:
        target_date = None
        fallback_reason = None
    try:
        if target_date is not None and target_date in key_map:
            orig_key = key_map[target_date]
            total_candidates_today = len(
                (candidates_by_date or {}).get(orig_key, []) or []
            )
        else:
            total_candidates_today = 0
    except Exception:
        total_candidates_today = 0
    # UIã®TRDlistã¯å„systemã®æœ€å¤§ãƒã‚¸ã‚·ãƒ§ãƒ³æ•°ã‚’è¶…ãˆãªã„ã‚ˆã†ã«è¡¨ç¤º
    try:
        _max_pos_ui = int(get_settings(create_dirs=False).risk.max_positions)
    except Exception:
        _max_pos_ui = 10
    if total_candidates_today and _max_pos_ui > 0:
        total_candidates_today = min(int(total_candidates_today), int(_max_pos_ui))
    try:
        if stage_progress:
            stage_progress(75, filter_pass, setup_pass, total_candidates_today, None)
    except Exception:
        pass
    if log_callback:
        try:
            log_callback(f"ğŸ§© ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒã‚§ãƒƒã‚¯å®Œäº†ï¼š{setup_pass} éŠ˜æŸ„")
            # èª¤è§£å›é¿: ã“ã“ã§ã®ä»¶æ•°ã¯ã€å€™è£œç”Ÿæˆã®æ¯é›†å›£ï¼ˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é€šéï¼‰ã€
            log_callback(f"ğŸ§® å€™è£œç”Ÿæˆå…ƒï¼ˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é€šéï¼‰ï¼š{setup_pass} éŠ˜æŸ„")
            # TRDlist ç›¸å½“ï¼ˆç›´è¿‘å–¶æ¥­æ—¥æ™‚ç‚¹ã®å€™è£œæ•°ã€‚æœ€å¤§{_max_pos_ui}ã«ä¸¸ã‚ï¼‰
            log_callback(
                f"ğŸ§® TRDlistç›¸å½“ï¼ˆç›´è¿‘å–¶æ¥­æ—¥æ™‚ç‚¹ã®å€™è£œæ•°ï¼‰ï¼š{total_candidates_today} éŠ˜æŸ„"
            )
        except Exception:
            pass

    if not candidates_by_date:
        return pd.DataFrame(
            columns=[
                "symbol",
                "system",
                "side",
                "signal_type",
                "entry_date",
                "entry_price",
                "stop_price",
                "score_key",
                "score",
            ]
        )

    # å½“æ—¥ã¾ãŸã¯ç›´è¿‘éå»æ—¥ã®å€™è£œã®ã¿æŠ½å‡º
    if target_date is not None and target_date in key_map:
        orig_key2 = key_map[target_date]
        today_candidates = cast(
            list[dict], candidates_by_date.get(orig_key2, [])
        )
    else:
        today_candidates = cast(list[dict], [])
    if not today_candidates:
        return pd.DataFrame(
            columns=[
                "symbol",
                "system",
                "side",
                "signal_type",
                "entry_date",
                "entry_price",
                "stop_price",
                "score_key",
                "score",
            ]
        )
    rows: list[TodaySignal] = []
    for c in today_candidates:
        sym = c.get("symbol")
        if not sym or sym not in prepared:
            continue
        df = prepared[sym]
        comp = _compute_entry_stop(strategy, df, c, side)
        if not comp:
            continue
        entry, stop = comp
        skey, sval, _asc = _score_from_candidate(system_name, c)

        # System1 ã¯ ROC200 ã‚’å¿…ãšã‚¹ã‚³ã‚¢ã«æ¡ç”¨ã§ãã‚‹ã‚ˆã†å …ç‰¢åŒ–
        try:
            if (system_name == "system1") and (
                skey is None or str(skey).upper() != "ROC200"
            ):
                skey = "ROC200"
        except Exception:
            pass

        # signal æ—¥ï¼ˆé€šå¸¸ã¯ entry_date ã®å‰å–¶æ¥­æ—¥ã‚’æƒ³å®šï¼‰
        signal_date_ts: pd.Timestamp | None = None
        try:
            # candidate["Date"] ãŒã‚ã‚Œã°å„ªå…ˆ
            if "Date" in c and c.get("Date") is not None:
                date_arg: Any = c.get("Date")
                tmp = pd.to_datetime(date_arg, errors="coerce")
                if not pd.isna(tmp):
                    signal_date_ts = pd.Timestamp(tmp).normalize()
        except Exception:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯å¾Œæ®µã® entry_date è£œå®Œã«ä»»ã›ã‚‹
            pass
        if signal_date_ts is None:
            try:
                ed_arg: Any = c.get("entry_date")
                ed = pd.to_datetime(ed_arg, errors="coerce")
                if isinstance(ed, pd.Timestamp) and not pd.isna(ed):
                    # ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ—¥ã®å‰ã€ŒNYSEå–¶æ¥­æ—¥ã€ã‚’æ¨å®š
                    signal_date_ts = get_latest_nyse_trading_day(
                        pd.Timestamp(ed).normalize() - pd.Timedelta(days=1)
                    )
            except Exception:
                signal_date_ts = None

        # æ¬ æã‚¹ã‚³ã‚¢ã®è£œå®Œï¼ˆã¾ãšå€¤ã€æ¬¡ã«é †ä½ï¼‰
        rank_val: int | None = None
        total_for_rank: int = 0
        if skey is not None:
            # 1) æ¬ æãªã‚‰ prepared ã‹ã‚‰åŒæ—¥å€¤ã‚’è£œå®Œ
            if sval is None or (isinstance(sval, float) and pd.isna(sval)):
                try:
                    if signal_date_ts is not None:
                        xdf = prepared[sym]
                        if "Date" in xdf.columns:
                            dt_vals = (
                                pd.to_datetime(xdf["Date"], errors="coerce")
                                .dt.normalize()
                                .to_numpy()
                            )
                        else:
                            dt_vals = (
                                pd.to_datetime(xdf.index, errors="coerce")
                                .normalize()
                                .to_numpy()
                            )
                        mask = dt_vals == signal_date_ts
                        row = xdf.loc[mask]
                        if not row.empty and skey in row.columns:
                            _v = row.iloc[0][skey]
                            if _v is not None and not pd.isna(_v):
                                sval = float(_v)
                except Exception:
                    pass
            # System1 ç”¨ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆå‰æ—¥ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ç›´è¿‘å€¤ï¼‰
            if (system_name == "system1") and (
                sval is None or (isinstance(sval, float) and pd.isna(sval))
            ):
                try:
                    if skey in prepared[sym].columns:
                        _v = pd.Series(prepared[sym][skey]).dropna().tail(1).iloc[0]
                        sval = float(_v)
                except Exception:
                    pass

            # 2) å€¤ãŒã¾ã æ¬ æãªã‚‰ã€åŒæ—¥å…¨éŠ˜æŸ„ã®é †ä½ã‚’ç®—å‡ºã—ã¦ã‚¹ã‚³ã‚¢ã«è¨­å®š
            try:
                if signal_date_ts is not None:
                    vals: list[tuple[str, float]] = []
                    for psym, pdf in prepared.items():
                        try:
                            if "Date" in pdf.columns:
                                dt_vals = (
                                    pd.to_datetime(pdf["Date"], errors="coerce")
                                    .dt.normalize()
                                    .to_numpy()
                                )
                            else:
                                dt_vals = (
                                    pd.to_datetime(pdf.index, errors="coerce")
                                    .normalize()
                                    .to_numpy()
                                )
                            mask = dt_vals == signal_date_ts
                            row = pdf.loc[mask]
                            if not row.empty and skey in row.columns:
                                v = row.iloc[0][skey]
                                if v is not None and not pd.isna(v):
                                    vals.append((psym, float(v)))
                        except Exception:
                            continue
                    total_for_rank = len(vals)
                    if total_for_rank:
                        # ä¸¦ã³é †: system ã®æ˜‡é™é †æ¨å®šã«åˆã‚ã›ã‚‹ï¼ˆROC200 ãªã©ã¯é™é †ï¼‰
                        reverse = not _asc
                        # å€¤ãŒåŒä¸€ã®ã¨ãã¯ã‚·ãƒ³ãƒœãƒ«ã§å®‰å®šã‚½ãƒ¼ãƒˆ
                        vals_sorted = sorted(
                            vals, key=lambda t: (t[1], t[0]), reverse=reverse
                        )
                        # è‡ªéŠ˜æŸ„ã®é †ä½ã‚’æ±ºå®š
                        symbols_sorted = [s for s, _ in vals_sorted]
                        if sym in symbols_sorted:
                            rank_val = symbols_sorted.index(sym) + 1
                        # ã‚¹ã‚³ã‚¢ãŒæ¬ æãªã‚‰é †ä½ã‚’ãã®ã¾ã¾ã‚¹ã‚³ã‚¢ã«æ¡ç”¨
                        if sval is None or (isinstance(sval, float) and pd.isna(sval)):
                            if rank_val is not None:
                                sval = float(rank_val)
            except Exception:
                pass

        # é¸å®šç†ç”±ï¼ˆé †ä½ã‚’æœ€å„ªå…ˆã€ãªã‘ã‚Œã°ç°¡æ½”ã‹ã¤ã‚·ã‚¹ãƒ†ãƒ å›ºæœ‰ã®æ–‡è¨€ï¼‰
        reason_parts: list[str] = []
        # System1 ã¯æ—¥æœ¬èªã§ã€ŒROC200ãŒnä½ã®ãŸã‚ã€ã«çµ±ä¸€ï¼ˆé †ä½ãŒå–ã‚Œãªã„å ´åˆã®ã¿æ±ç”¨æ–‡è¨€ï¼‰
        if system_name == "system1":
            if rank_val is not None and int(rank_val) <= 10:
                reason_parts = [f"ROC200ãŒ{int(rank_val)}ä½ã®ãŸã‚"]
            else:
                reason_parts = ["ROC200ãŒä¸Šä½ã®ãŸã‚"]
        elif system_name == "system2":
            if rank_val is not None and skey is not None:
                reason_parts = [f"{_label_for_score_key(skey)}ãŒ{rank_val}ä½ã®ãŸã‚"]
            else:
                reason_parts = ["ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ãŒå¼·ãéç†±ã®ãŸã‚"]
        elif system_name == "system3":
            if rank_val is not None and skey is not None:
                reason_parts = [f"{_label_for_score_key(skey)}ãŒ{rank_val}ä½ã®ãŸã‚"]
            else:
                reason_parts = ["ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒé«˜ãæ¡ä»¶ä¸€è‡´ã®ãŸã‚"]
        elif system_name == "system4":
            if rank_val is not None:
                reason_parts = [f"RSI4ãŒ{rank_val}ä½ï¼ˆä½æ°´æº–ï¼‰ã®ãŸã‚"]
            else:
                reason_parts = ["SPYä¸Šæ˜‡å±€é¢ã®æŠ¼ã—ç›®å€™è£œã®ãŸã‚"]
        elif system_name == "system5":
            if rank_val is not None and skey is not None:
                reason_parts = [f"{_label_for_score_key(skey)}ãŒ{rank_val}ä½ã®ãŸã‚"]
            else:
                reason_parts = ["ADXãŒå¼·ãã€åç™ºæœŸå¾…ã®ãŸã‚"]
        elif system_name == "system6":
            if rank_val is not None:
                reason_parts = [f"éå»6æ—¥é¨°è½ç‡ãŒ{rank_val}ä½ã®ãŸã‚"]
            else:
                reason_parts = ["çŸ­æœŸä¸‹è½ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆã‚·ãƒ§ãƒ¼ãƒˆï¼‰æ¡ä»¶ä¸€è‡´ã®ãŸã‚"]
        elif system_name == "system7":
            # ATR50 ã¯æåˆ‡ã‚Šè¨ˆç®—ç”¨ã€‚ç†ç”±ã¯ã€Œ50æ—¥å®‰å€¤æ›´æ–°ã€ã«é™å®šã™ã‚‹ã€‚
            reason_parts = ["SPYãŒ50æ—¥å®‰å€¤ã‚’æ›´æ–°ã—ãŸãŸã‚ï¼ˆãƒ˜ãƒƒã‚¸ï¼‰"]
        else:
            if skey is not None and rank_val is not None:
                if rank_val <= 10:
                    reason_parts = [f"{_label_for_score_key(skey)}ãŒ{rank_val}ä½ã®ãŸã‚"]
                else:
                    reason_parts = [f"rank={rank_val}/{total_for_rank}"]
            elif skey is not None:
                # å€¤ã¯åŸå‰‡éè¡¨ç¤ºï¼ˆå†—é•·å›é¿ï¼‰ã€‚å¿…è¦æœ€å°é™ã ã‘ç¤ºã™ã€‚
                try:
                    if sval is not None and not (
                        isinstance(sval, float) and pd.isna(sval)
                    ):
                        reason_parts.append("ã‚¹ã‚³ã‚¢æ¡ä»¶ã‚’æº€ãŸã—ãŸãŸã‚")
                except Exception:
                    reason_parts.append("ã‚¹ã‚³ã‚¢æ¡ä»¶ã‚’æº€ãŸã—ãŸãŸã‚")

        # fallback generic info
        if not reason_parts:
            reason_parts.append("æ¡ä»¶ä¸€è‡´ã®ãŸã‚")

        reason_text = "; ".join(reason_parts)

        try:
            _ed_raw: Any = c.get("entry_date")
            _ed = pd.Timestamp(_ed_raw) if _ed_raw is not None else None
            if _ed is None or pd.isna(_ed):
                # entry_date ãŒæ¬ æã™ã‚‹å€™è£œã¯ç„¡åŠ¹
                continue
            entry_date_norm = pd.Timestamp(_ed).normalize()
        except Exception:
            continue

        rows.append(
            TodaySignal(
                symbol=str(sym),
                system=system_name,
                side=side,
                signal_type=signal_type,
                entry_date=entry_date_norm,
                entry_price=float(entry),
                stop_price=float(stop),
                score_key=skey,
                # ã‚¹ã‚³ã‚¢ã¯å€¤ãŒã‚ã‚Œã°å€¤ã€ç„¡ã‘ã‚Œã°é †ä½ï¼ˆä¸Šè¨˜ã§è£œå®Œæ¸ˆã¿ï¼‰
                score=(
                    None
                    if sval is None or (isinstance(sval, float) and pd.isna(sval))
                    else float(sval)
                ),
                reason=reason_text,
            )
        )

    if not rows:
        return pd.DataFrame(
            columns=[
                "symbol",
                "system",
                "side",
                "signal_type",
                "entry_date",
                "entry_price",
                "stop_price",
                "score_key",
                "score",
            ]
        )

    out = pd.DataFrame([r.__dict__ for r in rows])

    try:
        max_pos = int(get_settings(create_dirs=False).risk.max_positions)
    except Exception:
        max_pos = 10
    if max_pos > 0 and not out.empty:

        def _sort_val(row: pd.Series) -> float:
            sc = row.get("score")
            sk = row.get("score_key")
            if sc is None or (isinstance(sc, float) and pd.isna(sc)):
                return float("inf")
            return float(sc) if _asc_by_score_key(sk) else -float(sc)

        out["_sort_val"] = out.apply(_sort_val, axis=1)
        out = (
            out.sort_values("_sort_val")
            .head(max_pos)
            .drop(columns=["_sort_val"])
            .reset_index(drop=True)
        )
    final_count = len(out)

    try:
        if log_callback:
            log_callback(f"ğŸ§® ãƒˆãƒ¬ãƒ¼ãƒ‰å€™è£œé¸å®šå®Œäº†ï¼ˆå½“æ—¥ï¼‰ï¼š{final_count} éŠ˜æŸ„")
    except Exception:
        pass
    try:
        if stage_progress:
            stage_progress(
                100, filter_pass, setup_pass, total_candidates_today, final_count
            )
    except Exception:
        pass
    return out


def run_all_systems_today(
    symbols: list[str] | None,
    *,
    slots_long: int | None = None,
    slots_short: int | None = None,
    capital_long: float | None = None,
    capital_short: float | None = None,
    save_csv: bool = False,
    csv_name_mode: str | None = None,
    notify: bool = True,
    log_callback: Callable[[str], None] | None = None,
    progress_callback: Callable[[int, int, str], None] | None = None,
    per_system_progress: Callable[[str, str], None] | None = None,
    symbol_data: dict[str, pd.DataFrame] | None = None,
    parallel: bool = False,
) -> tuple[pd.DataFrame, dict[str, pd.DataFrame]]:
    """scripts.run_all_systems_today.compute_today_signals ã®ãƒ©ãƒƒãƒ‘ãƒ¼ã€‚"""
    from scripts.run_all_systems_today import compute_today_signals as _compute

    return _compute(
        symbols,
        slots_long=slots_long,
        slots_short=slots_short,
        capital_long=capital_long,
        capital_short=capital_short,
        save_csv=save_csv,
        csv_name_mode=csv_name_mode,
        notify=notify,
        log_callback=log_callback,
        progress_callback=progress_callback,
        per_system_progress=per_system_progress,
        symbol_data=symbol_data,
        parallel=parallel,
    )


compute_today_signals = run_all_systems_today


__all__ = [
    "get_today_signals_for_strategy",
    "LONG_SYSTEMS",
    "SHORT_SYSTEMS",
    "run_all_systems_today",
    "compute_today_signals",
]
