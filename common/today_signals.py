from __future__ import annotations

from collections.abc import Callable
from dataclasses import dataclass
import inspect
import time as _t
from typing import Any, cast
import numpy as np

import pandas as pd

from config.settings import get_settings
from core.system5 import (
    DEFAULT_ATR_PCT_THRESHOLD,
    format_atr_pct_threshold_label,
)
from common.utils_spy import get_spy_with_indicators, resolve_signal_entry_date

# --- „Çµ„Ç§„ÉâÂÆöÁæ©ÔºàÂ£≤Ë≤∑Âå∫ÂàÜÔºâ---
# System1/3/5 „ÅØË≤∑„ÅÑÊà¶Áï•„ÄÅSystem2/4/6/7 „ÅØÂ£≤„ÇäÊà¶Áï•„Å®„Åó„Å¶Êâ±„ÅÜ„ÄÇ
LONG_SYSTEMS = {"system1", "system3", "system5"}
SHORT_SYSTEMS = {"system2", "system4", "system6", "system7"}

# fast-path Âà§ÂÆö„Å´‰ΩøÁî®„Åô„ÇãÂøÖÈ†àÂàó
_FAST_PATH_REQUIRED_COLUMNS = {"filter", "setup"}

TODAY_SIGNAL_COLUMNS = [
    "symbol",
    "system",
    "side",
    "signal_type",
    "entry_date",
    "entry_price",
    "stop_price",
    "score_key",
    "score",
    "reason",
]

# fast-path Âà§ÂÆö„Å´‰ΩøÁî®„Åô„ÇãÂøÖÈ†àÂàó
_FAST_PATH_REQUIRED_COLUMNS = {"filter", "setup"}


@dataclass(frozen=True)
class TodaySignal:
    symbol: str
    system: str
    side: str  # "long" | "short"
    signal_type: str  # "buy" | "sell"
    entry_date: pd.Timestamp
    entry_price: float
    stop_price: float
    score_key: str | None = None
    score: float | None = None
    reason: str | None = None


def _missing_fast_path_columns(data_dict: dict[str, pd.DataFrame]) -> set[str]:
    """È´òÈÄüÁµåË∑Ø„Å´ÂøÖË¶Å„Å™Âàó„ÅåÊèÉ„Å£„Å¶„ÅÑ„Çã„Åã„ÇíÂà§ÂÆö„Åó„ÄÅ‰∏çË∂≥ÈõÜÂêà„ÇíËøî„Åô„ÄÇ"""

    if not isinstance(data_dict, dict) or not data_dict:
        return set(_FAST_PATH_REQUIRED_COLUMNS)

    missing: set[str] = set()
    has_valid_frame = False
    for df in data_dict.values():
        if df is None or getattr(df, "empty", True):
            continue
        has_valid_frame = True
        try:
            cols = {str(c).strip().lower() for c in df.columns}
        except Exception:
            missing.update(_FAST_PATH_REQUIRED_COLUMNS)
            continue
        for col in _FAST_PATH_REQUIRED_COLUMNS:
            if col not in cols:
                missing.add(col)

    if not has_valid_frame:
        return set(_FAST_PATH_REQUIRED_COLUMNS)
    return missing


def _is_fast_path_viable(
    data_dict: dict[str, pd.DataFrame]
) -> tuple[bool, set[str]]:
    """È´òÈÄüÁµåË∑Ø„Åß candidate ÊäΩÂá∫„ÅåÂèØËÉΩ„ÅãÂà§ÂÆö„Åó„ÄÅ(bool, ‰∏çË∂≥Âàó) „ÇíËøî„Åô„ÄÇ"""

    missing = _missing_fast_path_columns(data_dict)
    return len(missing) == 0, missing


def _empty_today_signals_frame() -> pd.DataFrame:
    return pd.DataFrame(columns=TODAY_SIGNAL_COLUMNS)


def _normalize_daily_index(df: pd.DataFrame) -> pd.DataFrame:
    x = df.copy()
    if "Date" in x.columns:
        idx = pd.to_datetime(x["Date"], errors="coerce").dt.normalize()
        x.index = pd.Index(idx)
    else:
        x.index = pd.to_datetime(x.index, errors="coerce").normalize()
    x = x[~x.index.isna()]
    try:
        x = x.sort_index()
    except Exception:
        pass
    try:
        if getattr(x.index, "has_duplicates", False):
            x = x[~x.index.duplicated(keep="last")]
    except Exception:
        pass
    return x


def _make_spy_gate(spy_df: pd.DataFrame | None) -> bool | None:
    if spy_df is None or getattr(spy_df, "empty", True):
        return None
    try:
        last_row = spy_df.iloc[-1]
    except Exception:
        return None
    try:
        close_val = pd.to_numeric(
            pd.Series([last_row.get("Close")]), errors="coerce"
        ).iloc[0]
        sma_val = pd.to_numeric(
            pd.Series([last_row.get("SMA200")]), errors="coerce"
        ).iloc[0]
    except Exception:
        return None
    if pd.isna(close_val) or pd.isna(sma_val):
        return None
    try:
        return bool(float(close_val) > float(sma_val))
    except Exception:
        return None


def _collect_candidates_for_today(
    prepared: dict[str, pd.DataFrame],
    *,
    spy_df: pd.DataFrame,
    top_n: int,
) -> dict[pd.Timestamp, list[dict]] | None:
    try:
        spy_norm = _normalize_daily_index(spy_df)
    except Exception:
        return None
    if spy_norm.empty or "Close" not in spy_norm.columns:
        return None
    if "SMA200" not in spy_norm.columns:
        return None
    spy_norm = spy_norm.copy()
    spy_close = pd.to_numeric(spy_norm["Close"], errors="coerce")
    spy_sma = pd.to_numeric(spy_norm["SMA200"], errors="coerce")
    spy_norm["spy_filter"] = (spy_close > spy_sma).astype(int)
    spy_filter = spy_norm["spy_filter"]

    candidates: dict[pd.Timestamp, list[dict]] = {}
    required_cols = {
        "Close",
        "DollarVolume50",
        "HV50",
        "SMA200",
        "RSI4",
        "ATR40",
    }

    for sym, df in prepared.items():
        if str(sym).upper() == "SPY":
            continue
        if not isinstance(df, pd.DataFrame) or getattr(df, "empty", True):
            continue
        try:
            norm = _normalize_daily_index(df)
        except Exception:
            return None
        if required_cols - set(norm.columns):
            return None

        close = pd.to_numeric(norm["Close"], errors="coerce")
        sma200 = pd.to_numeric(norm["SMA200"], errors="coerce")
        dv50 = pd.to_numeric(norm["DollarVolume50"], errors="coerce")
        hv50 = pd.to_numeric(norm["HV50"], errors="coerce")

        setup_mask = (dv50 > 100_000_000) & hv50.between(10, 40) & (close > sma200)
        setup_mask = setup_mask.fillna(False)
        if not setup_mask.any():
            continue

        try:
            last_close_series = close.dropna()
            last_close = (
                float(last_close_series.iloc[-1])
                if not last_close_series.empty
                else None
            )
        except Exception:
            last_close = None

        for ts in norm.index[setup_mask]:
            ts_norm = pd.Timestamp(ts).normalize()
            if ts_norm not in spy_filter.index:
                continue
            try:
                gate_val = spy_filter.loc[ts_norm]
                if isinstance(gate_val, pd.Series):
                    gate_val = gate_val.iloc[-1]
            except Exception:
                continue
            if pd.isna(gate_val) or int(gate_val) == 0:
                continue
            entry_date = resolve_signal_entry_date(ts_norm)
            if pd.isna(entry_date):
                continue
            row = norm.loc[ts_norm]
            candidate = {
                "symbol": sym,
                "entry_date": entry_date,
                "RSI4": row.get("RSI4"),
                "ATR40": row.get("ATR40"),
            }
            if last_close is not None and not pd.isna(last_close):
                candidate["entry_price"] = last_close
            candidates.setdefault(entry_date, []).append(candidate)

    if not candidates:
        return {}

    limited: dict[pd.Timestamp, list[dict]] = {}
    try:
        limit_n = max(0, int(top_n))
    except Exception:
        limit_n = 0
    for dt, rows in candidates.items():
        sorted_rows = sorted(
            rows,
            key=lambda c: (
                float("inf")
                if c.get("RSI4") is None or pd.isna(c.get("RSI4"))
                else float(c["RSI4"]),
                str(c.get("symbol") or ""),
            ),
        )
        limited[dt] = sorted_rows[:limit_n]
    return limited


def _infer_side(system_name: str) -> str:
    name = (system_name or "").lower()
    if name in SHORT_SYSTEMS:
        return "short"
    return "long"


def _score_from_candidate(
    system_name: str, candidate: dict
) -> tuple[str | None, float | None, bool]:
    """
    ÂÄôË£ú„É¨„Ç≥„Éº„Éâ„Åã„Çâ„Çπ„Ç≥„Ç¢È†ÖÁõÆ„Å®‰∏¶„Å≥È†ÜÔºàÊòáÈ†Ü„ÅãÔºâ„ÇíÊé®ÂÆö„Åó„Å¶Ëøî„Åô„ÄÇ
    Êàª„ÇäÂÄ§: (score_key, score_value, asc)
    """
    name = (system_name or "").lower()
    # System7 „ÅØ SPY Â∞ÇÁî®„Éò„ÉÉ„Ç∏„ÄÇATR50 „ÅØ„Çπ„Éà„ÉÉ„ÉóË®àÁÆóÁî®„ÅÆ„Åü„ÇÅ„ÄÅ
    # „Çπ„Ç≥„Ç¢/ÁêÜÁî±„Å´„ÅØ‰ΩøÁî®„Åó„Å™„ÅÑÔºà„Çπ„Ç≥„Ç¢Ê¨Ñ„ÅØÁ©∫„Å´„Åô„ÇãÔºâ„ÄÇ
    if name == "system7":
        return None, None, False
    # „Ç∑„Çπ„ÉÜ„É†Âà•„ÅÆ‰ª£Ë°®„Çπ„Ç≥„Ç¢
    key_order: list[tuple[list[str], bool]] = [
        (["ROC200"], False),  # s1: Â§ß„Åç„ÅÑ„Åª„Å©ËâØ„ÅÑ
        (["ADX7"], False),  # s2,s5: Â§ß„Åç„ÅÑ„Åª„Å©ËâØ„ÅÑ
        (["Drop3D"], False),  # s3: Â§ß„Åç„ÅÑ„Åª„Å©ËâØ„ÅÑÔºà‰∏ãËêΩÁéáÔºâ
        (["RSI4"], True),  # s4: Â∞è„Åï„ÅÑ„Åª„Å©ËâØ„ÅÑ
        (["Return6D"], False),  # s6: Â§ß„Åç„ÅÑ„Åª„Å©ËâØ„ÅÑ
        (["ATR50"], False),  # s7: ÂèÇËÄÉ
    ]
    # system Âõ∫ÊúâÂÑ™ÂÖàÈ†Ü‰Ωç
    if name == "system4":
        key_order = [(["RSI4"], True), (["ATR40"], True)] + key_order
    elif name == "system2":
        key_order = [(["ADX7"], False), (["RSI3"], False)] + key_order
    elif name == "system5":
        key_order = [(["ADX7"], False), (["ATR10"], True)] + key_order
    elif name == "system6":
        key_order = [(["Return6D"], False), (["ATR10"], True)] + key_order

    for keys, asc in key_order:
        for k in keys:
            if k in candidate:
                v = candidate.get(k)
                if v is None:
                    return k, None, asc
                if isinstance(v, (int, float, str)):
                    try:
                        return k, float(v), asc
                    except Exception:
                        return k, None, asc
                else:
                    return k, None, asc
    # Ë¶ã„Å§„Åã„Çâ„Å™„ÅÑÂ†¥Âêà
    return None, None, False


def _label_for_score_key(key: str | None) -> str:
    """„Çπ„Ç≥„Ç¢„Ç≠„Éº„ÅÆÊó•Êú¨Ë™û„É©„Éô„É´„ÇíËøî„ÅôÔºàÊó¢Áü•„ÅÆ„ÇÇ„ÅÆ„ÅÆ„ÅøÁ∞°ÊΩîË°®Á§∫Ôºâ„ÄÇ"""
    if key is None:
        return "„Çπ„Ç≥„Ç¢"
    k = str(key).upper()
    mapping = {
        "ROC200": "ROC200",
        "ADX7": "ADX",
        "RSI4": "RSI4",
        "RSI3": "RSI3",
        "DROP3D": "3Êó•‰∏ãËêΩÁéá",
        "RETURN6D": "ÈÅéÂéª6Êó•È®∞ËêΩÁéá",
        "ATR10": "ATR10",
        "ATR20": "ATR20",
        "ATR40": "ATR40",
        "ATR50": "ATR50",
    }
    return mapping.get(k, k)


def _asc_by_score_key(score_key: str | None) -> bool:
    """„Çπ„Ç≥„Ç¢„Ç≠„Éº„Åî„Å®„ÅÆÊòáÈ†Ü/ÈôçÈ†Ü„ÇíÂà§ÂÆö„ÄÇ"""
    return bool(score_key and score_key.upper() in {"RSI4"})


def _pick_atr_col(df: pd.DataFrame) -> str | None:
    for col in ("ATR20", "ATR10", "ATR40", "ATR50", "ATR14"):
        if col in df.columns:
            return col
    return None


def _compute_entry_stop(
    strategy, df: pd.DataFrame, candidate: dict, side: str
) -> tuple[float, float] | None:
    # strategy Áã¨Ëá™„ÅÆ compute_entry „Åå„ÅÇ„Çå„Å∞ÂÑ™ÂÖà
    try:
        _fn = strategy.compute_entry  # type: ignore[attr-defined]
    except Exception:
        _fn = None
    if callable(_fn):
        try:
            res = _fn(df, candidate, 0.0)
            if res and isinstance(res, tuple) and len(res) == 2:
                entry, stop = float(res[0]), float(res[1])
                if entry > 0 and (
                    (side == "short" and stop > entry)
                    or (side == "long" and entry > stop)
                ):
                    return round(entry, 4), round(stop, 4)
        except Exception:
            pass

    # „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ: ÂΩìÊó•ÂßãÂÄ§ ¬± 3*ATR
    try:
        entry_ts = pd.Timestamp(candidate["entry_date"])
    except Exception:
        return None
    try:
        idxer = df.index.get_indexer([entry_ts])
        entry_idx = int(idxer[0]) if len(idxer) else -1
    except Exception:
        return None
    if entry_idx <= 0 or entry_idx >= len(df):
        return None
    try:
        entry = float(df.iloc[entry_idx]["Open"])
    except Exception:
        return None
    atr_col = _pick_atr_col(df)
    if not atr_col:
        return None
    try:
        atr = float(df.iloc[entry_idx - 1][atr_col])
    except Exception:
        return None
    mult = 3.0
    stop = entry - mult * atr if side == "long" else entry + mult * atr
    return round(entry, 4), round(stop, 4)


def get_today_signals_for_strategy(
    strategy,
    raw_data_dict: dict[str, pd.DataFrame],
    *,
    market_df: pd.DataFrame | None = None,
    today: pd.Timestamp | None = None,
    progress_callback: Callable[..., None] | None = None,
    log_callback: Callable[[str], None] | None = None,
    stage_progress: (
        Callable[[int, int | None, int | None, int | None, int | None], None] | None
    ) = None,
    use_process_pool: bool = False,
    max_workers: int | None = None,
    lookback_days: int | None = None,
) -> pd.DataFrame:
    """
    ÂêÑ Strategy „ÅÆ prepare_data / generate_candidates „ÇíÊµÅÁî®„Åó„ÄÅ
    ÊúÄÊñ∞Âñ∂Ê•≠Êó•„ÅÆÂÄôË£ú„ÅÆ„Åø„Çí DataFrame „ÅßËøî„Åô„ÄÇ

    Êàª„ÇäÂÄ§„Ç´„É©„É†:
        - symbol, system, side, signal_type,
          entry_date, entry_price, stop_price,
          score_key, score
    """
    from common.utils_spy import get_latest_nyse_trading_day

    try:
        system_name = str(strategy.SYSTEM_NAME).lower()  # type: ignore[attr-defined]
    except Exception:
        system_name = ""
    side = _infer_side(system_name)
    signal_type = "sell" if side == "short" else "buy"

    # ÂèñÂºïÊó•
    if today is None:
        today = get_latest_nyse_trading_day()
    try:
        today_ts = pd.Timestamp(today)
    except Exception:
        today_ts = get_latest_nyse_trading_day()
    if getattr(today_ts, "tzinfo", None) is not None:
        try:
            today_ts = today_ts.tz_convert(None)
        except (TypeError, ValueError, AttributeError):
            try:
                today_ts = today_ts.tz_localize(None)
            except Exception:
                today_ts = pd.Timestamp(today_ts.to_pydatetime().replace(tzinfo=None))
    today = today_ts.normalize()

    # Ê∫ñÂÇô
    total_symbols = len(raw_data_dict)
    if log_callback:
        try:
            log_callback(f"üß™ „Éï„Ç£„É´„Çø„Éº„ÉÅ„Çß„ÉÉ„ÇØÈñãÂßãÔºö{total_symbols} ÈäòÊüÑ")
        except Exception:
            pass
    # 0% -> 25%
    try:
        if stage_progress:
            # 0% „Çπ„ÉÜ„Éº„Ç∏„Åß„ÅØÂØæË±°ÈäòÊüÑÊï∞„ÇíÁ¨¨1ÂºïÊï∞„Å´Ê∏°„ÅôÔºàUI ÂÅ¥„Åß "ÂØæË±°‚Üín" Ë°®Á§∫„Å´‰ΩøÁî®Ôºâ
            stage_progress(0, total_symbols, None, None, None)
    except Exception:
        pass
    t0 = _t.time()
    # „É´„ÉÉ„ÇØ„Éê„ÉÉ„ÇØÊúÄÈÅ©ÂåñÔºöÂøÖË¶ÅÊó•Êï∞„ÅåÊåáÂÆö„Åï„Çå„Å¶„ÅÑ„Çå„Å∞ÂêÑDF„ÇíÊú´Â∞æNË°å„Å´„Çπ„É©„Ç§„Çπ
    sliced_dict = raw_data_dict
    try:
        if (
            lookback_days is not None
            and lookback_days > 0
            and isinstance(raw_data_dict, dict)
        ):
            sliced: dict[str, pd.DataFrame] = {}
            for _sym, _df in raw_data_dict.items():
                try:
                    if _df is None or getattr(_df, "empty", True):
                        continue
                    x = _df.copy()
                    if "Date" in x.columns:
                        idx = pd.to_datetime(x["Date"], errors="coerce").dt.normalize()
                        x.index = pd.Index(idx)
                    else:
                        x.index = pd.to_datetime(x.index, errors="coerce").normalize()
                    # ‰∏çÊ≠£„Å™Êó•ÊôÇ„ÅØÈô§Â§ñ
                    x = x[~x.index.isna()]
                    # Êú´Â∞æNÂñ∂Ê•≠Êó•Áõ∏ÂΩì„ÇíÊäΩÂá∫
                    x = x.tail(int(lookback_days))
                    sliced[_sym] = x
                except Exception:
                    sliced[_sym] = _df
            sliced_dict = sliced
    except Exception:
        sliced_dict = raw_data_dict

    prepared_dict: dict[str, pd.DataFrame] | None = None
    fast_path_used = False
    fast_missing: set[str] = set()
    try:
        fast_ok, fast_missing = _is_fast_path_viable(sliced_dict)
    except Exception:
        fast_ok = False
        fast_missing = set()
    if fast_ok:
        try:
            prepared_dict = {
                sym: df.copy()
                for sym, df in sliced_dict.items()
                if df is not None and not getattr(df, "empty", True)
            }
            fast_path_used = True
            if log_callback:
                log_callback("‚ö° È´òÈÄü„Éë„Çπ: Êó¢Â≠ò„Ç§„É≥„Ç∏„Ç±„Éº„Çø„Éº„ÇíÂÜçÂà©Áî®„Åó„Åæ„Åô")
        except Exception:
            prepared_dict = None
            fast_path_used = False

    # „Çπ„Ç≠„ÉÉ„ÉóÁêÜÁî±„ÅÆÂèéÈõÜÔºàsystem„Åî„Å®„Å´ÈõÜË®àÔºâ
    _skip_counts: dict[str, int] = {}
    _skip_samples: dict[str, list[str]] = {}
    _skip_details: list[dict[str, str]] = []

    def _on_skip(*args, **kwargs):
        try:
            if len(args) >= 2:
                _sym = str(args[0])
                _reason = str(args[1])
            elif len(args) == 1:
                # "SYM: reason" ÂΩ¢Âºè„Åã„ÇâÁêÜÁî±„Å†„ÅëÊäΩÂá∫
                txt = str(args[0])
                _sym, _reason = (
                    (txt.split(":", 1) + [""])[:2] if ":" in txt else ("", txt)
                )
                _sym = _sym.strip()
                _reason = _reason.strip()
            else:
                _reason = str(kwargs.get("reason", "unknown"))
                _sym = str(kwargs.get("symbol", ""))
        except Exception:
            _reason = "unknown"
            _sym = ""
        _skip_counts[_reason] = _skip_counts.get(_reason, 0) + 1
        if _sym:
            if _reason not in _skip_samples:
                _skip_samples[_reason] = []
            if len(_skip_samples[_reason]) < 5 and _sym not in _skip_samples[_reason]:
                _skip_samples[_reason].append(_sym)
        try:
            _skip_details.append(
                {"symbol": str(_sym or ""), "reason": str(_reason or "")}
            )
        except Exception:
            pass

    if not fast_path_used or prepared_dict is None:
        if fast_missing and log_callback:
            try:
                missing_list = ", ".join(sorted(fast_missing))
                log_callback(
                    "‚ö†Ô∏è È´òÈÄü„Éë„Çπ„ÇíÂà©Áî®„Åß„Åç„Åæ„Åõ„ÇìÔºàÂøÖÈ†àÂàó‰∏çË∂≥: "
                    + (missing_list or "‰∏çÊòé")
                    + "Ôºâ„ÄÇÂÜçË®àÁÆó„Åó„Åæ„Åô„ÄÇ"
                )
            except Exception:
                pass
        try:
            prepared_dict = strategy.prepare_data(
                sliced_dict,
                progress_callback=progress_callback,
                log_callback=log_callback,
                skip_callback=_on_skip,
                use_process_pool=use_process_pool,
                max_workers=max_workers,
                lookback_days=lookback_days,
            )
        except Exception as e:
            # „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ: Èùû„Éó„Éº„É´ + ÂÜçË®àÁÆóÔºàreuse_indicators=FalseÔºâ„ÅßÂÜçË©¶Ë°å
            try:
                if log_callback:
                    log_callback(
                        f"‚ö†Ô∏è {system_name}: ÂâçÂá¶ÁêÜÂ§±Êïó„ÅÆ„Åü„ÇÅ„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÔºàÈùû„Éó„Éº„É´„ÉªÂÜçË®àÁÆóÔºâ: {e}"
                    )
            except Exception:
                pass
            try:
                prepared_dict = strategy.prepare_data(
                    sliced_dict,
                    progress_callback=progress_callback,
                    log_callback=log_callback,
                    skip_callback=_on_skip,
                    use_process_pool=False,
                    max_workers=None,
                    lookback_days=lookback_days,
                    reuse_indicators=False,
                )
            except Exception as e2:
                # „Åì„Åì„ÅßÂ§±Êïó„Åó„Åü„ÇâÁ©∫„ÅÆÁµêÊûú„ÇíËøî„ÅôÔºàÂæåÊÆµ„ÅØ0‰ª∂„ÅßÊµÅ„Çå„ÇãÔºâ
                try:
                    if log_callback:
                        log_callback(
                            f"‚ö†Ô∏è {system_name}: „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ„ÇÇÂ§±ÊïóÔºà‰∏≠Êñ≠Ôºâ: {e2}"
                        )
                except Exception:
                    pass
                return pd.DataFrame(
                    columns=[
                        "symbol",
                        "system",
                        "side",
                        "signal_type",
                        "entry_date",
                        "entry_price",
                        "stop_price",
                        "score_key",
                        "score",
                    ]
                )
    if prepared_dict is None:
        prepared_dict = {}

    # „Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„ÇíÊ≠£Ë¶èÂåñ„ÉªÊòáÈ†Ü„ÉªÈáçË§áÈô§ÂéªÔºàpandas „ÅÆÂÜç„Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπÈñ¢ÈÄ£„Ç®„É©„ÉºÂØæÁ≠ñÔºâ
    try:
        if isinstance(prepared_dict, dict):
            _fixed: dict[str, pd.DataFrame] = {}
            for _sym, _df in prepared_dict.items():
                try:
                    x = _df.copy()
                    if "Date" in x.columns:
                        idx = pd.to_datetime(x["Date"], errors="coerce").dt.normalize()
                    else:
                        idx = pd.to_datetime(x.index, errors="coerce").normalize()
                    x.index = pd.Index(idx)
                    # Ê¨†Êêç„ÉªÈùûÂçòË™ø„ÉªÈáçË§á„ÇíÊï¥ÁêÜ
                    x = x[~x.index.isna()]
                    x = x.sort_index()
                    if getattr(x.index, "has_duplicates", False):
                        x = x[~x.index.duplicated(keep="last")]
                    _fixed[_sym] = x
                except Exception:
                    _fixed[_sym] = _df
            prepared_dict = _fixed
    except Exception:
        pass

    prepared = prepared_dict
    try:
        if log_callback:
            em, es = divmod(int(max(0, _t.time() - t0)), 60)
            log_callback(f"‚è±Ô∏è „Éï„Ç£„É´„Çø„Éº/ÂâçÂá¶ÁêÜ ÂÆå‰∫ÜÔºàÁµåÈÅé {em}ÂàÜ{es}ÁßíÔºâ")
    except Exception:
        pass
    # „Çπ„Ç≠„ÉÉ„ÉóÂÜÖË®≥„ÅÆË¶ÅÁ¥ÑÔºàÂ≠òÂú®ÊôÇ„ÅÆ„ÅøÔºâ
    try:
        if log_callback and _skip_counts:
            # ‰∏ä‰Ωç2‰ª∂„ÅÆ„Åø„ÇíÁ∞°ÊΩî„Å´Ë°®Á§∫
            sorted_items = sorted(
                _skip_counts.items(), key=lambda x: x[1], reverse=True
            )
            top = sorted_items[:2]
            details = ", ".join([f"{k}: {v}" for k, v in top])
            log_callback(f"üß™ „Çπ„Ç≠„ÉÉ„ÉóÂÜÖË®≥: {details}")
            # „Çµ„É≥„Éó„É´ÈäòÊüÑÂá∫Âäõ
            for k, _ in top:
                samples = _skip_samples.get(k) or []
                if samples:
                    log_callback(f"  ‚Ü≥ ‰æã({k}): {', '.join(samples)}")
            # ËøΩÂä†: ÂÖ®„Çπ„Ç≠„ÉÉ„Éó„ÅÆCSV„Çí‰øùÂ≠òÔºà„Éá„Éê„ÉÉ„Ç∞Áî®Ôºâ„ÄÇUI/CLI‰∏°Êñπ„Åß„Éë„Çπ„ÇíÂá∫Âäõ„ÄÇ
            try:
                import pandas as _pd
                from config.settings import get_settings as _gs

                _rows = []
                for _reason, _cnt in sorted_items:
                    _rows.append(
                        {
                            "reason": _reason,
                            "count": int(_cnt),
                            "examples": ", ".join(_skip_samples.get(_reason, [])),
                        }
                    )
                if _rows:
                    _df = _pd.DataFrame(_rows)
                    try:
                        _settings = _gs(create_dirs=True)
                        _dir = getattr(_settings.outputs, "results_csv_dir", None)
                    except Exception:
                        _dir = None
                    import os as _os

                    _out_dir = str(_dir or "results_csv")
                    try:
                        _os.makedirs(_out_dir, exist_ok=True)
                    except Exception:
                        pass
                    _fp = _os.path.join(_out_dir, f"skip_summary_{system_name}.csv")
                    try:
                        _df.to_csv(_fp, index=False, encoding="utf-8")
                        log_callback(f"üìù „Çπ„Ç≠„ÉÉ„ÉóÂÜÖË®≥CSV„Çí‰øùÂ≠ò: {_fp}")
                    except Exception:
                        pass
                    # per-symbol „ÅÆË©≥Á¥∞Ôºàsymbol, reasonÔºâ„ÇÇ‰øùÂ≠ò
                    try:
                        if _skip_details:
                            _df2 = _pd.DataFrame(_skip_details)
                            _fp2 = _os.path.join(
                                _out_dir, f"skip_details_{system_name}.csv"
                            )
                            _df2.to_csv(_fp2, index=False, encoding="utf-8")
                            log_callback(f"üìù „Çπ„Ç≠„ÉÉ„ÉóË©≥Á¥∞CSV„Çí‰øùÂ≠ò: {_fp2}")
                    except Exception:
                        pass
            except Exception:
                pass
    except Exception:
        pass
    # „Éï„Ç£„É´„Çø„ÉºÈÄöÈÅé‰ª∂Êï∞ÔºàNYSE„Ç´„É¨„É≥„ÉÄ„Éº„ÅÆÂâçÂñ∂Ê•≠Êó•„ÇíÂÑ™ÂÖà„ÄÇÁÑ°„ÅÑÂ†¥Âêà„ÅØÊúÄÁµÇË°åÔºâ„ÄÇ
    try:
        # ÂâçÂñ∂Ê•≠Êó•ÔºàÂΩìÊó•„Ç®„É≥„Éà„É™„Éº„ÅÆ„Ç∑„Ç∞„Éä„É´„ÅØÂâçÂñ∂Ê•≠Êó•„ÅÆÁµÇÂÄ§„ÅßÂà§ÂÆöÔºâ
        prev_trading_day = get_latest_nyse_trading_day(
            pd.Timestamp(today) - pd.Timedelta(days=1)
        )

        def _last_filter_on_date(x: pd.DataFrame) -> bool:
            try:
                if getattr(x, "empty", True) or "filter" not in x.columns:
                    return False
                # DateÂàó„Åå„ÅÇ„Çå„Å∞ÂÑ™ÂÖà„ÄÅÁÑ°„Åë„Çå„Å∞index„ÅßÊØîËºÉ
                if "Date" in x.columns:
                    dt_vals = (
                        pd.to_datetime(x["Date"], errors="coerce")
                        .dt.normalize()
                        .to_numpy()
                    )
                    mask = dt_vals == prev_trading_day
                    sel = pd.Series(np.asarray(x.loc[mask, "filter"]))
                else:
                    idx_vals = (
                        pd.to_datetime(x.index, errors="coerce").normalize().to_numpy()
                    )
                    mask = idx_vals == prev_trading_day
                    sel = pd.Series(np.asarray(x.loc[mask, "filter"]))
                if sel.size > 0:
                    v = sel.iloc[-1]
                    return bool(False if pd.isna(v) else bool(v))
                # „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ: ÊúÄÁµÇË°å
                v = pd.Series(x["filter"]).tail(1).iloc[0]
                return bool(False if pd.isna(v) else bool(v))
            except Exception:
                return False

        filter_pass = sum(int(_last_filter_on_date(df)) for df in prepared.values())
        # System7 „ÅØ SPY Âõ∫ÂÆö„ÅÆ„Åü„ÇÅ„ÄÅSPY„ÅåÂ≠òÂú®„Åô„ÇãÂ†¥Âêà„ÅØ„Éï„Ç£„É´„ÇøÈÄöÈÅé=1„Å®„Åó„Å¶Êâ±„ÅÜ
        try:
            if str(system_name).lower() == "system7":
                filter_pass = 1 if ("SPY" in (prepared or {})) else 0
        except Exception:
            pass
    except Exception:
        filter_pass = 0
    if log_callback:
        try:
            log_callback(f"üß™ „Éï„Ç£„É´„Çø„Éº„ÉÅ„Çß„ÉÉ„ÇØÂÆå‰∫ÜÔºö{filter_pass} ÈäòÊüÑ")
        except Exception:
            pass
    try:
        if stage_progress:
            stage_progress(25, filter_pass, None, None, None)
    except Exception:
        pass

    # ÂÄôË£úÁîüÊàêÔºàmarket_df „ÇíÂøÖË¶Å„Å®„Åô„ÇãÂÆüË£Ö„Å´ÈÖçÊÖÆÔºâ
    gen_fn = strategy.generate_candidates  # type: ignore[attr-defined]
    params = inspect.signature(gen_fn).parameters
    needs_market_df = "market_df" in params
    market_df_arg = market_df
    candidates_by_date: dict | None = None
    used_fast_path = False

    if str(system_name).lower() == "system4" and isinstance(prepared, dict):
        try:
            top_n_fast = int(get_settings(create_dirs=False).backtest.top_n_rank)
        except Exception:
            top_n_fast = 10

        spy_source: pd.DataFrame | None
        if isinstance(market_df_arg, pd.DataFrame) and not getattr(
            market_df_arg, "empty", False
        ):
            spy_source = market_df_arg.copy()
        else:
            maybe_spy = prepared.get("SPY")
            spy_source = (
                maybe_spy.copy()
                if isinstance(maybe_spy, pd.DataFrame)
                and not getattr(maybe_spy, "empty", True)
                else None
            )
        try:
            spy_with_ind = get_spy_with_indicators(spy_source)
        except Exception:
            spy_with_ind = None
        if spy_with_ind is not None and not getattr(spy_with_ind, "empty", True):
            spy_norm = _normalize_daily_index(spy_with_ind)
        else:
            spy_norm = None

        fast_path_message: str | None = None
        gate_state = _make_spy_gate(spy_norm)
        if gate_state is None:
            fast_path_message = "‚ö†Ô∏è System4 fast path: SPY„Éá„Éº„Çø‰∏çË∂≥„ÅÆ„Åü„ÇÅÂæìÊù•ÁµåË∑Ø„Å∏„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ„Åó„Åæ„Åô"
        elif gate_state is False:
            used_fast_path = True
            candidates_by_date = {}
            if spy_norm is not None:
                market_df = spy_norm
                market_df_arg = spy_norm
            fast_path_message = "üö´ System4 fast path: SPY„ÅåSMA200„Çí‰∏ãÂõû„Çã„Åü„ÇÅÂÄôË£ú„ÅØ0‰ª∂„Åß„Åô"
        else:
            fast_candidates = _collect_candidates_for_today(
                prepared,
                spy_df=spy_norm,
                top_n=top_n_fast,
            )
            if fast_candidates is None:
                fast_path_message = "‚ö†Ô∏è System4 fast path: ÂøÖË¶ÅÂàó‰∏çË∂≥„ÅÆ„Åü„ÇÅÂæìÊù•ÁµåË∑Ø„Å∏„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ„Åó„Åæ„Åô"
            else:
                used_fast_path = True
                candidates_by_date = fast_candidates
                if spy_norm is not None:
                    market_df = spy_norm
                    market_df_arg = spy_norm
                fast_path_message = "‚ö° System4 fast path: SPY„Ç≤„Éº„ÉàÈÄöÈÅé„ÅÆËªΩÈáèÊäΩÂá∫„ÇíÈÅ©Áî®„Åó„Åæ„Åó„Åü"

        if fast_path_message and log_callback:
            try:
                log_callback(fast_path_message)
            except Exception:
                pass

    if not used_fast_path:
        if needs_market_df and system_name == "system4":
            needs_fallback = market_df_arg is None or getattr(
                market_df_arg, "empty", False
            )
            if needs_fallback and isinstance(prepared, dict):
                maybe_spy = prepared.get("SPY")
                if isinstance(maybe_spy, pd.DataFrame) and not getattr(
                    maybe_spy, "empty", True
                ):
                    market_df_arg = maybe_spy
                    needs_fallback = False
            if needs_fallback:
                try:
                    cached_spy = get_spy_with_indicators()
                except Exception:
                    cached_spy = None
                if cached_spy is not None and not getattr(cached_spy, "empty", True):
                    market_df_arg = cached_spy
                    market_df = cached_spy
                    if log_callback:
                        try:
                            log_callback("üõü System4: SPY„Éá„Éº„Çø„Çí„Ç≠„É£„ÉÉ„Ç∑„É•„Åã„ÇâË£úÂÆå„Åó„Åæ„Åó„Åü")
                        except Exception:
                            pass
            if market_df_arg is None or getattr(market_df_arg, "empty", False):
                if log_callback:
                    try:
                        log_callback(
                            "‚ö†Ô∏è System4: SPY„Éá„Éº„Çø„ÅåË¶ã„Å§„Åã„Çâ„Å™„ÅÑ„Åü„ÇÅÂÄôË£úÊäΩÂá∫„Çí„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åô"
                        )
                    except Exception:
                        pass
                try:
                    if stage_progress:
                        stage_progress(75, filter_pass, None, None, None)
                        stage_progress(100, filter_pass, None, 0, 0)
                except Exception:
                    pass
                return _empty_today_signals_frame()
        if log_callback:
            try:
                log_callback(f"üß© „Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó„ÉÅ„Çß„ÉÉ„ÇØÈñãÂßãÔºö{filter_pass} ÈäòÊüÑ")
            except Exception:
                pass
        t1 = _t.time()
        if needs_market_df and market_df_arg is not None:
            market_df = market_df_arg
            candidates_by_date, _ = gen_fn(
                prepared,
                market_df=market_df_arg,
                progress_callback=progress_callback,
                log_callback=log_callback,
            )
        elif needs_market_df:
            candidates_by_date, _ = gen_fn(
                prepared,
                progress_callback=progress_callback,
                log_callback=log_callback,
            )
        else:
            candidates_by_date, _ = gen_fn(
                prepared,
                progress_callback=progress_callback,
                log_callback=log_callback,
            )
        try:
            if log_callback:
                em, es = divmod(int(max(0, _t.time() - t1)), 60)
                log_callback(f"‚è±Ô∏è „Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó/ÂÄôË£úÊäΩÂá∫ ÂÆå‰∫ÜÔºàÁµåÈÅé {em}ÂàÜ{es}ÁßíÔºâ")
        except Exception:
            pass
    else:
        if log_callback:
            try:
                log_callback("‚è±Ô∏è „Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó/ÂÄôË£úÊäΩÂá∫ ÂÆå‰∫ÜÔºàËªΩÈáèÁµåË∑ØÔºâ")
            except Exception:
                pass

    # „Çª„ÉÉ„Éà„Ç¢„ÉÉ„ÉóÈÄöÈÅé‰ª∂Êï∞ÔºàNYSE„Ç´„É¨„É≥„ÉÄ„Éº„ÅÆÂâçÂñ∂Ê•≠Êó•„ÇíÂÑ™ÂÖà„ÄÇÁÑ°„Åë„Çå„Å∞ÊúÄÁµÇË°åÔºâ
    try:
        prev_trading_day = get_latest_nyse_trading_day(
            pd.Timestamp(today) - pd.Timedelta(days=1)
        )

        def _last_row(x: pd.DataFrame) -> pd.Series | None:
            try:
                if "Date" in x.columns:
                    dt_vals = (
                        pd.to_datetime(x["Date"], errors="coerce")
                        .dt.normalize()
                        .to_numpy()
                    )
                    mask = dt_vals == prev_trading_day
                    rows = x.loc[mask]
                else:
                    idx_vals = (
                        pd.to_datetime(x.index, errors="coerce")
                        .normalize()
                        .to_numpy()
                    )
                    mask = idx_vals == prev_trading_day
                    rows = x.loc[mask]
                if len(rows) == 0:
                    rows = x.tail(1)
                if len(rows) == 0:
                    return None
                return rows.iloc[-1]
            except Exception:
                return None

        if isinstance(prepared, dict):
            items = list(prepared.items())
        elif isinstance(prepared, pd.DataFrame):
            items = [("", prepared)]
        else:
            items = []
        latest_rows: dict[str, pd.Series] = {}
        for sym, df in items:
            if df is None or getattr(df, "empty", True):
                continue
            row = _last_row(df)
            if row is None:
                continue
            latest_rows[str(sym)] = row

        def _count_if(rows: list[pd.Series], fn: Callable[[pd.Series], bool]) -> int:
            cnt = 0
            for row in rows:
                try:
                    if fn(row):
                        cnt += 1
                except Exception:
                    continue
            return cnt

        rows_list = list(latest_rows.values())
        name = str(system_name).lower()
        setup_pass = 0

        if name == "system1":
            filtered_rows = [r for r in rows_list if bool(r.get("filter"))]

            def _sma_ok(row: pd.Series) -> bool:
                try:
                    return float(row.get("SMA25", 0)) > float(row.get("SMA50", 0))
                except Exception:
                    return False

            sma_pass = _count_if(filtered_rows, _sma_ok)
            spy_source = market_df if market_df is not None else None
            try:
                spy_df = get_spy_with_indicators(spy_source)
            except Exception:
                spy_df = None

            spy_gate: int | None
            try:
                if spy_df is None or getattr(spy_df, "empty", True):
                    spy_gate = None
                else:
                    last_row = spy_df.iloc[-1]
                    close_val = float(last_row.get("Close", float("nan")))
                    sma_val = float(last_row.get("SMA100", float("nan")))
                    if np.isnan(close_val) or np.isnan(sma_val):
                        spy_gate = None
                    else:
                        spy_gate = 1 if close_val > sma_val else 0
            except Exception:
                spy_gate = None

            setup_pass = sma_pass if spy_gate != 0 else 0

            if log_callback:
                spy_label = "-" if spy_gate is None else str(int(spy_gate))
                try:
                    log_callback(
                        "üß© system1„Çª„ÉÉ„Éà„Ç¢„ÉÉ„ÉóÂÜÖË®≥: "
                        + f"„Éï„Ç£„É´„ÇøÈÄöÈÅé={filter_pass}, SPY>SMA100: {spy_label}, "
                        + f"SMA25>SMA50: {sma_pass}"
                    )
                except Exception:
                    pass
        elif name == "system2":
            def _rsi_ok(row: pd.Series) -> bool:
                try:
                    return float(row.get("RSI3", 0)) > 90
                except Exception:
                    return False

            def _two_up_ok(row: pd.Series) -> bool:
                return bool(row.get("TwoDayUp"))

            filtered_rows = [r for r in rows_list if bool(r.get("filter"))]
            rsi_pass = _count_if(filtered_rows, _rsi_ok)
            two_up_pass = _count_if(
                filtered_rows, lambda r: _rsi_ok(r) and _two_up_ok(r)
            )
            setup_pass = two_up_pass
            if log_callback:
                try:
                    log_callback(
                        "üß© system2„Çª„ÉÉ„Éà„Ç¢„ÉÉ„ÉóÂÜÖË®≥: "
                        + f"„Éï„Ç£„É´„ÇøÈÄöÈÅé={filter_pass}, RSI3>90: {rsi_pass}, "
                        + f"TwoDayUp: {two_up_pass}"
                    )
                except Exception:
                    pass
        elif name == "system3":
            filtered_rows = [r for r in rows_list if bool(r.get("filter"))]

            def _close_ok(row: pd.Series) -> bool:
                try:
                    return float(row.get("Close", 0)) > float(row.get("SMA150", 0))
                except Exception:
                    return False

            def _drop_ok(row: pd.Series) -> bool:
                try:
                    return float(row.get("Drop3D", 0)) >= 0.125
                except Exception:
                    return False

            close_pass = _count_if(filtered_rows, _close_ok)
            drop_pass = _count_if(
                filtered_rows, lambda r: _close_ok(r) and _drop_ok(r)
            )
            setup_pass = drop_pass
            if log_callback:
                try:
                    log_callback(
                        "üß© system3„Çª„ÉÉ„Éà„Ç¢„ÉÉ„ÉóÂÜÖË®≥: "
                        + f"„Éï„Ç£„É´„ÇøÈÄöÈÅé={filter_pass}, Close>SMA150: {close_pass}, "
                        + f"3Êó•‰∏ãËêΩÁéá>=12.5%: {drop_pass}"
                    )
                except Exception:
                    pass
        elif name == "system4":
            def _above_sma(row: pd.Series) -> bool:
                try:
                    return bool(row.get("filter")) and (
                        float(row.get("Close", 0)) > float(row.get("SMA200", 0))
                    )
                except Exception:
                    return False

            above_sma = _count_if(rows_list, _above_sma)
            setup_pass = above_sma
            if log_callback:
                try:
                    log_callback(
                        "üß© system4„Çª„ÉÉ„Éà„Ç¢„ÉÉ„ÉóÂÜÖË®≥: "
                        + f"„Éï„Ç£„É´„ÇøÈÄöÈÅé={filter_pass}, Close>SMA200: {above_sma}"
                    )
                except Exception:
                    pass
        elif name == "system5":
            threshold_label = format_atr_pct_threshold_label()
            s5_total = len(rows_list)
            s5_av = 0
            s5_dv = 0
            s5_atr = 0
            for row in rows_list:
                try:
                    av_val = row.get("AvgVolume50")
                    if av_val is None or pd.isna(av_val) or float(av_val) <= 500_000:
                        continue
                    s5_av += 1
                    dv_val = row.get("DollarVolume50")
                    if dv_val is None or pd.isna(dv_val) or float(dv_val) <= 2_500_000:
                        continue
                    s5_dv += 1
                    atr_pct_val = row.get("ATR_Pct")
                    if (
                        atr_pct_val is not None
                        and not pd.isna(atr_pct_val)
                        and float(atr_pct_val) > DEFAULT_ATR_PCT_THRESHOLD
                    ):
                        s5_atr += 1
                except Exception:
                    continue
            if log_callback:
                try:
                    log_callback(
                        "üß™ system5ÂÜÖË®≥: "
                        + f"ÂØæË±°={s5_total}, AvgVol50>500k: {s5_av}, "
                        + f"DV50>2.5M: {s5_dv}, {threshold_label}: {s5_atr}"
                    )
                except Exception:
                    pass

            def _price_ok(row: pd.Series) -> bool:
                try:
                    return bool(row.get("filter")) and (
                        float(row.get("Close", 0))
                        > float(row.get("SMA100", 0)) + float(row.get("ATR10", 0))
                    )
                except Exception:
                    return False

            def _adx_ok(row: pd.Series) -> bool:
                try:
                    return float(row.get("ADX7", 0)) > 55
                except Exception:
                    return False

            def _rsi_ok(row: pd.Series) -> bool:
                try:
                    return float(row.get("RSI3", 100)) < 50
                except Exception:
                    return False

            price_pass = _count_if(rows_list, _price_ok)
            adx_pass = _count_if(rows_list, lambda r: _price_ok(r) and _adx_ok(r))
            rsi_pass = _count_if(
                rows_list, lambda r: _price_ok(r) and _adx_ok(r) and _rsi_ok(r)
            )
            setup_pass = rsi_pass
            if log_callback:
                try:
                    log_callback(
                        "üß© system5„Çª„ÉÉ„Éà„Ç¢„ÉÉ„ÉóÂÜÖË®≥: "
                        + f"„Éï„Ç£„É´„ÇøÈÄöÈÅé={filter_pass}, Close>SMA100+ATR10: {price_pass}, "
                        + f"ADX7>55: {adx_pass}, RSI3<50: {rsi_pass}"
                    )
                except Exception:
                    pass
        elif name == "system6":
            filtered_rows = [r for r in rows_list if bool(r.get("filter"))]

            def _ret_ok(row: pd.Series) -> bool:
                try:
                    return float(row.get("Return6D", 0)) > 0.20
                except Exception:
                    return False

            def _up_two(row: pd.Series) -> bool:
                return bool(row.get("UpTwoDays"))

            ret_pass = _count_if(filtered_rows, _ret_ok)
            up_pass = _count_if(filtered_rows, lambda r: _ret_ok(r) and _up_two(r))
            setup_pass = up_pass
            if log_callback:
                try:
                    msg = (
                        "üß© system6„Çª„ÉÉ„Éà„Ç¢„ÉÉ„ÉóÂÜÖË®≥: "
                        f"„Éï„Ç£„É´„ÇøÈÄöÈÅé={filter_pass}, "
                        f"Return6D>20%: {ret_pass}, "
                        f"UpTwoDays: {up_pass}"
                    )
                    log_callback(msg)
                except Exception:
                    pass
        elif name == "system7":
            spy_present = 1 if "SPY" in latest_rows else 0
            setup_pass = spy_present
            if log_callback:
                try:
                    msg = f"üß© system7„Çª„ÉÉ„Éà„Ç¢„ÉÉ„ÉóÂÜÖË®≥: SPYÂ≠òÂú®={spy_present}"
                    if spy_present:
                        try:
                            val = latest_rows.get("SPY", pd.Series())
                            if isinstance(val, pd.Series):
                                setup_flag = bool(val.get("setup", 0))
                            else:
                                setup_flag = False
                            msg += f", setup={int(setup_flag)}"
                        except Exception:
                            pass
                    log_callback(msg)
                except Exception:
                    pass
        else:
            setup_pass = _count_if(
                rows_list,
                lambda r: bool(r.get("setup")) if "setup" in r else False,
            )

        try:
            setup_pass = int(setup_pass)
        except Exception:
            setup_pass = 0
    except Exception:
        setup_pass = 0
    try:
        if stage_progress:
            stage_progress(50, filter_pass, setup_pass, None, None)
    except Exception:
        pass
    # „Éà„É¨„Éº„ÉâÂÄôË£ú‰ª∂Êï∞ÔºàÂΩìÊó•„ÅÆ„ÅøÔºâ‚Üí UIË°®Á§∫„ÅØÊúÄÂ§ß„Éù„Ç∏„Ç∑„Éß„É≥Êï∞„Å´Âêà„Çè„Åõ„Å¶‰∏äÈôê10„Å´‰∏∏„ÇÅ„Çã
    # ÂÄôË£ú„Ç≠„ÉºÂûã„ÅÆ„ÇÜ„Çâ„ÅéÔºàstr/date/TimestampÔºâ„ÇíÂê∏Âèé„Åô„Çã„Åü„ÇÅ„ÄÅ
    # Ê≠£Ë¶èÂåñTimestamp‚ÜíÂÖÉ„Ç≠„Éº„ÅÆ„Éû„ÉÉ„Éó„Çí‰ΩúÊàê„Åó„Å¶„Åã„ÇâÈÅ∏Êäû„ÉªÂèÇÁÖß„Åô„Çã
    try:
        key_map: dict[pd.Timestamp, object] = {}
        cand_keys = list((candidates_by_date or {}).keys())
        for _k in cand_keys:
            try:
                _raw_ts = pd.to_datetime(_k, errors="coerce")
                if pd.isna(_raw_ts):
                    continue
                _ts = pd.Timestamp(_raw_ts)
                if getattr(_ts, "tzinfo", None) is not None:
                    try:
                        _ts = _ts.tz_localize(None)
                    except Exception:
                        try:
                            _ts = pd.Timestamp(
                                _ts.to_pydatetime().replace(tzinfo=None)
                            )
                        except Exception:
                            continue
                _ts = _ts.normalize()
                if _ts not in key_map:
                    key_map[_ts] = _k
            except Exception:
                continue
        candidate_dates = sorted(list(key_map.keys()), reverse=True)
    except Exception:
        key_map = {}
        candidate_dates = []

    target_date: pd.Timestamp | None = None
    fallback_reason: str | None = None

    def _collect_recent_days(
        anchor: pd.Timestamp | None, count: int
    ) -> list[pd.Timestamp]:
        if anchor is None or count <= 0:
            return []
        out: list[pd.Timestamp] = []
        seen: set[pd.Timestamp] = set()
        cur = pd.Timestamp(anchor).normalize()
        while len(out) < count:
            if cur in seen:
                break
            out.append(cur)
            seen.add(cur)
            prev = get_latest_nyse_trading_day(cur - pd.Timedelta(days=1))
            prev = pd.Timestamp(prev).normalize()
            if prev >= cur:
                break
            cur = prev
        return out

    try:
        primary_days = _collect_recent_days(today, 3)
        for dt in primary_days:
            if dt in candidate_dates:
                target_date = dt
                break

        if target_date is None:
            try:
                settings = get_settings(create_dirs=False)
                cfg = getattr(settings, "cache", None)
                rolling_cfg = getattr(cfg, "rolling", None)
                max_stale = getattr(
                    rolling_cfg,
                    "max_staleness_days",
                    getattr(rolling_cfg, "max_stale_days", 2),
                )
                stale_limit = int(max_stale)
            except Exception:
                stale_limit = 2
            fallback_window = max(len(primary_days), stale_limit + 3)
            extended_days = _collect_recent_days(today, fallback_window)
            for dt in extended_days:
                if dt in candidate_dates:
                    target_date = dt
                    if dt not in primary_days:
                        fallback_reason = "recent"
                    break

        if target_date is None and candidate_dates:
            today_norm = (
                pd.Timestamp(today).normalize() if today is not None else None
            )
            past_candidates = [
                d
                for d in candidate_dates
                if today_norm is None or d <= today_norm
            ]
            if past_candidates:
                target_date = max(past_candidates)
                if fallback_reason is None:
                    fallback_reason = "latest_past"
            else:
                target_date = max(candidate_dates)
                if fallback_reason is None:
                    fallback_reason = "latest_any"

        if log_callback:
            try:
                _cands_str = ", ".join([str(d.date()) for d in candidate_dates[:5]])
                _search_str = ", ".join([str(d.date()) for d in primary_days])
                _chosen = str(target_date.date()) if target_date is not None else "None"
                fallback_msg = ""
                if fallback_reason:
                    fallback_labels = {
                        "recent": "Áõ¥ËøëÂñ∂Ê•≠Êó•„Å´ÂÄôË£ú„ÅåÁÑ°„ÅÑ„Åü„ÇÅÈÅéÂéªÊó•„ÇíÊé°Áî®",
                        "latest_past": "Êé¢Á¥¢ÁØÑÂõ≤Â§ñ„ÅÆÊúÄÊñ∞ÈÅéÂéªÊó•„ÇíÊé°Áî®",
                        "latest_any": "Êú™Êù•Êó•„Åó„ÅãÂ≠òÂú®„Åó„Å™„ÅÑ„Åü„ÇÅÂÄôË£úÊúÄÁµÇÊó•„ÇíÊé°Áî®",
                    }
                    label = fallback_labels.get(fallback_reason, fallback_reason)
                    fallback_msg = f" | „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ: {label}"
                log_callback(
                    "üóìÔ∏è ÂÄôË£úÊó•ÔºàÊúÄÊñ∞‰∏ä‰ΩçÔºâ: "
                    f"{_cands_str} | Êé¢Á¥¢È†Ü: {_search_str} | Êé°Áî®: {_chosen}{fallback_msg}"
                )
            except Exception:
                pass
    except Exception:
        target_date = None
        fallback_reason = None
    try:
        if target_date is not None and target_date in key_map:
            orig_key = key_map[target_date]
            total_candidates_today = len(
                (candidates_by_date or {}).get(orig_key, []) or []
            )
        else:
            total_candidates_today = 0
    except Exception:
        total_candidates_today = 0
    # UI„ÅÆTRDlist„ÅØÂêÑsystem„ÅÆÊúÄÂ§ß„Éù„Ç∏„Ç∑„Éß„É≥Êï∞„ÇíË∂Ö„Åà„Å™„ÅÑ„Çà„ÅÜ„Å´Ë°®Á§∫
    try:
        _max_pos_ui = int(get_settings(create_dirs=False).risk.max_positions)
    except Exception:
        _max_pos_ui = 10
    if total_candidates_today and _max_pos_ui > 0:
        total_candidates_today = min(int(total_candidates_today), int(_max_pos_ui))
    try:
        if stage_progress:
            stage_progress(75, filter_pass, setup_pass, total_candidates_today, None)
    except Exception:
        pass
    if log_callback:
        try:
            log_callback(f"üß© „Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó„ÉÅ„Çß„ÉÉ„ÇØÂÆå‰∫ÜÔºö{setup_pass} ÈäòÊüÑ")
            # Ë™§Ëß£ÂõûÈÅø: „Åì„Åì„Åß„ÅÆ‰ª∂Êï∞„ÅØ„ÄéÂÄôË£úÁîüÊàê„ÅÆÊØçÈõÜÂõ£Ôºà„Çª„ÉÉ„Éà„Ç¢„ÉÉ„ÉóÈÄöÈÅéÔºâ„Äè
            log_callback(f"üßÆ ÂÄôË£úÁîüÊàêÂÖÉÔºà„Çª„ÉÉ„Éà„Ç¢„ÉÉ„ÉóÈÄöÈÅéÔºâÔºö{setup_pass} ÈäòÊüÑ")
            # TRDlist Áõ∏ÂΩìÔºàÁõ¥ËøëÂñ∂Ê•≠Êó•ÊôÇÁÇπ„ÅÆÂÄôË£úÊï∞„ÄÇÊúÄÂ§ß{_max_pos_ui}„Å´‰∏∏„ÇÅÔºâ
            log_callback(
                f"üßÆ TRDlistÁõ∏ÂΩìÔºàÁõ¥ËøëÂñ∂Ê•≠Êó•ÊôÇÁÇπ„ÅÆÂÄôË£úÊï∞ÔºâÔºö{total_candidates_today} ÈäòÊüÑ"
            )
        except Exception:
            pass

    if not candidates_by_date:
        return _empty_today_signals_frame()

    # ÂΩìÊó•„Åæ„Åü„ÅØÁõ¥ËøëÈÅéÂéªÊó•„ÅÆÂÄôË£ú„ÅÆ„ÅøÊäΩÂá∫
    if target_date is not None and target_date in key_map:
        orig_key2 = key_map[target_date]
        today_candidates = cast(
            list[dict], candidates_by_date.get(orig_key2, [])
        )
    else:
        today_candidates = cast(list[dict], [])
    if not today_candidates:
        return _empty_today_signals_frame()
    rows: list[TodaySignal] = []
    for c in today_candidates:
        sym = c.get("symbol")
        if not sym or sym not in prepared:
            continue
        df = prepared[sym]
        comp = _compute_entry_stop(strategy, df, c, side)
        if not comp:
            continue
        entry, stop = comp
        skey, sval, _asc = _score_from_candidate(system_name, c)

        # System1 „ÅØ ROC200 „ÇíÂøÖ„Åö„Çπ„Ç≥„Ç¢„Å´Êé°Áî®„Åß„Åç„Çã„Çà„ÅÜÂ†ÖÁâ¢Âåñ
        try:
            if (system_name == "system1") and (
                skey is None or str(skey).upper() != "ROC200"
            ):
                skey = "ROC200"
        except Exception:
            pass

        # signal Êó•ÔºàÈÄöÂ∏∏„ÅØ entry_date „ÅÆÂâçÂñ∂Ê•≠Êó•„ÇíÊÉ≥ÂÆöÔºâ
        signal_date_ts: pd.Timestamp | None = None
        try:
            # candidate["Date"] „Åå„ÅÇ„Çå„Å∞ÂÑ™ÂÖà
            if "Date" in c and c.get("Date") is not None:
                date_arg: Any = c.get("Date")
                tmp = pd.to_datetime(date_arg, errors="coerce")
                if not pd.isna(tmp):
                    signal_date_ts = pd.Timestamp(tmp).normalize()
        except Exception:
            # „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ„ÅØÂæåÊÆµ„ÅÆ entry_date Ë£úÂÆå„Å´‰ªª„Åõ„Çã
            pass
        if signal_date_ts is None:
            try:
                ed_arg: Any = c.get("entry_date")
                ed = pd.to_datetime(ed_arg, errors="coerce")
                if isinstance(ed, pd.Timestamp) and not pd.isna(ed):
                    # „Ç®„É≥„Éà„É™„ÉºÊó•„ÅÆÂâç„ÄåNYSEÂñ∂Ê•≠Êó•„Äç„ÇíÊé®ÂÆö
                    signal_date_ts = get_latest_nyse_trading_day(
                        pd.Timestamp(ed).normalize() - pd.Timedelta(days=1)
                    )
            except Exception:
                signal_date_ts = None

        # Ê¨†Êêç„Çπ„Ç≥„Ç¢„ÅÆË£úÂÆåÔºà„Åæ„ÅöÂÄ§„ÄÅÊ¨°„Å´È†Ü‰ΩçÔºâ
        rank_val: int | None = None
        total_for_rank: int = 0
        if skey is not None:
            # 1) Ê¨†Êêç„Å™„Çâ prepared „Åã„ÇâÂêåÊó•ÂÄ§„ÇíË£úÂÆå
            if sval is None or (isinstance(sval, float) and pd.isna(sval)):
                try:
                    if signal_date_ts is not None:
                        xdf = prepared[sym]
                        if "Date" in xdf.columns:
                            dt_vals = (
                                pd.to_datetime(xdf["Date"], errors="coerce")
                                .dt.normalize()
                                .to_numpy()
                            )
                        else:
                            dt_vals = (
                                pd.to_datetime(xdf.index, errors="coerce")
                                .normalize()
                                .to_numpy()
                            )
                        mask = dt_vals == signal_date_ts
                        row = xdf.loc[mask]
                        if not row.empty and skey in row.columns:
                            _v = row.iloc[0][skey]
                            if _v is not None and not pd.isna(_v):
                                sval = float(_v)
                except Exception:
                    pass
            # System1 Áî®„ÅÆ„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÔºàÂâçÊó•„ÅåË¶ã„Å§„Åã„Çâ„Å™„ÅÑÂ†¥Âêà„ÅØÁõ¥ËøëÂÄ§Ôºâ
            if (system_name == "system1") and (
                sval is None or (isinstance(sval, float) and pd.isna(sval))
            ):
                try:
                    if skey in prepared[sym].columns:
                        _v = pd.Series(prepared[sym][skey]).dropna().tail(1).iloc[0]
                        sval = float(_v)
                except Exception:
                    pass

            # 2) ÂÄ§„Åå„Åæ„Å†Ê¨†Êêç„Å™„Çâ„ÄÅÂêåÊó•ÂÖ®ÈäòÊüÑ„ÅÆÈ†Ü‰Ωç„ÇíÁÆóÂá∫„Åó„Å¶„Çπ„Ç≥„Ç¢„Å´Ë®≠ÂÆö
            try:
                if signal_date_ts is not None:
                    vals: list[tuple[str, float]] = []
                    for psym, pdf in prepared.items():
                        try:
                            if "Date" in pdf.columns:
                                dt_vals = (
                                    pd.to_datetime(pdf["Date"], errors="coerce")
                                    .dt.normalize()
                                    .to_numpy()
                                )
                            else:
                                dt_vals = (
                                    pd.to_datetime(pdf.index, errors="coerce")
                                    .normalize()
                                    .to_numpy()
                                )
                            mask = dt_vals == signal_date_ts
                            row = pdf.loc[mask]
                            if not row.empty and skey in row.columns:
                                v = row.iloc[0][skey]
                                if v is not None and not pd.isna(v):
                                    vals.append((psym, float(v)))
                        except Exception:
                            continue
                    total_for_rank = len(vals)
                    if total_for_rank:
                        # ‰∏¶„Å≥È†Ü: system „ÅÆÊòáÈôçÈ†ÜÊé®ÂÆö„Å´Âêà„Çè„Åõ„ÇãÔºàROC200 „Å™„Å©„ÅØÈôçÈ†ÜÔºâ
                        reverse = not _asc
                        # ÂÄ§„ÅåÂêå‰∏Ä„ÅÆ„Å®„Åç„ÅØ„Ç∑„É≥„Éú„É´„ÅßÂÆâÂÆö„ÇΩ„Éº„Éà
                        vals_sorted = sorted(
                            vals, key=lambda t: (t[1], t[0]), reverse=reverse
                        )
                        # Ëá™ÈäòÊüÑ„ÅÆÈ†Ü‰Ωç„ÇíÊ±∫ÂÆö
                        symbols_sorted = [s for s, _ in vals_sorted]
                        if sym in symbols_sorted:
                            rank_val = symbols_sorted.index(sym) + 1
                        # „Çπ„Ç≥„Ç¢„ÅåÊ¨†Êêç„Å™„ÇâÈ†Ü‰Ωç„Çí„Åù„ÅÆ„Åæ„Åæ„Çπ„Ç≥„Ç¢„Å´Êé°Áî®
                        if sval is None or (isinstance(sval, float) and pd.isna(sval)):
                            if rank_val is not None:
                                sval = float(rank_val)
            except Exception:
                pass

        # ÈÅ∏ÂÆöÁêÜÁî±ÔºàÈ†Ü‰Ωç„ÇíÊúÄÂÑ™ÂÖà„ÄÅ„Å™„Åë„Çå„Å∞Á∞°ÊΩî„Åã„Å§„Ç∑„Çπ„ÉÜ„É†Âõ∫Êúâ„ÅÆÊñáË®ÄÔºâ
        reason_parts: list[str] = []
        # System1 „ÅØÊó•Êú¨Ë™û„Åß„ÄåROC200„Åån‰Ωç„ÅÆ„Åü„ÇÅ„Äç„Å´Áµ±‰∏ÄÔºàÈ†Ü‰Ωç„ÅåÂèñ„Çå„Å™„ÅÑÂ†¥Âêà„ÅÆ„ÅøÊ±éÁî®ÊñáË®ÄÔºâ
        if system_name == "system1":
            if rank_val is not None and int(rank_val) <= 10:
                reason_parts = [f"ROC200„Åå{int(rank_val)}‰Ωç„ÅÆ„Åü„ÇÅ"]
            else:
                reason_parts = ["ROC200„Åå‰∏ä‰Ωç„ÅÆ„Åü„ÇÅ"]
        elif system_name == "system2":
            if rank_val is not None and skey is not None:
                reason_parts = [f"{_label_for_score_key(skey)}„Åå{rank_val}‰Ωç„ÅÆ„Åü„ÇÅ"]
            else:
                reason_parts = ["„É¢„É°„É≥„Çø„É†„ÅåÂº∑„ÅèÈÅéÁÜ±„ÅÆ„Åü„ÇÅ"]
        elif system_name == "system3":
            if rank_val is not None and skey is not None:
                reason_parts = [f"{_label_for_score_key(skey)}„Åå{rank_val}‰Ωç„ÅÆ„Åü„ÇÅ"]
            else:
                reason_parts = ["„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£„ÅåÈ´ò„ÅèÊù°‰ª∂‰∏ÄËá¥„ÅÆ„Åü„ÇÅ"]
        elif system_name == "system4":
            if rank_val is not None:
                reason_parts = [f"RSI4„Åå{rank_val}‰ΩçÔºà‰ΩéÊ∞¥Ê∫ñÔºâ„ÅÆ„Åü„ÇÅ"]
            else:
                reason_parts = ["SPY‰∏äÊòáÂ±ÄÈù¢„ÅÆÊäº„ÅóÁõÆÂÄôË£ú„ÅÆ„Åü„ÇÅ"]
        elif system_name == "system5":
            if rank_val is not None and skey is not None:
                reason_parts = [f"{_label_for_score_key(skey)}„Åå{rank_val}‰Ωç„ÅÆ„Åü„ÇÅ"]
            else:
                reason_parts = ["ADX„ÅåÂº∑„Åè„ÄÅÂèçÁô∫ÊúüÂæÖ„ÅÆ„Åü„ÇÅ"]
        elif system_name == "system6":
            if rank_val is not None:
                reason_parts = [f"ÈÅéÂéª6Êó•È®∞ËêΩÁéá„Åå{rank_val}‰Ωç„ÅÆ„Åü„ÇÅ"]
            else:
                reason_parts = ["Áü≠Êúü‰∏ãËêΩ„Éà„É¨„É≥„ÉâÔºà„Ç∑„Éß„Éº„ÉàÔºâÊù°‰ª∂‰∏ÄËá¥„ÅÆ„Åü„ÇÅ"]
        elif system_name == "system7":
            # ATR50 „ÅØÊêçÂàá„ÇäË®àÁÆóÁî®„ÄÇÁêÜÁî±„ÅØ„Äå50Êó•ÂÆâÂÄ§Êõ¥Êñ∞„Äç„Å´ÈôêÂÆö„Åô„Çã„ÄÇ
            reason_parts = ["SPY„Åå50Êó•ÂÆâÂÄ§„ÇíÊõ¥Êñ∞„Åó„Åü„Åü„ÇÅÔºà„Éò„ÉÉ„Ç∏Ôºâ"]
        else:
            if skey is not None and rank_val is not None:
                if rank_val <= 10:
                    reason_parts = [f"{_label_for_score_key(skey)}„Åå{rank_val}‰Ωç„ÅÆ„Åü„ÇÅ"]
                else:
                    reason_parts = [f"rank={rank_val}/{total_for_rank}"]
            elif skey is not None:
                # ÂÄ§„ÅØÂéüÂâáÈùûË°®Á§∫ÔºàÂÜóÈï∑ÂõûÈÅøÔºâ„ÄÇÂøÖË¶ÅÊúÄÂ∞èÈôê„Å†„ÅëÁ§∫„Åô„ÄÇ
                try:
                    if sval is not None and not (
                        isinstance(sval, float) and pd.isna(sval)
                    ):
                        reason_parts.append("„Çπ„Ç≥„Ç¢Êù°‰ª∂„ÇíÊ∫Ä„Åü„Åó„Åü„Åü„ÇÅ")
                except Exception:
                    reason_parts.append("„Çπ„Ç≥„Ç¢Êù°‰ª∂„ÇíÊ∫Ä„Åü„Åó„Åü„Åü„ÇÅ")

        # fallback generic info
        if not reason_parts:
            reason_parts.append("Êù°‰ª∂‰∏ÄËá¥„ÅÆ„Åü„ÇÅ")

        reason_text = "; ".join(reason_parts)

        try:
            _ed_raw: Any = c.get("entry_date")
            _ed = pd.Timestamp(_ed_raw) if _ed_raw is not None else None
            if _ed is None or pd.isna(_ed):
                # entry_date „ÅåÊ¨†Êêç„Åô„ÇãÂÄôË£ú„ÅØÁÑ°Âäπ
                continue
            entry_date_norm = pd.Timestamp(_ed).normalize()
        except Exception:
            continue

        rows.append(
            TodaySignal(
                symbol=str(sym),
                system=system_name,
                side=side,
                signal_type=signal_type,
                entry_date=entry_date_norm,
                entry_price=float(entry),
                stop_price=float(stop),
                score_key=skey,
                # „Çπ„Ç≥„Ç¢„ÅØÂÄ§„Åå„ÅÇ„Çå„Å∞ÂÄ§„ÄÅÁÑ°„Åë„Çå„Å∞È†Ü‰ΩçÔºà‰∏äË®ò„ÅßË£úÂÆåÊ∏à„ÅøÔºâ
                score=(
                    None
                    if sval is None or (isinstance(sval, float) and pd.isna(sval))
                    else float(sval)
                ),
                reason=reason_text,
            )
        )

    if not rows:
        return pd.DataFrame(
            columns=[
                "symbol",
                "system",
                "side",
                "signal_type",
                "entry_date",
                "entry_price",
                "stop_price",
                "score_key",
                "score",
            ]
        )

    out = pd.DataFrame([r.__dict__ for r in rows])

    try:
        max_pos = int(get_settings(create_dirs=False).risk.max_positions)
    except Exception:
        max_pos = 10
    if max_pos > 0 and not out.empty:

        def _sort_val(row: pd.Series) -> float:
            sc = row.get("score")
            sk = row.get("score_key")
            if sc is None or (isinstance(sc, float) and pd.isna(sc)):
                return float("inf")
            return float(sc) if _asc_by_score_key(sk) else -float(sc)

        out["_sort_val"] = out.apply(_sort_val, axis=1)
        out = (
            out.sort_values("_sort_val")
            .head(max_pos)
            .drop(columns=["_sort_val"])
            .reset_index(drop=True)
        )
    final_count = len(out)

    try:
        if log_callback:
            log_callback(f"üßÆ „Éà„É¨„Éº„ÉâÂÄôË£úÈÅ∏ÂÆöÂÆå‰∫ÜÔºàÂΩìÊó•ÔºâÔºö{final_count} ÈäòÊüÑ")
    except Exception:
        pass
    try:
        if stage_progress:
            stage_progress(
                100, filter_pass, setup_pass, total_candidates_today, final_count
            )
    except Exception:
        pass
    return out


def run_all_systems_today(
    symbols: list[str] | None,
    *,
    slots_long: int | None = None,
    slots_short: int | None = None,
    capital_long: float | None = None,
    capital_short: float | None = None,
    save_csv: bool = False,
    csv_name_mode: str | None = None,
    notify: bool = True,
    log_callback: Callable[[str], None] | None = None,
    progress_callback: Callable[[int, int, str], None] | None = None,
    per_system_progress: Callable[[str, str], None] | None = None,
    symbol_data: dict[str, pd.DataFrame] | None = None,
    parallel: bool = False,
) -> tuple[pd.DataFrame, dict[str, pd.DataFrame]]:
    """scripts.run_all_systems_today.compute_today_signals „ÅÆ„É©„ÉÉ„Éë„Éº„ÄÇ"""
    from scripts.run_all_systems_today import compute_today_signals as _compute

    return _compute(
        symbols,
        slots_long=slots_long,
        slots_short=slots_short,
        capital_long=capital_long,
        capital_short=capital_short,
        save_csv=save_csv,
        csv_name_mode=csv_name_mode,
        notify=notify,
        log_callback=log_callback,
        progress_callback=progress_callback,
        per_system_progress=per_system_progress,
        symbol_data=symbol_data,
        parallel=parallel,
    )


compute_today_signals = run_all_systems_today


__all__ = [
    "get_today_signals_for_strategy",
    "LONG_SYSTEMS",
    "SHORT_SYSTEMS",
    "run_all_systems_today",
    "compute_today_signals",
]
