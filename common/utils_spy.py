from __future__ import annotations

import os
from datetime import time as dtime
from pathlib import Path
from collections.abc import Iterable
import sys

import pandas as pd
import pandas_market_calendars as mcal
import streamlit as st
from ta.trend import SMAIndicator

from common.i18n import tr
from config.settings import get_settings


def _ui_enabled() -> bool:
    """Return True when running under Streamlit UI.

    Heuristic only: avoid querying Streamlit runtime context directly to prevent
    'missing ScriptRunContext' warnings. Prefer environment flag or command hint.
    """
    try:
        v = (os.getenv("STREAMLIT_SERVER_ENABLED") or "").strip().lower()
        if v in {"1", "true", "yes"}:
            return True
    except Exception:
        pass
    try:
        argv = " ".join(sys.argv).lower()
        if "streamlit" in argv:
            return True
    except Exception:
        pass
    return False


def _st_emit(kind: str, *args, **kwargs) -> None:
    """Safely emit Streamlit UI calls only when UI context is active.

    In CLI/batch runs, this becomes a no-op to avoid ScriptRunContext warnings.
    """
    if not _ui_enabled():
        return
    try:
        fn = getattr(st, kind, None)
        if callable(fn):
            fn(*args, **kwargs)
    except Exception:
        # Silently ignore UI errors in non-critical paths
        return


def _candidate_spy_paths(root: Path) -> list[Path]:
    """SPY.csv ã‚’æ¢ã™å€™è£œãƒ‘ã‚¹ã‚’è¿”ã™ã€‚

    ï¼ˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãªã©åºƒæœŸé–“ãŒå¿…è¦ãªå ´é¢ã§ã¯ base ã‚’å„ªå…ˆã—ã€
     å½“æ—¥ã‚·ã‚°ãƒŠãƒ«ãªã©ã§ã¯ rolling ã‚’å„ªå…ˆã™ã‚‹è¨­è¨ˆã ãŒã€
     æœ¬é–¢æ•°ã¯å˜ç´”ãªå€™è£œåˆ—æŒ™ã®ã¿ã‚’è¡Œã†ï¼‰
    å¤§æ–‡å­—å°æ–‡å­—ã®é•ã„ã‚‚å¸åã™ã‚‹ï¼ˆã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®ãŸã‚ï¼‰ã€‚
    """

    def _case_insensitive_find(dir_path: Path, name: str) -> Path | None:
        try:
            if not dir_path.exists():
                return None
            for fn in os.listdir(dir_path):
                if fn.lower() == name.lower():
                    return dir_path / fn
        except Exception:
            return None
        return None

    names = ("SPY.csv",)
    dirs: Iterable[Path] = (
        root / "base",
        root / "full",
        root / "rolling",
    )
    out: list[Path] = []
    for d in dirs:
        for nm in names:
            p = _case_insensitive_find(d, nm)
            if p is not None:
                out.append(p)
    return out


def _read_daily_csv_any_datecol(path: Path) -> pd.DataFrame:
    """æ—¥è¶³CSVã‚’ 'Date' ã¾ãŸã¯ 'date' ã„ãšã‚Œã§ã‚‚èª­ã¿è¾¼ã‚ã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚"""
    df = pd.read_csv(path)
    date_col = None
    if "Date" in df.columns:
        date_col = "Date"
    elif "date" in df.columns:
        date_col = "date"
    if date_col is None:
        raise ValueError("date/Date åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    df[date_col] = pd.to_datetime(df[date_col])
    df = df.sort_values(date_col).set_index(date_col)
    return df


def get_spy_data_cached_v2(folder: str = "data_cache", mode: str = "backtest"):
    """
    SPY.csv ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã‚€ã€‚
    - mode="backtest": data_cache/base â†’ data_cache/full_backup ã®é †ï¼ˆrolling ã¯æ¢ç´¢ã—ãªã„ï¼‰
    - mode="today": data_cache/rolling â†’ data_cache/base â†’ data_cache/full_backup ã®é †
    - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™
    """
    try:
        settings = get_settings(create_dirs=True)
        root = Path(settings.DATA_CACHE_DIR)
        full_dir = Path(getattr(settings.cache, "full_dir", root / "full_backup"))
        rolling_dir = Path(getattr(settings.cache, "rolling_dir", root / "rolling"))
    except Exception:
        root = Path(folder)
        full_dir = root / "full_backup"
        rolling_dir = root / "rolling"

    # æ¢ç´¢é †ã‚’ mode ã§åˆ‡ã‚Šæ›¿ãˆ
    base_dir = root / "base"
    mode_lower = str(mode).lower()
    if mode_lower == "today":
        search_dirs: list[Path] = [rolling_dir, base_dir, full_dir]
    else:
        # backtest: rolling ã¯æ¢ç´¢ã—ãªã„
        search_dirs = [base_dir, full_dir]

    def _find_case_insensitive(d: Path, name: str) -> Path | None:
        try:
            if not d.exists():
                return None
            for fn in os.listdir(d):
                if fn.lower() == name.lower():
                    return d / fn
        except Exception:
            return None
        return None

    path: Path | None = None
    for d in search_dirs:
        p = _find_case_insensitive(d, "SPY.csv")
        if p is not None:
            path = p
            break
    if path is None or not path.exists():
        _st_emit(
            "error", tr("âŒ SPY.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (base/full_backup/rolling ã‚’ç¢ºèª)")
        )
        return None

    # backtest æ™‚ã¯ full_backup ã®å­˜åœ¨ã‚’å¿…é ˆã¨ã—ã€ç„¡ã‘ã‚Œã°ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    if mode_lower != "today":
        has_full_backup = _find_case_insensitive(full_dir, "SPY.csv") is not None
        if not has_full_backup:
            try:
                _st_emit(
                    "error",
                    tr(
                        "âš  SPY ã® full_backup ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {p}",
                        p=str(full_dir / "SPY.csv"),
                    ),
                )
            except Exception:
                pass

    try:
        df = _read_daily_csv_any_datecol(Path(path))

        # ç›´è¿‘æƒ…å ±ã®è¡¨ç¤ºï¼ˆUIãŒç„¡ã„å ´é¢ã§ã¯ç„¡è¦–ã•ã‚Œã‚‹ï¼‰
        try:
            _st_emit(
                "write", tr("âœ… SPYã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€çµ‚æ—¥: {d}", d=str(df.index[-1].date()))
            )
        except Exception:
            pass

        # NYSE æœ€æ–°å–¶æ¥­æ—¥
        today = pd.Timestamp.today().normalize()
        latest_trading_day = get_latest_nyse_trading_day(today)
        try:
            _st_emit(
                "write", tr("ğŸ—“ï¸ ç›´è¿‘ã®NYSEå–¶æ¥­æ—¥: {d}", d=str(latest_trading_day.date()))
            )
        except Exception:
            pass

        # 1ã¤å‰ã®å–¶æ¥­æ—¥ï¼ˆå½“æ—¥å–¶æ¥­æ™‚é–“å¸¯ã®å½±éŸ¿ã‚’é¿ã‘ã‚‹ï¼‰
        try:
            nyse = mcal.get_calendar("NYSE")
            sched = nyse.schedule(
                start_date=today - pd.Timedelta(days=7),
                end_date=today,
            )
            valid = pd.to_datetime(sched.index).normalize()
            prev_trading_day = valid[-2] if len(valid) >= 2 else latest_trading_day
        except Exception:
            prev_trading_day = latest_trading_day

        # ç±³æ±éƒ¨æ™‚é–“ã‚’å–å¾—
        try:
            ny_time = pd.Timestamp.now(tz="America/New_York").time()
        except Exception:
            ny_time = dtime(18, 0)

        # å¤ã„å ´åˆã¯è­¦å‘Šã®ã¿è¡¨ç¤º
        if df.index[-1].normalize() < prev_trading_day and ny_time >= dtime(18, 0):
            try:
                _st_emit("warning", tr("âš  SPYã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå¤ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"))
            except Exception:
                pass
        else:
            try:
                _st_emit("write", tr("âœ… SPYã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯æœ‰åŠ¹"))
            except Exception:
                pass

        return df

    except Exception as e:
        _st_emit("error", tr("âŒ SPYèª­ã¿è¾¼ã¿å¤±æ•—: {e}", e=str(e)))
        return None


def _normalize_to_naive_day(ts: pd.Timestamp | None) -> pd.Timestamp:
    """Normalize timestamp to tz-naive midnight."""

    if ts is None:
        ts = pd.Timestamp.today()
    else:
        ts = pd.Timestamp(ts)
    tz = getattr(ts, "tzinfo", None)
    if tz is not None:
        try:
            ts = ts.tz_convert(None)
        except (TypeError, ValueError, AttributeError):
            try:
                ts = ts.tz_localize(None)
            except Exception:
                ts = pd.Timestamp(ts.to_pydatetime().replace(tzinfo=None))
    return ts.normalize()


def get_latest_nyse_trading_day(today: pd.Timestamp | None = None) -> pd.Timestamp:
    nyse = mcal.get_calendar("NYSE")
    today_naive = _normalize_to_naive_day(today)
    sched = nyse.schedule(
        start_date=today_naive - pd.Timedelta(days=7),
        end_date=today_naive + pd.Timedelta(days=1),
    )
    valid_days = pd.to_datetime(sched.index).normalize()
    return valid_days[valid_days <= today_naive].max()


def get_next_nyse_trading_day(current: pd.Timestamp | None = None) -> pd.Timestamp:
    """NYè¨¼åˆ¸å–å¼•æ‰€ã®ç¿Œå–¶æ¥­æ—¥ã‚’è¿”ã™ã€‚"""

    nyse = mcal.get_calendar("NYSE")
    current_naive = _normalize_to_naive_day(current)
    sched = nyse.schedule(
        start_date=current_naive,
        end_date=current_naive + pd.Timedelta(days=10),
    )
    valid_days = pd.to_datetime(sched.index).normalize()
    future_days = valid_days[valid_days > current_naive]
    if future_days.empty:
        raise ValueError("No upcoming NYSE trading day found")
    return future_days.min()


def resolve_signal_entry_date(base_date) -> pd.Timestamp | pd.NaT:
    """ã‚·ã‚°ãƒŠãƒ«æ—¥ã‹ã‚‰ç¿Œå–¶æ¥­æ—¥ï¼ˆå–å¼•äºˆå®šæ—¥ï¼‰ã‚’ç®—å‡ºã™ã‚‹ã€‚

    - base_date ãŒæ¬ æãƒ»å¤‰æ›ä¸å¯ã®å ´åˆã¯ NaT ã‚’è¿”ã™ã€‚
    - get_next_nyse_trading_day ã®çµæœã¯å¸¸ã« tz-naive ãªæ—¥ä»˜ã«æ­£è¦åŒ–ã™ã‚‹ã€‚
    """

    if base_date is None or (isinstance(base_date, float) and pd.isna(base_date)):
        return pd.NaT
    try:
        ts = pd.Timestamp(base_date)
    except Exception:
        return pd.NaT
    if pd.isna(ts):
        return pd.NaT
    ts = _normalize_to_naive_day(ts)
    try:
        entry_candidate = get_next_nyse_trading_day(ts)
    except Exception:
        return pd.NaT
    if pd.isna(entry_candidate):
        return pd.NaT
    entry_ts = pd.Timestamp(entry_candidate)
    try:
        entry_ts = entry_ts.tz_localize(None)
    except Exception:
        pass
    return entry_ts.normalize()


def get_spy_data_cached(folder: str = "data_cache"):
    """
    æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã® SPY ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿é–¢æ•°ã€‚
    - v2 ãƒªã‚¾ãƒ«ãƒã‚’ä½¿ç”¨ï¼ˆbacktest: baseâ†’full_backup, today: rollingâ†’baseâ†’full_backupï¼‰
    """
    # v2 å®Ÿè£…ã¸å§”è­²ï¼ˆæ¢ç´¢é †åˆ‡æ›¿ã¯ v2 ã«é›†ç´„ï¼‰
    try:
        return get_spy_data_cached_v2(folder)
    except Exception:
        # v2 å´ã«ä¸€æœ¬åŒ–ã™ã‚‹ãŸã‚ã€å¾“æ¥ã® data_cache ç›´ä¸‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯å»ƒæ­¢
        return get_spy_data_cached_v2(folder)


def get_spy_with_indicators(spy_df=None):
    """
    SPY ã« SMA100 / SMA200 ã‚’ä»˜ä¸ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯æˆ¦ç•¥å´ã§åˆ¤å®šã™ã‚‹ï¼‰
    """
    if spy_df is None:
        # ã‚ˆã‚Šå …ç‰¢ãª v2 ã‚’ä½¿ç”¨
        spy_df = get_spy_data_cached_v2()
    if spy_df is not None and not getattr(spy_df, "empty", True):
        # Close åˆ—åã®ã‚†ã‚‰ãã«å¯¾å¿œï¼ˆclose/AdjClose/adjusted_close ç­‰ï¼‰
        if "Close" not in spy_df.columns:
            if "close" in spy_df.columns:
                spy_df["Close"] = spy_df["close"]
            elif "AdjClose" in spy_df.columns:
                spy_df["Close"] = spy_df["AdjClose"]
            elif "adjclose" in spy_df.columns:
                spy_df["Close"] = spy_df["adjclose"]
            elif "adjusted_close" in spy_df.columns:
                spy_df["Close"] = spy_df["adjusted_close"]
            else:
                try:
                    _st_emit(
                        "warning",
                        tr(
                            "â—SPYã®çµ‚å€¤åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {cols}",
                            cols=str(list(spy_df.columns)),
                        ),
                    )
                except Exception:
                    pass
                return spy_df

        spy_df["SMA100"] = SMAIndicator(
            pd.to_numeric(spy_df["Close"], errors="coerce"),
            window=100,
        ).sma_indicator()
        spy_df["SMA200"] = SMAIndicator(
            pd.to_numeric(spy_df["Close"], errors="coerce"),
            window=200,
        ).sma_indicator()
    return spy_df
