# c:\Repos\quant_trading_system\common\ai_dashboard.py
"""
AIæ”¯æ´åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹ã€åˆ†æçµæœã€æœ€é©åŒ–ææ¡ˆã‚’å¯è¦–åŒ–
"""

import logging
from typing import Any, Dict

try:
    import numpy as np
    import plotly.graph_objects as go
    import streamlit as st

    HAS_PLOTTING = True
except ImportError:
    HAS_PLOTTING = False

from .ai_analysis import get_ai_analyzer

logger = logging.getLogger(__name__)


def render_ai_analysis_page() -> None:
    """AIæ”¯æ´åˆ†æãƒšãƒ¼ã‚¸ã®æç”»"""
    if not HAS_PLOTTING:
        st.error("ğŸ“Š AIåˆ†æè¡¨ç¤ºã«ã¯ plotly ã¨ streamlit ãŒå¿…è¦ã§ã™")
        st.code("pip install plotly streamlit", language="bash")
        return

    st.title("ğŸ¤– AIæ”¯æ´åˆ†æã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("æ©Ÿæ¢°å­¦ç¿’ã‚’ä½¿ã£ãŸç•°å¸¸æ¤œçŸ¥ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬ã€æœ€é©åŒ–ææ¡ˆ")

    try:
        ai_analyzer = get_ai_analyzer()

        # åˆ†æã‚µãƒãƒªãƒ¼å–å¾—
        analysis_summary = ai_analyzer.get_analysis_summary()

        # ã‚µãƒãƒªãƒ¼ã‚«ãƒ¼ãƒ‰è¡¨ç¤º
        render_ai_summary_cards(analysis_summary)

        # ã‚¿ãƒ–ã§æ©Ÿèƒ½ã‚’åˆ†å‰²
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹", "ğŸ” ç•°å¸¸æ¤œçŸ¥", "ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬", "ğŸ’¡ æœ€é©åŒ–ææ¡ˆ"])

        with tab1:
            render_model_status_tab(analysis_summary)

        with tab2:
            render_anomaly_detection_tab(analysis_summary)

        with tab3:
            render_performance_prediction_tab(analysis_summary)

        with tab4:
            render_optimization_suggestions_tab(analysis_summary)

    except Exception as e:
        st.error(f"AIåˆ†æã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"AIåˆ†æãƒšãƒ¼ã‚¸ã‚¨ãƒ©ãƒ¼: {e}")


def render_ai_summary_cards(summary: Dict[str, Any]) -> None:
    """AIã‚·ã‚¹ãƒ†ãƒ ã‚µãƒãƒªãƒ¼ã‚«ãƒ¼ãƒ‰ã®è¡¨ç¤º"""
    model_status = summary.get("model_status", {})
    data_collection = summary.get("data_collection", {})
    _analysis_capabilities = summary.get("capabilities", {})  # å°†æ¥æ‹¡å¼µç”¨ãƒ»æœªä½¿ç”¨ä¿æŒ

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        is_trained = model_status.get("is_trained", False)
        status_color = "ğŸŸ¢" if is_trained else "ğŸ”´"
        st.metric(
            label=f"{status_color} ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹",
            value="è¨“ç·´æ¸ˆã¿" if is_trained else "æœªè¨“ç·´",
            delta=f"ãƒ‡ãƒ¼ã‚¿: {model_status.get('training_data_count', 0)}ä»¶",
        )

    with col2:
        has_sklearn = model_status.get("has_sklearn", False)
        ml_color = "ğŸŸ¢" if has_sklearn else "ğŸŸ¡"
        st.metric(
            label=f"{ml_color} MLæ©Ÿèƒ½",
            value="åˆ©ç”¨å¯èƒ½" if has_sklearn else "åˆ¶é™ãƒ¢ãƒ¼ãƒ‰",
            delta="scikit-learn" if has_sklearn else "ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¨å¥¨",
        )

    with col3:
        total_records = data_collection.get("total_records", 0)
        collection_rate = data_collection.get("collection_rate", "0/1000")
        st.metric(
            label="ğŸ“Š ãƒ‡ãƒ¼ã‚¿åé›†",
            value=f"{total_records}ä»¶",
            delta=f"å®¹é‡: {collection_rate}",
        )

    with col4:
        current_analysis = summary.get("current_analysis", {})
        analysis_status = current_analysis.get("analysis_status", "N/A")
        status_emoji = "âœ…" if analysis_status == "OK" else "âš ï¸"
        st.metric(
            label=f"{status_emoji} åˆ†æçŠ¶æ…‹",
            value=analysis_status,
            delta=(
                current_analysis.get("timestamp", "").split("T")[1][:8] if current_analysis.get("timestamp") else None
            ),
        )


def render_model_status_tab(summary: Dict[str, Any]) -> None:
    """ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ã‚¿ãƒ–ã®æç”»"""
    st.subheader("ğŸ”§ æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹")

    model_status = summary.get("model_status", {})
    data_collection = summary.get("data_collection", {})
    capabilities = summary.get("analysis_capabilities", {})

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### ğŸ“Š ãƒ‡ãƒ¼ã‚¿åé›†çŠ¶æ³")

        total_records = data_collection.get("total_records", 0)
        max_records = 1000
        progress = min(total_records / max_records, 1.0)

        st.progress(progress)
        st.text(f"åé›†ãƒ‡ãƒ¼ã‚¿: {total_records}/{max_records} ä»¶")
        st.text(f"ç‰¹å¾´é‡æ•°: {data_collection.get('feature_count', 0)}")

        # ãƒ‡ãƒ¼ã‚¿åé›†ã®å¯è¦–åŒ–
        if total_records > 0:
            # æ¨¡æ“¬çš„ãªé€²æ—ã‚°ãƒ©ãƒ•
            days = list(range(max(1, total_records - 50), total_records + 1))
            cumulative_data = [min(i, total_records) for i in days]

            fig = go.Figure()
            fig.add_trace(
                go.Scatter(
                    x=days,
                    y=cumulative_data,
                    mode="lines+markers",
                    name="ãƒ‡ãƒ¼ã‚¿è“„ç©",
                    line=dict(color="blue", width=3),
                )
            )

            fig.update_layout(
                title="ãƒ‡ãƒ¼ã‚¿åé›†é€²æ—",
                xaxis_title="å®Ÿè¡Œå›æ•°",
                yaxis_title="ç´¯ç©ãƒ‡ãƒ¼ã‚¿æ•°",
                height=300,
            )

            st.plotly_chart(fig, width="stretch")

    with col2:
        st.markdown("### ğŸ¤– ãƒ¢ãƒ‡ãƒ«æƒ…å ±")

        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´çŠ¶æ³
        is_trained = model_status.get("is_trained", False)  # noqa: F841
        training_count = model_status.get("training_data_count", 0)  # noqa: F841
        last_training = model_status.get("last_training")

        status_data = {
            "ç•°å¸¸æ¤œçŸ¥ãƒ¢ãƒ‡ãƒ«": ("âœ… åˆ©ç”¨å¯èƒ½" if capabilities.get("anomaly_detection") else "âŒ æœªè¨“ç·´"),
            "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬": ("âœ… åˆ©ç”¨å¯èƒ½" if capabilities.get("performance_prediction") else "âŒ æœªè¨“ç·´"),
            "æœ€é©åŒ–ææ¡ˆ": ("âœ… åˆ©ç”¨å¯èƒ½" if capabilities.get("optimization_suggestions") else "âŒ æœªå¯¾å¿œ"),
            "scikit-learn": ("âœ… ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿" if model_status.get("has_sklearn") else "âŒ æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"),
        }

        for feature, status in status_data.items():
            st.text(f"{feature}: {status}")

        if last_training:
            st.text(f"æœ€çµ‚è¨“ç·´: {last_training.split('T')[0]}")

        # å†è¨“ç·´ãƒœã‚¿ãƒ³
        if st.button("ğŸ”„ ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´", key="retrain_models"):
            with st.spinner("ãƒ¢ãƒ‡ãƒ«ã‚’å†è¨“ç·´ä¸­..."):
                ai_analyzer = get_ai_analyzer()
                success = ai_analyzer.train_models(force_retrain=True)
                if success:
                    st.success("âœ… ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´å®Œäº†!")
                    st.rerun()
                else:
                    st.error("âŒ å†è¨“ç·´ã«å¤±æ•—ã—ã¾ã—ãŸ")

    # æ©Ÿèƒ½èª¬æ˜
    st.markdown("### ğŸ“– AIåˆ†ææ©Ÿèƒ½ã®èª¬æ˜")

    with st.expander("ç•°å¸¸æ¤œçŸ¥ãƒ¢ãƒ‡ãƒ« (Isolation Forest)"):
        st.markdown(
            """
        - **ç›®çš„**: é€šå¸¸ã¨ç•°ãªã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è‡ªå‹•æ¤œçŸ¥
        - **ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **: Isolation Forestï¼ˆå­¤ç«‹æ£®æ—æ³•ï¼‰
        - **æ¤œçŸ¥å¯¾è±¡**: CPUä½¿ç”¨ç‡ã€å®Ÿè¡Œæ™‚é–“ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³
        - **ç²¾åº¦**: æ±šæŸ“ç‡10%ï¼ˆ10%ã‚’ç•°å¸¸ã¨ã—ã¦æ¤œçŸ¥ï¼‰
        """
        )

    with st.expander("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬ãƒ¢ãƒ‡ãƒ« (Random Forest)"):
        st.markdown(
            """
        - **ç›®çš„**: å®Ÿè¡Œæ™‚é–“ã®äºˆæ¸¬ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‚¾å‘ã®åˆ†æ
        - **ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **: Random Forestå›å¸°
        - **äºˆæ¸¬å¯¾è±¡**: ç·å®Ÿè¡Œæ™‚é–“ã€ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥å‡¦ç†æ™‚é–“
        - **ç‰¹å¾´é‡**: ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€æ™‚é–“çš„è¦å› 
        """
        )

    with st.expander("æœ€é©åŒ–ææ¡ˆã‚·ã‚¹ãƒ†ãƒ "):
        st.markdown(
            """
        - **ç›®çš„**: ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãå…·ä½“çš„ãªæ”¹å–„ææ¡ˆã®ç”Ÿæˆ
        - **åˆ†æè¦ç´ **: ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ãƒ•ã‚§ãƒ¼ã‚ºã€ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³ã€æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹é‡è¦è¦å› 
        - **ææ¡ˆå†…å®¹**: ä¸¦åˆ—å‡¦ç†ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ´»ç”¨ã€ãƒªã‚½ãƒ¼ã‚¹é…åˆ†æœ€é©åŒ–
        - **åŠ¹æœäºˆæ¸¬**: æ”¹å–„è¦‹è¾¼ã¿ã®å®šé‡çš„æ¨å®š
        """
        )


def render_anomaly_detection_tab(summary: Dict[str, Any]) -> None:
    """ç•°å¸¸æ¤œçŸ¥ã‚¿ãƒ–ã®æç”»"""
    st.subheader("ğŸ” ç•°å¸¸æ¤œçŸ¥åˆ†æ")

    current_analysis = summary.get("current_analysis", {})

    if not current_analysis:
        st.info("ğŸ’¡ ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå¾Œã«ç•°å¸¸æ¤œçŸ¥çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
        return

    # ç¾åœ¨ã®ç•°å¸¸æ¤œçŸ¥çŠ¶æ³
    col1, col2, col3 = st.columns(3)

    with col1:
        is_anomaly = current_analysis.get("is_anomaly", False)
        anomaly_color = "ğŸ”´" if is_anomaly else "ğŸŸ¢"
        st.metric(
            label=f"{anomaly_color} ç•°å¸¸æ¤œçŸ¥",
            value="ç•°å¸¸ã‚ã‚Š" if is_anomaly else "æ­£å¸¸",
            delta=f"ä¿¡é ¼åº¦: {current_analysis.get('confidence', 0):.1%}",
        )

    with col2:
        anomaly_score = current_analysis.get("anomaly_score", 0)
        score_color = "ğŸ”´" if anomaly_score < -0.1 else "ğŸŸ¡" if anomaly_score < 0 else "ğŸŸ¢"
        st.metric(
            label=f"{score_color} ç•°å¸¸ã‚¹ã‚³ã‚¢",
            value=f"{anomaly_score:.3f}",
            delta="ä½ã„ã»ã©ç•°å¸¸",
        )

    with col3:
        predicted_time = current_analysis.get("predicted_performance")
        if predicted_time:
            st.metric(label="â±ï¸ äºˆæ¸¬å®Ÿè¡Œæ™‚é–“", value=f"{predicted_time:.1f}ç§’", delta=None)
        else:
            st.metric(label="â±ï¸ äºˆæ¸¬å®Ÿè¡Œæ™‚é–“", value="N/A", delta="ãƒ‡ãƒ¼ã‚¿ä¸è¶³")

    # ç•°å¸¸æ¤œçŸ¥ã®è©³ç´°èª¬æ˜
    if is_anomaly:
        st.warning("âš ï¸ **ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ**")

        st.markdown("### ğŸ” ç•°å¸¸ã®è©³ç´°")
        st.markdown(
            f"""
        - **ç•°å¸¸ã‚¹ã‚³ã‚¢**: {anomaly_score:.3f}ï¼ˆé€šå¸¸: > -0.1ï¼‰
        - **æ¤œå‡ºæ™‚åˆ»**: {current_analysis.get("timestamp", "N/A")}
        - **ç‰¹å¾´é‡æ•°**: {current_analysis.get("feature_count", 0)}
        """
        )

        # ç•°å¸¸æ¤œçŸ¥ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹
        st.markdown("### ğŸ’¡ å¯¾å¿œæ¨å¥¨äº‹é …")
        st.markdown(
            """
        1. **ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ã®ç¢ºèª**: CPUã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ã‚’ãƒã‚§ãƒƒã‚¯
        2. **å¤–éƒ¨è¦å› ã®èª¿æŸ»**: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€ãƒ‡ã‚£ã‚¹ã‚¯I/Oã®çŠ¶æ³ç¢ºèª
        3. **ãƒ‡ãƒ¼ã‚¿å“è³ªã®ç¢ºèª**: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        4. **æœ€é©åŒ–ææ¡ˆã®ç¢ºèª**: AIåˆ†æã«ã‚ˆã‚‹å…·ä½“çš„ãªæ”¹å–„æ¡ˆã‚’å‚ç…§
        """
        )
    else:
        st.success("âœ… **ã‚·ã‚¹ãƒ†ãƒ ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™**")

    # ç•°å¸¸æ¤œçŸ¥ã®ä»•çµ„ã¿èª¬æ˜
    with st.expander("ğŸ”§ ç•°å¸¸æ¤œçŸ¥ã®ä»•çµ„ã¿"):
        st.markdown(
            """
        **Isolation Forest ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **

        1. **å­¦ç¿’ãƒ•ã‚§ãƒ¼ã‚º**: éå»ã®æ­£å¸¸ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ­£å¸¸ç¯„å›²ã‚’å­¦ç¿’
        2. **æ¤œçŸ¥ãƒ•ã‚§ãƒ¼ã‚º**: æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒæ­£å¸¸ç¯„å›²ã‹ã‚‰å¤–ã‚Œã¦ã„ã‚‹ã‹ã‚’åˆ¤å®š
        3. **ã‚¹ã‚³ã‚¢è¨ˆç®—**: -1ï¼ˆç•°å¸¸ï¼‰ã‹ã‚‰ +1ï¼ˆæ­£å¸¸ï¼‰ã¾ã§ã®ã‚¹ã‚³ã‚¢ã‚’ç®—å‡º
        4. **é–¾å€¤åˆ¤å®š**: ã‚¹ã‚³ã‚¢ãŒ -0.1 æœªæº€ã®å ´åˆã«ç•°å¸¸ã¨ã—ã¦æ¤œçŸ¥

        **æ¤œçŸ¥å¯¾è±¡ã®ç‰¹å¾´é‡**
        - å®Ÿè¡Œæ™‚é–“ï¼ˆç·æ™‚é–“ã€æœ€é•·ãƒ•ã‚§ãƒ¼ã‚ºã€ã°ã‚‰ã¤ãï¼‰
        - ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ï¼ˆCPUã€ãƒ¡ãƒ¢ãƒªã€I/Oï¼‰
        - å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä¸¦åˆ—åº¦ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºï¼‰
        - æ™‚é–“çš„è¦å› ï¼ˆæ™‚åˆ»ã€æ›œæ—¥ï¼‰
        """
        )


def render_performance_prediction_tab(summary: Dict[str, Any]) -> None:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬ã‚¿ãƒ–ã®æç”»"""
    st.subheader("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬åˆ†æ")

    current_analysis = summary.get("current_analysis", {})

    if not current_analysis:
        st.info("ğŸ’¡ ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå¾Œã«äºˆæ¸¬çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
        return

    # äºˆæ¸¬çµæœã®è¡¨ç¤º
    predicted_time = current_analysis.get("predicted_performance")
    confidence = current_analysis.get("confidence", 0)

    if predicted_time:
        col1, col2 = st.columns(2)

        with col1:
            st.metric(
                label="â±ï¸ äºˆæ¸¬å®Ÿè¡Œæ™‚é–“",
                value=f"{predicted_time:.1f}ç§’",
                delta=f"ä¿¡é ¼åº¦: {confidence:.1%}",
            )

        with col2:
            # éå»ã®å®Ÿè¡Œæ™‚é–“ã¨ã®æ¯”è¼ƒï¼ˆæ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ï¼‰
            ai_analyzer = get_ai_analyzer()
            if len(ai_analyzer.performance_history) > 0:
                recent_times = [r["total_time"] for r in list(ai_analyzer.performance_history)[-10:]]
                avg_time = np.mean(recent_times) if recent_times else predicted_time
                diff_percent = ((predicted_time - avg_time) / avg_time * 100) if avg_time > 0 else 0

                st.metric(
                    label="ğŸ“ˆ éå»å¹³å‡ã¨ã®å·®",
                    value=f"{diff_percent:+.1f}%",
                    delta=f"å¹³å‡: {avg_time:.1f}ç§’",
                )

        # äºˆæ¸¬ç²¾åº¦ã®å¯è¦–åŒ–
        st.markdown("### ğŸ“Š äºˆæ¸¬ç²¾åº¦ãƒˆãƒ¬ãƒ³ãƒ‰")

        # æ¨¡æ“¬çš„ãªäºˆæ¸¬ç²¾åº¦ãƒ‡ãƒ¼ã‚¿
        if len(ai_analyzer.performance_history) > 5:
            recent_data = list(ai_analyzer.performance_history)[-20:]

            actual_times = [r["total_time"] for r in recent_data]
            # æ¨¡æ“¬çš„ãªäºˆæ¸¬å€¤ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ä¿å­˜ã•ã‚ŒãŸäºˆæ¸¬å€¤ã‚’ä½¿ç”¨ï¼‰
            predicted_times = [t * (0.9 + 0.2 * np.random.random()) for t in actual_times]

            fig = go.Figure()

            x_values = list(range(len(actual_times)))

            fig.add_trace(
                go.Scatter(
                    x=x_values,
                    y=actual_times,
                    mode="lines+markers",
                    name="å®Ÿéš›ã®å®Ÿè¡Œæ™‚é–“",
                    line=dict(color="blue", width=3),
                )
            )

            fig.add_trace(
                go.Scatter(
                    x=x_values,
                    y=predicted_times,
                    mode="lines+markers",
                    name="äºˆæ¸¬å®Ÿè¡Œæ™‚é–“",
                    line=dict(color="red", width=2, dash="dash"),
                )
            )

            fig.update_layout(
                title="å®Ÿè¡Œæ™‚é–“ã®äºˆæ¸¬ç²¾åº¦",
                xaxis_title="å®Ÿè¡Œå›æ•°ï¼ˆç›´è¿‘20å›ï¼‰",
                yaxis_title="å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰",
                height=400,
                showlegend=True,
            )

            st.plotly_chart(fig, width="stretch")

        # ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆæ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ï¼‰
        st.markdown("### ğŸ¯ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å½±éŸ¿è¦å› ")

        feature_names = [
            "CPUä½¿ç”¨ç‡",
            "ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡",
            "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º",
            "ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°",
            "æ™‚é–“å¸¯",
            "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡",
        ]
        importance_scores = np.random.random(len(feature_names))
        importance_scores = importance_scores / importance_scores.sum() * 100

        fig = go.Figure(data=[go.Bar(x=feature_names, y=importance_scores, marker_color="lightblue")])

        fig.update_layout(
            title="ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¸ã®å½±éŸ¿åº¦",
            xaxis_title="è¦å› ",
            yaxis_title="å½±éŸ¿åº¦ï¼ˆ%ï¼‰",
            height=400,
        )

        st.plotly_chart(fig, width="stretch")

    else:
        st.warning("âš ï¸ äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        st.info("ğŸ’¡ ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒè“„ç©ã•ã‚Œã‚‹ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬ãŒåˆ©ç”¨å¯èƒ½ã«ãªã‚Šã¾ã™")

    # äºˆæ¸¬æ©Ÿèƒ½ã®èª¬æ˜
    with st.expander("ğŸ”§ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬ã®ä»•çµ„ã¿"):
        st.markdown(
            """
        **Random Forest å›å¸°ãƒ¢ãƒ‡ãƒ«**

        1. **å­¦ç¿’ãƒ‡ãƒ¼ã‚¿**: éå»ã®å®Ÿè¡Œãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´é‡ã¨å®Ÿè¡Œæ™‚é–“ã®é–¢ä¿‚ã‚’å­¦ç¿’
        2. **ç‰¹å¾´é‡**: ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€å®Ÿè¡Œè¨­å®šã€æ™‚é–“çš„è¦å› ã‚’çµ„ã¿åˆã‚ã›
        3. **äºˆæ¸¬**: ç¾åœ¨ã®çŠ¶æ³ã‹ã‚‰å®Ÿè¡Œæ™‚é–“ã‚’äºˆæ¸¬
        4. **ä¿¡é ¼åº¦**: éå»ã®äºˆæ¸¬ç²¾åº¦ã«åŸºã¥ãä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢

        **æ´»ç”¨ãƒ¡ãƒªãƒƒãƒˆ**
        - äº‹å‰ã®ãƒªã‚½ãƒ¼ã‚¹è¨ˆç”»ç«‹æ¡ˆ
        - ãƒœãƒˆãƒ«ãƒãƒƒã‚¯äºˆæ¸¬ã«ã‚ˆã‚‹æœ€é©åŒ–
        - SLAéµå®ˆã®ãŸã‚ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
        - å‡¦ç†ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã®æœ€é©åŒ–
        """
        )


def render_optimization_suggestions_tab(summary: Dict[str, Any]) -> None:
    """æœ€é©åŒ–ææ¡ˆã‚¿ãƒ–ã®æç”»"""
    st.subheader("ğŸ’¡ AIæœ€é©åŒ–ææ¡ˆ")

    suggestions = summary.get("optimization_suggestions", [])

    if not suggestions:
        st.info("ğŸ’¡ ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå¾Œã«æœ€é©åŒ–ææ¡ˆãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
        return

    # ææ¡ˆã‚µãƒãƒªãƒ¼
    col1, col2, col3 = st.columns(3)

    priority_counts = {}
    for suggestion in suggestions:
        priority = suggestion.get("priority", "info")
        priority_counts[priority] = priority_counts.get(priority, 0) + 1

    with col1:
        high_count = priority_counts.get("high", 0)
        st.metric(label="ğŸ”´ é«˜å„ªå…ˆåº¦", value=f"{high_count}ä»¶", delta="å³åº§ãªå¯¾å¿œæ¨å¥¨")

    with col2:
        medium_count = priority_counts.get("medium", 0)
        st.metric(label="ğŸŸ¡ ä¸­å„ªå…ˆåº¦", value=f"{medium_count}ä»¶", delta="è¨ˆç”»çš„ãªæ”¹å–„")

    with col3:
        info_count = priority_counts.get("info", 0)
        st.metric(label="ğŸ”µ æƒ…å ±æä¾›", value=f"{info_count}ä»¶", delta="å‚è€ƒæƒ…å ±")

    # ææ¡ˆã®è©³ç´°è¡¨ç¤º
    st.markdown("### ğŸ“‹ æœ€é©åŒ–ææ¡ˆè©³ç´°")

    for i, suggestion in enumerate(suggestions):
        priority = suggestion.get("priority", "info")
        suggestion_type = suggestion.get("type", "general")
        title = suggestion.get("title", "No Title")
        description = suggestion.get("description", "No Description")
        estimated_improvement = suggestion.get("estimated_improvement", "N/A")

        # å„ªå…ˆåº¦ã‚¢ã‚¤ã‚³ãƒ³ã¨ã‚«ãƒ©ãƒ¼
        priority_config = {
            "high": {"icon": "ğŸ”´", "color": "red"},
            "medium": {"icon": "ğŸŸ¡", "color": "orange"},
            "info": {"icon": "ğŸ”µ", "color": "blue"},
        }

        config = priority_config.get(priority, priority_config["info"])

        # ææ¡ˆã‚«ãƒ¼ãƒ‰
        with st.container():
            st.markdown(
                f"""
            <div style="
                border-left: 4px solid {config["color"]};
                padding: 1rem;
                margin: 1rem 0;
                background-color: #f8f9fa;
                border-radius: 0 8px 8px 0;
            ">
                <h4>{config["icon"]} {title}</h4>
                <p><strong>ã‚¿ã‚¤ãƒ—:</strong> {suggestion_type}</p>
                <p><strong>è©³ç´°:</strong> {description}</p>
                <p><strong>äºˆæƒ³åŠ¹æœ:</strong> {estimated_improvement}</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

    # ææ¡ˆã‚¿ã‚¤ãƒ—åˆ¥ã®çµ±è¨ˆ
    st.markdown("### ğŸ“Š ææ¡ˆã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ")

    type_counts = {}
    for suggestion in suggestions:
        suggestion_type = suggestion.get("type", "general")
        type_counts[suggestion_type] = type_counts.get(suggestion_type, 0) + 1

    if type_counts:
        fig = go.Figure(
            data=[
                go.Pie(
                    labels=list(type_counts.keys()),
                    values=list(type_counts.values()),
                    hole=0.4,
                )
            ]
        )

        fig.update_layout(title="æœ€é©åŒ–ææ¡ˆã®åˆ†å¸ƒ", height=400)

        st.plotly_chart(fig, width="stretch")

    # å®Ÿè£…ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³
    st.markdown("### ğŸš€ å®Ÿè£…ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³")

    # å„ªå…ˆåº¦é †ã§ã‚½ãƒ¼ãƒˆ
    priority_order = {"high": 0, "medium": 1, "info": 2}
    sorted_suggestions = sorted(suggestions, key=lambda x: priority_order.get(x.get("priority", "info"), 2))

    for i, suggestion in enumerate(sorted_suggestions[:5]):  # ä¸Šä½5ä»¶ã®ã¿è¡¨ç¤º
        priority = suggestion.get("priority", "info")
        title = suggestion.get("title", "No Title")

        checkbox_key = f"suggestion_{i}_{hash(title)}"
        completed = st.checkbox(
            f"[{priority.upper()}] {title}",
            key=checkbox_key,
            help=suggestion.get("description", ""),
        )

        if completed:
            st.success(f"âœ… å®Œäº†: {title}")

    # æœ€é©åŒ–åŠ¹æœã®è¨ˆç®—
    if suggestions:
        st.markdown("### ğŸ“ˆ æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ")

        total_improvements = []
        for suggestion in suggestions:
            improvement_text = suggestion.get("estimated_improvement", "")
            # ç°¡å˜ãªæ•°å€¤æŠ½å‡ºï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ã‚ˆã‚Šè©³ç´°ãªè§£æãŒå¿…è¦ï¼‰
            if "%" in improvement_text:
                try:
                    # "20-40%ã®æ™‚é–“çŸ­ç¸®" -> 30%ã¨ã—ã¦è¨ˆç®—
                    numbers = [
                        int(s) for s in improvement_text.split() if s.replace("-", "").replace("%", "").isdigit()
                    ]
                    if numbers:
                        avg_improvement = sum(numbers) / len(numbers)
                        total_improvements.append(avg_improvement)
                except Exception:
                    pass

        if total_improvements:
            avg_improvement = np.mean(total_improvements)
            st.info(f"ğŸ’¡ å…¨ææ¡ˆã‚’å®Ÿè£…ã—ãŸå ´åˆã®äºˆæƒ³æ”¹å–„åŠ¹æœ: ç´„ {avg_improvement:.1f}%")

    # ææ¡ˆã‚·ã‚¹ãƒ†ãƒ ã®èª¬æ˜
    with st.expander("ğŸ”§ æœ€é©åŒ–ææ¡ˆã‚·ã‚¹ãƒ†ãƒ "):
        st.markdown(
            """
        **AIåˆ†æã«ã‚ˆã‚‹ææ¡ˆç”Ÿæˆ**

        1. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ**: å®Ÿè¡Œãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å•é¡Œç‚¹ã‚’ç‰¹å®š
        2. **æ©Ÿæ¢°å­¦ç¿’åˆ†æ**: ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦ã‹ã‚‰æ”¹å–„ãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡º
        3. **ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ†æ**: çµŒé¨“çš„çŸ¥è­˜ã«åŸºã¥ãæœ€é©åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³
        4. **åŠ¹æœäºˆæ¸¬**: éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ”¹å–„åŠ¹æœã‚’å®šé‡çš„ã«æ¨å®š

        **ææ¡ˆã‚«ãƒ†ã‚´ãƒª**
        - **phase_optimization**: ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥ã®å‡¦ç†æœ€é©åŒ–
        - **resource_optimization**: ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨ã®æœ€é©åŒ–
        - **ml_insight**: æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹æ´å¯Ÿ
        - **configuration**: è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´
        """
        )


# ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰çµ±åˆé–¢æ•°
def render_ai_analysis_dashboard() -> None:
    """AIåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®çµ±åˆè¡¨ç¤º"""
    render_ai_analysis_page()
