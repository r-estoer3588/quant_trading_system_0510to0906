#!/usr/bin/env python3
"""Debug the _prepare_rolling_frame function step by step."""

import sys
from pathlib import Path

ROOT_DIR = Path(__file__).resolve().parent
if str(ROOT_DIR) not in sys.path:
    sys.path.insert(0, str(ROOT_DIR))

import pandas as pd
from common.cache_manager import CacheManager
from common.indicators_common import add_indicators
from config.settings import get_settings


def debug_prepare_rolling_frame():
    """Debug the _prepare_rolling_frame function step by step."""
    print("ğŸ” _prepare_rolling_frame é–¢æ•°ã®å‹•ä½œè§£æ")

    settings = get_settings(create_dirs=True)
    cm = CacheManager(settings)

    # Get a sample symbol
    csv_path = next(cm.full_dir.glob("*.csv"))
    symbol = csv_path.stem
    print(f"\nğŸ“Š ã‚·ãƒ³ãƒœãƒ«: {symbol}")

    # Read raw data
    df = cm.read(symbol, "full")
    print(f"ğŸ”´ Raw ãƒ‡ãƒ¼ã‚¿: {len(df.columns)} åˆ—")
    print(f"ğŸ“ Raw åˆ—å: {list(df.columns)}")

    # Step 1: Copy and basic processing
    work = df.copy()
    print(f"\n1ï¸âƒ£ Copyå¾Œ: {len(work.columns)} åˆ—")

    # Step 2: Date processing
    if "date" not in work.columns:
        if "Date" in work.columns:
            work = work.rename(columns={"Date": "date"})
        print(f"2ï¸âƒ£ Dateå‡¦ç†å¾Œ: {len(work.columns)} åˆ—")

    # Step 3: Date normalization
    work["date"] = pd.to_datetime(work["date"], errors="coerce")
    work = work.dropna(subset=["date"])
    work = work.sort_values("date").drop_duplicates("date", keep="last").reset_index(drop=True)
    print(f"3ï¸âƒ£ Dateæ­£è¦åŒ–å¾Œ: {len(work.columns)} åˆ—")

    # Step 4: Create calc copy
    calc = work.copy()
    calc["Date"] = pd.to_datetime(calc["date"], errors="coerce").dt.normalize()
    print(f"4ï¸âƒ£ calcä½œæˆ(Dateè¿½åŠ )å¾Œ: {len(calc.columns)} åˆ—")
    print(f"   ğŸ“ åˆ—å: {list(calc.columns)}")

    # Step 5: Column conversion (this is where the problem likely occurs)
    print("\n5ï¸âƒ£ OHLCV åˆ—å¤‰æ›å‡¦ç†:")
    col_pairs = (
        ("open", "Open"),
        ("high", "High"),
        ("low", "Low"),
        ("close", "Close"),
        ("volume", "Volume"),
    )

    for src, dst in col_pairs:
        if src in calc.columns and dst not in calc.columns:
            print(f"   âœ… {src} -> {dst} (å¤‰æ›å®Ÿè¡Œ)")
            calc[dst] = calc[src]
        elif src in calc.columns and dst in calc.columns:
            print(f"   âš ï¸  {src} ã¨ {dst} ä¸¡æ–¹å­˜åœ¨ -> {src}å‰Šé™¤")
            calc = calc.drop(columns=[src])
        else:
            print(f"   â­ï¸ {src}({src in calc.columns}) -> {dst}({dst in calc.columns}) ã‚¹ã‚­ãƒƒãƒ—")

    print(f"   ğŸ”„ å¤‰æ›å¾Œ: {len(calc.columns)} åˆ—")
    print(f"   ğŸ“ åˆ—å: {list(calc.columns)}")

    # Step 6: AdjClose processing
    if "AdjClose" not in calc.columns:
        for cand in ("adjusted_close", "adj_close", "adjclose"):
            if cand in calc.columns:
                print(f"6ï¸âƒ£ AdjCloseå¤‰æ›: {cand} -> AdjClose")
                calc["AdjClose"] = calc[cand]
                calc = calc.drop(columns=[cand])
                break

    print(f"6ï¸âƒ£ AdjCloseå‡¦ç†å¾Œ: {len(calc.columns)} åˆ—")

    # Step 7: Indicator calculation
    print(f"\n7ï¸âƒ£ æŒ‡æ¨™è¨ˆç®—å‰: {len(calc.columns)} åˆ—")
    enriched = add_indicators(calc)
    print(f"7ï¸âƒ£ æŒ‡æ¨™è¨ˆç®—å¾Œ: {len(enriched.columns)} åˆ—")

    # Find what changed
    added = set(enriched.columns) - set(calc.columns)
    removed = set(calc.columns) - set(enriched.columns)

    if added:
        print(f"   ğŸ†• è¿½åŠ åˆ—: {sorted(added)}")
    if removed:
        print(f"   ğŸ—‘ï¸ å‰Šé™¤åˆ—: {sorted(removed)}")

    # Step 8: Final cleanup (simulate _clean_duplicate_columns)
    print(f"\n8ï¸âƒ£ é‡è¤‡ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‰ã®åˆ—:")
    all_cols = enriched.columns.tolist()
    col_mapping = {}
    for col in all_cols:
        key = col.lower()
        if key not in col_mapping:
            col_mapping[key] = []
        col_mapping[key].append(col)

    duplicates_to_remove = []
    for key, similar_cols in col_mapping.items():
        if len(similar_cols) > 1:
            print(f"   ğŸ”„ {key}: {similar_cols}")
            # Keep the best one
            priority_scores = []
            for col in similar_cols:
                if col.isupper():
                    score = 3
                elif col[0].isupper():
                    score = 2
                elif "_" in col:
                    score = 1
                else:
                    score = 0
                priority_scores.append((score, col))

            priority_scores.sort(reverse=True)
            best_col = priority_scores[0][1]
            print(f"     âœ… ä¿æŒ: {best_col}")

            for _, col in priority_scores[1:]:
                duplicates_to_remove.append(col)
                print(f"     âŒ å‰Šé™¤: {col}")

    print(f"\nğŸ§¹ å‰Šé™¤å¯¾è±¡: {duplicates_to_remove}")


if __name__ == "__main__":
    debug_prepare_rolling_frame()
