# ============================================================================
# ðŸ§  Context Note
# ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ core/system1.py ã‚’ Streamlit UI ç”¨ã«é©å¿œã•ã›ã‚‹ãƒ©ãƒƒãƒ‘ãƒ¼å±¤ã€‚ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼†å½“æ—¥å®Ÿè¡Œä¸¡å¯¾å¿œ
#
# å‰ææ¡ä»¶ï¼š
#   - UI ã‹ã‚‰ã®ã‚·ã‚°ãƒŠãƒ«å‘¼ã³å‡ºã—ãƒ•ãƒ­ãƒ¼: symbol list â†’ setup â†’ rank â†’ signals
#   - ãƒ­ã‚¸ãƒƒã‚¯ã®æœ¬ä½“ã¯ core/system1.pyã€‚ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ orchestration ã®ã¿
#   - Alpaca ç™ºæ³¨å¯¾å¿œã€‚YAML è¨­å®šçµŒç”±ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ³¨å…¥
#   - æœ€çµ‚é…åˆ†ã¯ finalize_allocation() ã§ä¸€å…ƒåŒ–ï¼ˆAPI å¥‘ç´„åŽ³å®ˆï¼‰
#
# ãƒ­ã‚¸ãƒƒã‚¯å˜ä½ï¼š
#   generate_signals() â†’ prepare_data + generate_candidates ã‚’é †åºå®Ÿè¡Œ
#   apply_allocation() â†’ å½“æ—¥é…åˆ†ãƒ»ãƒã‚¸ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ã¾ã¨ã‚ã¦ finalize_allocation() ã¸
#   prepare_data()    â†’ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰æŒ‡æ¨™ãƒ­ãƒ¼ãƒ‰
#
# Copilot ã¸ï¼š
#   â†’ core ã®ãƒ­ã‚¸ãƒƒã‚¯å¤‰æ›´ã¯ core/system1.py ã§å®Ÿæ–½ï¼ˆã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å¤‰æ›´ç¦æ­¢ï¼‰
#   â†’ finalize_allocation() API å¥‘ç´„ã¯å¤‰æ›´ã™ã‚‹ãª
#   â†’ UI ç”¨ã®æ¤œè¨¼ã¯ç°¡æ½”ã«ã€‚è¤‡é›‘ãªæ¤œæŸ»ã¯ core ã«ä»»ã›ã‚‹
# ============================================================================

"""System1 strategy wrapper class using shared core functions.

This class integrates with YAML-driven settings for backtest parameters
and relies on StrategyBase to inject risk/system-specific config.  As an
extension example, Alpaca ç™ºæ³¨å‡¦ç†ã‚‚çµ„ã¿è¾¼ã¿ã€ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã¨å®Ÿå£²åŒæ–¹ã«
å¯¾å¿œã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚
"""

from __future__ import annotations

from typing import Any, cast

import pandas as pd

from common.alpaca_order import AlpacaOrderMixin
from core.system1 import (
    generate_candidates_system1,
    get_total_days_system1,
    prepare_data_vectorized_system1,
)

from .base_strategy import StrategyBase
from .constants import STOP_ATR_MULTIPLE_SYSTEM1


class System1Strategy(AlpacaOrderMixin, StrategyBase):
    SYSTEM_NAME = "system1"

    def __init__(self) -> None:
        super().__init__()

    def prepare_data(
        self,
        raw_data_or_symbols: dict | list[str],
        reuse_indicators: bool | None = None,
        **kwargs: Any,
    ) -> dict:
        """System1ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆå…±é€šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ + ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œï¼‰"""
        return cast(
            dict,
            self._prepare_data_template(
                raw_data_or_symbols,
                prepare_data_vectorized_system1,
                reuse_indicators=reuse_indicators,
                **kwargs,
            ),
        )

    def generate_candidates(self, data_dict, market_df=None, **kwargs):
        """å€™è£œç”Ÿæˆï¼ˆå…±é€šãƒ¡ã‚½ãƒƒãƒ‰ä½¿ç”¨ï¼‰"""
        top_n = self._get_top_n_setting(kwargs.get("top_n"))
        latest_only = bool(kwargs.get("latest_only", False))

        # Extract progress/log callbacks from kwargs if present
        progress_callback = kwargs.get("progress_callback", kwargs.get("on_progress"))
        log_callback = kwargs.get("log_callback", kwargs.get("on_log"))

        # perf snapshot è¨ˆæ¸¬ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯ãƒŽãƒ¼ã‚ªãƒšï¼‰
        try:  # noqa: SIM105
            from common.perf_snapshot import get_global_perf

            _perf = get_global_perf()
            if _perf is not None:
                _perf.mark_system_start(self.SYSTEM_NAME)
        except Exception:  # pragma: no cover
            pass
        # æœªçŸ¥ã®è¿½åŠ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆlatest_mode_date / max_date_lag_days ç­‰ï¼‰ã‚‚ã‚³ã‚¢ã¸é€éŽ
        # ãŸã ã—ã€æ˜Žç¤ºå¼•æ•°ã¨ã—ã¦æ¸¡ã™ã‚­ãƒ¼ã¯è¡çªã‚’é¿ã‘ã‚‹ãŸã‚é™¤å¤–
        extra_kwargs = dict(kwargs)
        for k in (
            "latest_only",
            "top_n",
            "progress_callback",
            "on_progress",
            "log_callback",
            "on_log",
        ):
            if k in extra_kwargs:
                extra_kwargs.pop(k, None)
        result = generate_candidates_system1(
            data_dict,
            top_n=top_n,
            latest_only=latest_only,
            progress_callback=progress_callback,
            log_callback=log_callback,
            **extra_kwargs,
        )
        if isinstance(result, tuple) and len(result) == 3:
            candidates_by_date, merged_df, diagnostics = result
            self.last_diagnostics = diagnostics
            if merged_df is not None:
                try:
                    merged_df.attrs["system1_diagnostics"] = diagnostics
                except Exception:
                    pass
            result_tuple = (candidates_by_date, merged_df)
        else:  # Fallback for unexpected shapes
            self.last_diagnostics = None
            # åž‹ãŒæƒ³å®šå¤–ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™ï¼ˆå‘¼ã³å‡ºã—å´ãŒå®‰å…¨ã«æ‰±ã†ï¼‰
            result_tuple = result
        try:  # noqa: SIM105
            from common.perf_snapshot import get_global_perf as _gpf

            _p2 = _gpf()
            if _p2 is not None:
                candidate_count = self._compute_candidate_count(result_tuple)
                _p2.mark_system_end(
                    self.SYSTEM_NAME,
                    symbol_count=len(data_dict or {}),
                    candidate_count=candidate_count,
                )
        except Exception:  # pragma: no cover
            pass
        return result_tuple

    def calculate_position_size(
        self,
        capital: float,
        entry_price: float,
        stop_price: float,
        *,
        risk_pct: float | None = None,
        max_pct: float | None = None,
        **kwargs,
    ) -> int:
        risk = self._resolve_pct(risk_pct, "risk_pct", 0.02)
        max_alloc = self._resolve_pct(max_pct, "max_pct", 0.10)
        return self._calculate_position_size_core(
            capital,
            entry_price,
            stop_price,
            risk,
            max_alloc,
        )

    def compute_entry(
        self,
        df: pd.DataFrame,
        candidate: dict,
        _current_capital: float,
    ) -> tuple[float, float] | None:
        """
        ç¿Œæ—¥å¯„ã‚Šä»˜ãã§æˆè¡Œä»•æŽ›ã‘ã—ã€ATR20Ã—5 ã‚’æåˆ‡ã‚Šã«è¨­å®šã€‚

        Args:
            df: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            candidate: ã‚¨ãƒ³ãƒˆãƒªãƒ¼å€™è£œæƒ…å ±
            _current_capital: ç¾åœ¨è³‡æœ¬ï¼ˆæœªä½¿ç”¨ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹äº’æ›æ€§ã®ãŸã‚ï¼‰

        Returns:
            (entry_price, stop_price) ã¾ãŸã¯ None
        """
        result = self._compute_entry_common(
            df,
            candidate,
            atr_column="atr20",
            stop_multiplier=self.config.get(
                "stop_atr_multiple",
                STOP_ATR_MULTIPLE_SYSTEM1,
            ),
        )
        if result is None:
            return None
        entry_price, stop_price, _ = result
        return entry_price, stop_price

    def get_total_days(self, data_dict: dict) -> int:
        return int(get_total_days_system1(data_dict))

    def compute_exit(
        self,
        df: pd.DataFrame,
        entry_idx: int,
        _entry_price: float,
        stop_price: float,
    ) -> tuple[float, pd.Timestamp]:
        """
        Day-based exit for System1 (long):
        - Stop hit: if Low <= stop -> exit same day at stop_price
        - Otherwise, max-hold days then exit on close

        Args:
            df: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            entry_idx: ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            _entry_price: ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼ï¼ˆæœªä½¿ç”¨ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹äº’æ›æ€§ã®ãŸã‚ï¼‰
            stop_price: ã‚¹ãƒˆãƒƒãƒ—ä¾¡æ ¼

        Returns:
            (exit_price, exit_date): æ±ºæ¸ˆä¾¡æ ¼ã¨æ—¥ä»˜ã®ã‚¿ãƒ—ãƒ«
        """
        try:
            from .constants import MAX_HOLD_DAYS_DEFAULT
        except Exception:
            MAX_HOLD_DAYS_DEFAULT = 3
        max_hold_days = int(self.config.get("max_hold_days", MAX_HOLD_DAYS_DEFAULT))
        n = len(df)
        for offset in range(max_hold_days):
            idx = entry_idx + offset
            if idx >= n:
                break
            row = df.iloc[idx]
            try:
                if float(row["Low"]) <= float(stop_price):
                    return float(stop_price), pd.Timestamp(str(df.index[idx]))
            except Exception:
                pass
        exit_idx = min(entry_idx + max_hold_days, n - 1)
        return float(df.iloc[exit_idx]["Close"]), pd.Timestamp(str(df.index[exit_idx]))
