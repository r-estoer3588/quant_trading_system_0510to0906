#!/usr/bin/env python3
"""
ãƒ†ã‚¹ãƒˆç”¨æ¶ç©ºéŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

System1-7 ã®å„æ®µéšï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ»ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ»ã‚·ã‚°ãƒŠãƒ«ï¼‰ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ãŸã‚ã®
æ¶ç©ºéŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
    python tools/generate_test_symbols.py

ç”Ÿæˆã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«:
    data_cache/test_symbols/FAIL_ALL.feather
    data_cache/test_symbols/FILTER_ONLY_S1.feather
    ... (ä»–ã®æ¶ç©ºéŠ˜æŸ„)
"""

from __future__ import annotations

from pathlib import Path
import sys
from typing import Any

import numpy as np
import pandas as pd
import pandas_market_calendars as mcal

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from common.cache_manager import CacheManager
from common.indicators_common import add_indicators as compute_all_indicators
from config.settings import get_settings

DEFAULT_LOOKBACK_DAYS = 300
DEFAULT_VOLATILITY = 0.02
DEFAULT_RANDOM_SEED = 42

ALIAS_COLUMN_MAP: dict[str, str] = {
    "sma25": "SMA25",
    "sma50": "SMA50",
    "sma100": "SMA100",
    "sma150": "SMA150",
    "sma200": "SMA200",
    "atr10": "ATR10",
    "atr20": "ATR20",
    "atr40": "ATR40",
    "atr50": "ATR50",
    "atr_ratio": "ATR_Ratio",
    "atr_pct": "ATR_Pct",
    "dollarvolume20": "DollarVolume20",
    "dollarvolume50": "DollarVolume50",
    "avgvolume50": "AvgVolume50",
    "roc200": "ROC200",
    "rsi3": "RSI3",
    "rsi4": "RSI4",
    "hv50": "HV50",
    "adx7": "ADX7",
}


def create_base_dates(days: int = DEFAULT_LOOKBACK_DAYS) -> pd.DatetimeIndex:
    """å–¶æ¥­æ—¥ï¼ˆNYSEï¼‰ãƒ™ãƒ¼ã‚¹ã®æ—¥ä»˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ"""

    nyse = mcal.get_calendar("NYSE")
    end_date = pd.Timestamp.utcnow().normalize()
    start_candidate = end_date - pd.Timedelta(days=int(days * 1.5))
    schedule = nyse.schedule(start_date=start_candidate, end_date=end_date)
    trading_days = pd.DatetimeIndex(schedule.index.tz_localize(None)).normalize()

    if len(trading_days) >= days:
        trading_days = trading_days[-days:]

    return pd.DatetimeIndex(trading_days, name="Date")


def create_base_ohlcv(
    dates: pd.DatetimeIndex,
    base_price: float,
    volatility: float = DEFAULT_VOLATILITY,
    seed: int | None = None,
) -> pd.DataFrame:
    """åŸºæœ¬çš„ãª OHLCV ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""

    rng = np.random.default_rng(seed if seed is not None else DEFAULT_RANDOM_SEED)
    n_days = len(dates)

    prices = np.empty(n_days)
    prices[0] = base_price
    returns = rng.normal(0, volatility, n_days)
    for idx in range(1, n_days):
        prices[idx] = prices[idx - 1] * (1 + returns[idx])

    high_noise = rng.uniform(0, 0.01, n_days)
    low_noise = rng.uniform(-0.01, 0, n_days)
    high_prices = prices * (1 + high_noise)
    low_prices = prices * (1 + low_noise)
    open_prices = np.roll(prices, 1)
    open_prices[0] = prices[0]

    base_volume = 1_000_000
    volume_noise = rng.uniform(0.5, 2.0, n_days)
    volumes = (base_volume * volume_noise).astype(int)

    return pd.DataFrame(
        {
            "Date": dates,
            "Open": open_prices,
            "High": high_prices,
            "Low": low_prices,
            "Close": prices,
            "Volume": volumes,
        }
    )


def ensure_custom_columns(df: pd.DataFrame) -> pd.DataFrame:
    """æˆ¦ç•¥ãŒå‚ç…§ã™ã‚‹è¿½åŠ ã‚«ãƒ©ãƒ ã‚’ç¢ºå®Ÿã«æŒãŸã›ã‚‹"""

    enriched = df.copy()
    if "Close" not in enriched:
        return enriched

    close = enriched["Close"]
    up_days = close.gt(close.shift(1))
    enriched["TwoDayUp"] = up_days & up_days.shift(1)
    enriched["UpTwoDays"] = enriched["TwoDayUp"]

    with np.errstate(divide="ignore", invalid="ignore"):
        enriched["3æ—¥ä¸‹è½ç‡"] = (close.shift(3) - close) / close.shift(3) * 100
        enriched["6æ—¥ä¸Šæ˜‡ç‡"] = (close - close.shift(6)) / close.shift(6) * 100

    return enriched


def add_alias_columns(df: pd.DataFrame) -> pd.DataFrame:
    """ä¸»è¦åˆ—ã«å¾“æ¥è¡¨è¨˜ï¼ˆå¤§æ–‡å­—ï¼‰ã‚’ä»˜ä¸ã™ã‚‹"""

    enriched = df.copy()
    for source, alias in ALIAS_COLUMN_MAP.items():
        if source in enriched.columns and alias not in enriched.columns:
            enriched[alias] = enriched[source]
    return enriched


def apply_symbol_config(df: pd.DataFrame, config: dict[str, Any]) -> pd.DataFrame:
    """å…±é€šæŒ‡æ¨™ã‚’è¨ˆç®—ã—ã¤ã¤è¨­å®šã«åŸºã¥ã„ã¦æœ€çµ‚è¡Œã‚’ä¸Šæ›¸ã

    å…¨ã‚«ãƒ©ãƒ ã‚’å°æ–‡å­—ã«çµ±ä¸€ã—ã¦ CacheManager ã¨äº’æ›æ€§ã‚’ç¢ºä¿
    """

    enriched = compute_all_indicators(df)
    enriched = ensure_custom_columns(enriched)
    enriched = add_alias_columns(enriched)

    # å…¨ã‚«ãƒ©ãƒ ã‚’å°æ–‡å­—ã«çµ±ä¸€ï¼ˆCacheManager äº’æ›ï¼‰
    enriched.columns = [c.lower() for c in enriched.columns]

    col_map = {
        col.lower(): col for col in enriched.columns
        if col.lower() not in {"date"}
    }

    skip_keys = {"base_price", "volatility"}

    for key, value in config.items():
        if key.lower() in skip_keys:
            continue
        if not isinstance(value, (int, float, bool)):
            continue

        lookup_key = key.lower()
        actual_col = col_map.get(lookup_key)
        if actual_col is None:
            actual_col = key.lower()
            enriched[actual_col] = np.nan
            col_map[lookup_key] = actual_col

        enriched.loc[enriched.index[-1], actual_col] = value

    return enriched


def create_test_symbol_configs() -> dict[str, dict[str, Any]]:
    """å„æ¶ç©ºéŠ˜æŸ„ã®è¨­å®šã‚’å®šç¾©: 113éŠ˜æŸ„+SPY rolling ãƒ‘ã‚¿ãƒ¼ãƒ³

    - FAIL_ALL_00..04 (5å€‹): ãƒ•ã‚£ãƒ«ã‚¿ä¸åˆæ ¼
    - FILTER_ONLY_S{1..6}_00..02 (18å€‹): ãƒ•ã‚£ãƒ«ã‚¿ã¯åˆæ ¼ã€ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸åˆæ ¼
    - SETUP_PASS_S{1..6}_00..14 (90å€‹): ãƒ•ã‚£ãƒ«ã‚¿ãƒ»ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—åˆæ ¼ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æ•£
    åˆè¨ˆ: 113éŠ˜æŸ„
    """
    configs = {}

    # === FAIL_ALL_00..04: ãƒ•ã‚£ãƒ«ã‚¿ä¸åˆæ ¼ ===
    for idx in range(5):
        configs[f"FAIL_ALL_{idx:02d}"] = {
            "base_price": 2.0,
            "Close": 2.0,
            "Volume": 50000 + idx * 10000,
            "SMA25": 2.1,
            "SMA50": 2.0,
            "RSI3": 50,
            "ATR_Ratio": 0.01,
            "DollarVolume20": 100000 + idx * 20000,
            "DollarVolume50": 100000 + idx * 20000,
            "HV50": 3 + idx,
        }

    # === FILTER_ONLY_S{1..6}_00..02: ãƒ•ã‚£ãƒ«ã‚¿åˆæ ¼ã€ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸åˆæ ¼ ===
    # S1: ROC200, SMAæ¡ä»¶ OK ã ãŒ Signal ä¸åˆæ ¼
    for idx in range(3):
        configs[f"FILTER_ONLY_S1_{idx:02d}"] = {
            "base_price": 50.0 + idx * 2,
            "Close": 50.0 + idx * 2,
            "Volume": 1500000 + idx * 100000,
            "SMA25": 51.0 + idx,
            "SMA50": 49.0 + idx,
            "DollarVolume20": 75000000 + idx * 5000000,
            "ATR_Ratio": 0.015,
            "ROC200": 0.08 + idx * 0.01,
            "RSI3": 45 + idx * 5,  # Signal ã§ã¯ æ¡ä»¶å¤–
        }

    # S2: RSI3 ãŒé«˜ã„ãŒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ¡ä»¶å¤–
    for idx in range(3):
        configs[f"FILTER_ONLY_S2_{idx:02d}"] = {
            "base_price": 25.0 + idx * 1.5,
            "Close": 25.0 + idx * 1.5,
            "Volume": 1200000 + idx * 80000,
            "DollarVolume20": 30000000 + idx * 2000000,
            "ATR_Ratio": 0.04 + idx * 0.005,
            "RSI3": 80 + idx * 3,
            "ADX7": 28 + idx * 2,
            "TwoDayUp": False,  # Signal ã§ã¯ True å¿…é ˆ
        }

    # S3: Low ãŒä½ã„ã€ä¸‹è½ç‡ãŒã‚ã‚‹ç¨‹åº¦ã‚ã‚‹ãŒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ¡ä»¶å¤–
    for idx in range(3):
        configs[f"FILTER_ONLY_S3_{idx:02d}"] = {
            "base_price": 22.0 + idx * 1,
            "Close": 22.0 + idx * 1,
            "Low": 19.5 + idx * 0.5,
            "Volume": 1200000 + idx * 80000,
            "AvgVolume50": 1200000 + idx * 80000,
            "ATR_Ratio": 0.065 + idx * 0.01,
            "SMA150": 23.5 + idx,
            "3æ—¥ä¸‹è½ç‡": 8.0 + idx * 2,  # Signal ã§ã¯ 15% ä»¥ä¸Šå¿…é ˆ
        }

    # S4: HV/SMA ã¯åˆæ ¼ã ãŒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ¡ä»¶å¤–
    for idx in range(3):
        configs[f"FILTER_ONLY_S4_{idx:02d}"] = {
            "base_price": 100.0 + idx * 5,
            "Close": 100.0 + idx * 5,
            "Volume": 1000000 + idx * 80000,
            "DollarVolume50": 100000000 + idx * 5000000,
            "HV50": 24 + idx * 2,
            "SMA200": 106.0 + idx * 2,  # Signal ã§ã¯ 95 ä»¥ä¸‹å¿…é ˆ
            "RSI4": 35 + idx * 5,
        }

    # S5: ä½ä¾¡æ ¼ãƒ»é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã€ãŸã ã—ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ¡ä»¶å¤–
    for idx in range(3):
        configs[f"FILTER_ONLY_S5_{idx:02d}"] = {
            "base_price": 15.0 + idx * 0.5,
            "Close": 15.0 + idx * 0.5,
            "Volume": 500000 + idx * 50000,
            "AvgVolume50": 500000 + idx * 50000,
            "DollarVolume50": 7500000 + idx * 500000,
            "ATR_Pct": 0.035 + idx * 0.005,
            "SMA100": 14.5 + idx * 0.2,
            "ATR10": 0.9 + idx * 0.05,
            "ADX7": 55 + idx * 5,
            "RSI3": 50 + idx * 3,  # Signal ã§ã¯ 40 æœªæº€å¿…é ˆ
        }

    # S6: return_6d ãŒä¸­ç¨‹åº¦ã ãŒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ¡ä»¶å¤–
    for idx in range(3):
        configs[f"FILTER_ONLY_S6_{idx:02d}"] = {
            "base_price": 20.0 + idx * 1,
            "Close": 20.0 + idx * 1,
            "Low": 18.0 + idx * 0.5,
            "Volume": 700000 + idx * 50000,
            "DollarVolume50": 14000000 + idx * 1000000,
            "return_6d": 12.0 + idx * 2,
            "UpTwoDays": False,  # Signal ã§ã¯ True å¿…é ˆ
            "6æ—¥ä¸Šæ˜‡ç‡": 20.0 + idx * 2,
        }

    # === SETUP_PASS_S{1..6}_00..14: ãƒ•ã‚£ãƒ«ã‚¿ãƒ»ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—åˆæ ¼ (ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æ•£) ===
    # S1: SMA25 > SMA50, ROC200 > 0
    for idx in range(15):
        configs[f"SETUP_PASS_S1_{idx:02d}"] = {
            "base_price": 50.0 + idx * 2,
            "Close": 50.0 + idx * 2,
            "Volume": 1500000 + idx * 50000,
            "SMA25": 51.5 + idx * 1.2,
            "SMA50": 49.0 + idx * 0.8,
            "DollarVolume20": 75000000 + idx * 3000000,
            "ATR_Ratio": 0.012 + idx * 0.001,
            "ROC200": 0.08 + idx * 0.02,
            "RSI3": 55 + idx * 2,
        }

    # S2: RSI3 > 80, TwoDayUp=True, ADX > 25
    for idx in range(15):
        configs[f"SETUP_PASS_S2_{idx:02d}"] = {
            "base_price": 25.0 + idx * 1.5,
            "Close": 25.0 + idx * 1.5,
            "Volume": 1200000 + idx * 60000,
            "DollarVolume20": 30000000 + idx * 2000000,
            "ATR_Ratio": 0.04 + idx * 0.003,
            "RSI3": 85 + idx * 1,
            "TwoDayUp": True,
            "ADX7": 30 + idx * 2,
        }

    # S3: Close > SMA150, 3æ—¥ä¸‹è½ç‡ > 15%, ATR_Ratio
    for idx in range(15):
        configs[f"SETUP_PASS_S3_{idx:02d}"] = {
            "base_price": 22.0 + idx * 1.2,
            "Close": 22.0 + idx * 1.2,
            "Low": 20.0 + idx * 0.8,
            "Volume": 1200000 + idx * 60000,
            "AvgVolume50": 1200000 + idx * 60000,
            "ATR_Ratio": 0.062 + idx * 0.003,
            "SMA150": 20.5 + idx * 0.5,
            "3æ—¥ä¸‹è½ç‡": 18.0 + idx * 1.5,
        }

    # S4: Close > SMA200, HV > 20
    for idx in range(15):
        configs[f"SETUP_PASS_S4_{idx:02d}"] = {
            "base_price": 100.0 + idx * 5,
            "Close": 100.0 + idx * 5,
            "Volume": 1000000 + idx * 50000,
            "DollarVolume50": 100000000 + idx * 5000000,
            "HV50": 22 + idx * 1.5,
            "SMA200": 92.0 + idx * 2,
            "RSI4": 32 + idx * 1.5,
        }

    # S5: AvgVolume > threshold, ATR_Pct > threshold, ADX, RSI3 < 40
    for idx in range(15):
        configs[f"SETUP_PASS_S5_{idx:02d}"] = {
            "base_price": 15.0 + idx * 0.8,
            "Close": 15.0 + idx * 0.8,
            "Volume": 500000 + idx * 40000,
            "AvgVolume50": 500000 + idx * 40000,
            "DollarVolume50": 7500000 + idx * 600000,
            "ATR_Pct": 0.032 + idx * 0.002,
            "SMA100": 13.5 + idx * 0.3,
            "ATR10": 0.6 + idx * 0.05,
            "ADX7": 58 + idx * 1.5,
            "RSI3": 35 + idx * 1,
        }

    # S6: return_6d > 20%, UpTwoDays=True, 6æ—¥ä¸Šæ˜‡ç‡ > 25%
    for idx in range(15):
        configs[f"SETUP_PASS_S6_{idx:02d}"] = {
            "base_price": 20.0 + idx * 1.2,
            "Close": 20.0 + idx * 1.2,
            "Low": 18.0 + idx * 0.5,
            "Volume": 700000 + idx * 50000,
            "DollarVolume50": 14000000 + idx * 1200000,
            "return_6d": 22.0 + idx * 1.5,
            "UpTwoDays": True,
            "6æ—¥ä¸Šæ˜‡ç‡": 28.0 + idx * 2,
        }

    # === æ—§13éŠ˜æŸ„äº’æ›ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼ˆå¾Œã§ upsert æ™‚ã«è¿½åŠ ï¼‰ ===
    # ã“ã‚Œã‚‰ã¯åˆ¥é€”ãƒãƒ³ãƒ‰ãƒ«ã—ã€ç”Ÿæˆå¾Œã« CacheManager ã§ copy ã¨ã—ã¦ä¿å­˜

    return configs


def generate_test_symbols() -> None:
    """113éŠ˜æŸ„+SPY rolling ã‚’ç”Ÿæˆãƒ»CacheManagerçµŒç”±ã§ä¿å­˜

    ãƒ‘ã‚¿ãƒ¼ãƒ³:
      - FAIL_ALL_00..04 (5å€‹)
      - FILTER_ONLY_S{1..6}_00..02 (18å€‹)
      - SETUP_PASS_S{1..6}_00..14 (90å€‹)
      = 113éŠ˜æŸ„ + æ—§13éŠ˜æŸ„ã‚¨ã‚¤ãƒªã‚¢ã‚¹ + SPY rolling-only
    """

    settings = get_settings()
    cache = CacheManager(settings)
    dates = create_base_dates()
    configs = create_test_symbol_configs()

    # test_symbols ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å…ˆã«æº–å‚™
    test_symbols_dir = settings.DATA_CACHE_DIR / "test_symbols"
    test_symbols_dir.mkdir(exist_ok=True)

    print("æ¶ç©ºéŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­... (113+SPYéŠ˜æŸ„)")

    # === 113éŠ˜æŸ„ã‚’ç”Ÿæˆãƒ»ä¿å­˜ ===
    for idx, (symbol_name, config) in enumerate(configs.items()):
        print(f"  {symbol_name}ã‚’ç”Ÿæˆä¸­...")

        df = create_base_ohlcv(
            dates=dates,
            base_price=float(config["base_price"]),
            volatility=float(config.get("volatility",
                                        DEFAULT_VOLATILITY)),
            seed=DEFAULT_RANDOM_SEED + idx,
        )

        df = apply_symbol_config(df, config)

        # upsert_both ã«å‚™ãˆã¦ Date ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ date ã‚«ãƒ©ãƒ ã«æˆ»ã™
        # ï¼ˆapply_symbol_config ã§å°æ–‡å­—ã«çµ±ä¸€ã—ã¦ã„ã‚‹ãŸã‚ date ã‚«ãƒ©ãƒ ã‚ã‚Šï¼‰
        is_indexed = (
            (
                df.index.name
                and isinstance(df.index.name, str)
                and "Date" in df.index.name
            )
            or isinstance(df.index, pd.DatetimeIndex)
        )
        if is_indexed:
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒ Date ã®å ´åˆã€date ã‚«ãƒ©ãƒ ã«å¤‰æ›
            df = df.reset_index()
            if "index" in df.columns:
                df = df.drop(columns=["index"])

        # date ã‚«ãƒ©ãƒ ãŒç„¡ã„å ´åˆã¯ä½œæˆ
        if "date" not in df.columns:
            if "Date" in df.columns:
                df = df.rename(columns={"Date": "date"})
            else:
                df["date"] = dates

        # CacheManagerçµŒç”±ã§ rolling+full ã‚’è‡ªå‹•è¨ˆç®—ãƒ»ä¿å­˜
        cache.upsert_both(symbol_name, df)

        # test_symbols ã«ç›´æ¥ä¿å­˜ï¼ˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§èª­ã‚ã‚‹å½¢ã§ï¼‰
        try:
            test_file = test_symbols_dir / f"{symbol_name}.feather"
            df.to_feather(str(test_file))
        except Exception:
            pass  # å¤±æ•—ã—ã¦ã‚‚ç¶šè¡Œ

        last_row = df.iloc[-1]
        close_val = last_row.get("close", last_row.get("Close", "N/A"))
        volume_val = last_row.get("volume", last_row.get("Volume", "N/A"))
        if close_val != "N/A" and volume_val != "N/A":
            print(
                f"    ä¿å­˜å®Œäº† (upsert_both)\n"
                f"    close={close_val:.2f},"
                f" volume={volume_val:,}"
            )
        else:
            print("    ä¿å­˜å®Œäº† (upsert_both)")

    # === æ—§13éŠ˜æŸ„äº’æ›ã‚¨ã‚¤ãƒªã‚¢ã‚¹: rolling/full ã‚’ã‚³ãƒ”ãƒ¼ ===
    legacy_aliases = {
        "FAIL_ALL": "FAIL_ALL_00",
        "FILTER_ONLY_S1": "FILTER_ONLY_S1_00",
        "FILTER_ONLY_S2": "FILTER_ONLY_S2_00",
        "FILTER_ONLY_S3": "FILTER_ONLY_S3_00",
        "FILTER_ONLY_S4": "FILTER_ONLY_S4_00",
        "FILTER_ONLY_S5": "FILTER_ONLY_S5_00",
        "FILTER_ONLY_S6": "FILTER_ONLY_S6_00",
        "SETUP_PASS_S1": "SETUP_PASS_S1_00",
        "SETUP_PASS_S2": "SETUP_PASS_S2_00",
        "SETUP_PASS_S3": "SETUP_PASS_S3_00",
        "SETUP_PASS_S4": "SETUP_PASS_S4_00",
        "SETUP_PASS_S5": "SETUP_PASS_S5_00",
        "SETUP_PASS_S6": "SETUP_PASS_S6_00",
    }

    print("\næ—§13éŠ˜æŸ„ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã‚’ç”Ÿæˆä¸­...")
    for alias, source_symbol in legacy_aliases.items():
        print(f"  {alias} -> {source_symbol}")
        # full ã‚’èª­ã¿è¾¼ã‚“ã§ã‚³ãƒ”ãƒ¼ä¿å­˜ï¼ˆupsert_both ã§ rolling ã‚‚å†è¨ˆç®—ï¼‰
        df_full = cache.read(source_symbol, "full")
        if df_full is not None and not df_full.empty:
            cache.upsert_both(alias, df_full)

    # === SPY rolling-only ã‚’ç”Ÿæˆ ===
    # SPY ã¯ upsert_both ã§ rolling ã‚‚ä¿å­˜
    print("\nSPY rolling-only ã‚’ç”Ÿæˆä¸­...")
    spy_df = create_base_ohlcv(
        dates=dates,
        base_price=450.0,
        volatility=0.015,
        seed=DEFAULT_RANDOM_SEED + len(configs),
    )
    spy_df = compute_all_indicators(spy_df)

    # date ã‚«ãƒ©ãƒ ã¸ã®çµ±ä¸€
    is_indexed = (
        (
            isinstance(spy_df.index.name, str)
            and "Date" in spy_df.index.name
        )
        or isinstance(spy_df.index, pd.DatetimeIndex)
    )
    if is_indexed:
        spy_df = spy_df.reset_index()
        if "index" in spy_df.columns:
            spy_df = spy_df.drop(columns=["index"])
    if "date" not in spy_df.columns:
        if "Date" in spy_df.columns:
            spy_df = spy_df.rename(columns={"Date": "date"})
        else:
            spy_df["date"] = dates

    # æŒ‡æ¨™ã‚’å¤§æ–‡å­—ã‹ã‚‰å°æ–‡å­—ã«çµ±ä¸€
    rename_map = {}
    for col_upper, col_lower in zip(
        ["Open", "High", "Low", "Close", "Volume"],
        ["open", "high", "low", "close", "volume"],
    ):
        if col_upper in spy_df.columns and col_lower not in spy_df.columns:
            rename_map[col_upper] = col_lower
    if rename_map:
        spy_df = spy_df.rename(columns=rename_map)

    cache.upsert_both("SPY", spy_df)
    print("  SPY rolling ä¿å­˜å®Œäº†")

    # test_symbols ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã®ä¿å­˜ã¯ãƒ«ãƒ¼ãƒ—å†…ã§å®Ÿæ–½æ¸ˆã¿

    total_symbols = len(configs) + len(legacy_aliases) + 1
    print(f"\nâœ… æ¶ç©ºéŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {total_symbols}éŠ˜æŸ„")
    print(f"  - æ–°ãƒ‘ã‚¿ãƒ¼ãƒ³: {len(configs)}éŠ˜æŸ„")
    print(f"  - æ—§ã‚¨ã‚¤ãƒªã‚¢ã‚¹: {len(legacy_aliases)}éŠ˜æŸ„")
    print("  - SPY rolling: 1éŠ˜æŸ„")
    print("\nğŸ“– ä½¿ç”¨æ–¹æ³•:")
    print(
        "  python scripts/run_all_systems_today.py"
        " --test-mode test_symbols --skip-external"
    )


if __name__ == "__main__":
    generate_test_symbols()
